# -*- coding: utf-8 -*-
"""
Quantum-Enhanced Self-Evolving Enterprise LLM System v3.5Î³ ULTIMATE
é«˜åº¦AIä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  - é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ»è‡ªå·±é€²åŒ–ãƒ»åˆ†æ•£æ¨è«–ãƒ»ãƒ¡ã‚¿å­¦ç¿’

- ğŸ”® Quantum-Inspired Optimization (QAOAé¢¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ )
- ğŸ§¬ Genetic Algorithm for Prompt Evolution
- ğŸŒŠ Swarm Intelligence for Multi-Agent Coordination
- ğŸ­ Multi-Persona Debate System
- ğŸ”¬ Automated Hypothesis Generation & Testing
- ğŸ“Š Bayesian Confidence Calibration
- ğŸ¯ Reinforcement Learning from Human Feedback (RLHF)
- ğŸ§  Neural Architecture Search with Meta-Learning
- ğŸ”„ Self-Improving Reasoning Chains
- ğŸŒ Distributed Consensus Mechanism
- ğŸª Adversarial Testing & Red Teaming
- ğŸ” Blockchain-inspired Verification
- ğŸŒˆ Multi-Modal Reasoning Fusion
- ğŸ“ Curriculum Learning with Difficulty Adaptation
- ğŸ”® Predictive Query Understanding
- ğŸ§© Causal Inference Engine
- ğŸ¨ Creative Synthesis System
- ğŸ“¡ Real-time Knowledge Integration
- ğŸ† Competitive Multi-Model Ensemble
- ğŸ”¬ Scientific Method Application

ä½¿ã„æ–¹:
export GROQ_API_KEY='your_key'
pip install groq numpy scipy
python enterprise-llm-chat-verÎ³.py
"""

import os
import sys
import time
import json
import hashlib
import logging
import asyncio
import re
import uuid
import math
import statistics
from typing import Optional, List, Dict, Any, Callable, Tuple, Set, Union
from dataclasses import dataclass, field, asdict
from collections import defaultdict, Counter, deque
from datetime import datetime, timedelta
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from functools import lru_cache
import numpy as np

try:
    from groq import Groq, RateLimitError, APIError
except ImportError:
    print("âŒ Required: pip install groq numpy scipy")
    sys.exit(1)
try:
    import readline
except ImportError:
    pass

# ==================== å®šæ•°ãƒ»åˆ—æŒ™å‹ ====================

class Intent(str, Enum):
    QUESTION = "question"
    COMMAND = "command"
    CREATIVE = "creative"
    TECHNICAL = "technical"
    CASUAL = "casual"
    EXPLANATION = "explanation"
    REASONING = "reasoning"
    ANALYSIS = "analysis"
    RESEARCH = "research"
    PLANNING = "planning"
    DEBUGGING = "debugging"
    OPTIMIZATION = "optimization"

class Complexity(str, Enum):
    TRIVIAL = "trivial"
    SIMPLE = "simple"
    MEDIUM = "medium"
    COMPLEX = "complex"
    EXPERT = "expert"
    RESEARCH = "research"
    FRONTIER = "frontier"

class Strategy(str, Enum):
    DIRECT = "direct"
    COT = "chain_of_thought"
    REFLECTION = "reflection"
    ENSEMBLE = "ensemble"
    ITERATIVE = "iterative"
    TREE_SEARCH = "tree_search"
    DEBATE = "debate"
    SYNTHESIS = "synthesis"
    SWARM = "swarm_intelligence"
    GENETIC = "genetic_evolution"
    QUANTUM = "quantum_inspired"

class PersonaType(str, Enum):
    OPTIMIST = "optimist"
    PESSIMIST = "pessimist"
    PRAGMATIST = "pragmatist"
    INNOVATOR = "innovator"
    CRITIC = "critic"
    SYNTHESIZER = "synthesizer"

class ReasoningType(str, Enum):
    DEDUCTIVE = "deductive"
    INDUCTIVE = "inductive"
    ABDUCTIVE = "abductive"
    ANALOGICAL = "analogical"
    CAUSAL = "causal"
    COUNTERFACTUAL = "counterfactual"
    BAYESIAN = "bayesian"
    DIALECTICAL = "dialectical"
    SYSTEMS_THINKING = "systems_thinking"

class VerificationMethod(str, Enum):
    CROSS_REFERENCE = "cross_reference"
    LOGICAL_CONSISTENCY = "logical_consistency"
    FACT_CHECK = "fact_check"
    PEER_REVIEW = "peer_review"
    ADVERSARIAL_TEST = "adversarial_test"
    BLOCKCHAIN_VERIFY = "blockchain_verify"

# ==================== ãƒ‡ãƒ¼ã‚¿æ§‹é€  ====================

@dataclass
class CausalNode:
    """å› æœæ¨è«–ãƒãƒ¼ãƒ‰"""
    id: str
    event: str
    causes: List[str] = field(default_factory=list)
    effects: List[str] = field(default_factory=list)
    probability: float = 0.5
    confidence: float = 0.5
    evidence: List[str] = field(default_factory=list)

@dataclass
class AdversarialTest:
    """æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆ"""
    id: str
    original_query: str
    adversarial_query: str
    original_response: str
    adversarial_response: str
    consistency_score: float
    vulnerability_detected: bool
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class VerificationRecord:
    """æ¤œè¨¼è¨˜éŒ²"""
    id: str
    claim: str
    method: VerificationMethod
    result: bool
    confidence: float
    evidence: List[str] = field(default_factory=list)
    verified_by: str = "system"
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class CreativeSynthesis:
    """å‰µé€ çš„çµ±åˆ"""
    id: str
    concept_a: str
    concept_b: str
    synthesis: str
    novelty_score: float
    coherence_score: float
    usefulness_score: float

@dataclass
class PredictiveModel:
    """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"""
    user_patterns: Dict[str, List[float]] = field(default_factory=dict)
    query_embeddings: List[np.ndarray] = field(default_factory=list)
    predicted_intents: List[Intent] = field(default_factory=list)
    prediction_accuracy: float = 0.5

# ==================== è¨­å®š ====================

@dataclass
class QuantumConfig:
    """é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢è¨­å®š"""
    enabled: bool = True
    num_qubits: int = 8
    iterations: int = 10
    optimization_depth: int = 3

@dataclass
class GeneticConfig:
    """éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­å®š"""
    enabled: bool = True
    population_size: int = 20
    mutation_rate: float = 0.15
    crossover_rate: float = 0.7
    elite_ratio: float = 0.2
    generations: int = 5

@dataclass
class SwarmConfig:
    """ç¾¤çŸ¥èƒ½è¨­å®š"""
    enabled: bool = True
    num_agents: int = 5
    inertia_weight: float = 0.7
    cognitive_weight: float = 1.5
    social_weight: float = 1.5
    max_iterations: int = 10

@dataclass
class RLHFConfig:
    """RLHFè¨­å®š"""
    enabled: bool = True
    learning_rate: float = 0.01
    discount_factor: float = 0.95
    exploration_rate: float = 0.1
    reward_shaping: bool = True

@dataclass
class SystemConfig:
    """ã‚·ã‚¹ãƒ†ãƒ è¨­å®š"""
    # åŸºæœ¬è¨­å®š
    model: str = "llama-3.1-8b-instant"
    max_tokens: int = 4000
    temperature: float = 0.7
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»DB
    vec_db: bool = True
    vec_dim: int = 384
    cache_ttl: int = 3600
    similarity_threshold: float = 0.92
    # ãƒªãƒˆãƒ©ã‚¤
    max_retries: int = 3
    retry_delay: float = 1.0
    max_query_length: int = 15000
    # ã‚³ã‚¢æ©Ÿèƒ½
    adaptive: bool = True
    multi_armed_bandit: bool = True
    long_term_memory: bool = True
    knowledge_graph: bool = True
    chain_of_thought: bool = True
    self_reflection: bool = True
    ensemble_learning: bool = True
    metacognition: bool = True
    tree_of_thoughts: bool = True
    debate_mode: bool = True
    critic_system: bool = True
    confidence_calibration: bool = True
    active_learning: bool = True
    curriculum_learning: bool = True
    quantum: QuantumConfig = field(default_factory=QuantumConfig)
    genetic: GeneticConfig = field(default_factory=GeneticConfig)
    swarm: SwarmConfig = field(default_factory=SwarmConfig)
    rlhf: RLHFConfig = field(default_factory=RLHFConfig)
    adversarial_testing: bool = True
    causal_reasoning: bool = True
    creative_synthesis: bool = True
    predictive_modeling: bool = True
    verification_system: bool = True
    multi_model_competition: bool = True
    scientific_method: bool = True
    blockchain_verify: bool = False  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    real_time_learning: bool = True
    meta_learning: bool = True

# ==================== ãƒ‡ãƒ¼ã‚¿æ§‹é€  ====================

@dataclass
class Response:
    """LLMå¿œç­”"""
    text: str
    confidence: float
    tokens: int = 0
    prompt_tokens: int = 0
    completion_tokens: int = 0
    latency: float = 0
    cost: float = 0
    model: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    finish_reason: str = "unknown"
    cached: bool = False
    similarity: float = 0
    rating: Optional[int] = None
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    intent: Optional[Intent] = None
    complexity: Optional[Complexity] = None
    sentiment: float = 0
    strategy: Optional[Strategy] = None
    reasoning_type: Optional[ReasoningType] = None
    reasoning_steps: List[str] = field(default_factory=list)
    reflection: Optional[str] = None
    uncertainty: float = 0
    alternatives: List[Dict] = field(default_factory=list)
    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    coherence_score: float = 0
    relevance_score: float = 0
    completeness_score: float = 0
    factuality_score: float = 0
    novelty_score: float = 0
    bayesian_confidence: Optional[Tuple[float, float]] = None  # (mean, std)
    hypothesis_tested: List[str] = field(default_factory=list)
    personas_involved: List[str] = field(default_factory=list)
    genetic_fitness: float = 0
    quantum_optimized: bool = False
    swarm_consensus: float = 0
    
    @property
    def success(self) -> bool:
        return self.finish_reason in ("stop", "length")
    
    @property
    def quality_score(self) -> float:
        """ç·åˆå“è³ªã‚¹ã‚³ã‚¢"""
        scores = [
            self.confidence * 0.25,
            self.coherence_score * 0.2,
            self.relevance_score * 0.25,
            self.completeness_score * 0.15,
            self.factuality_score * 0.15
        ]
        return sum(s for s in scores if s > 0)
    
    def to_dict(self) -> Dict:
        return {
            'text': self.text,
            'confidence': self.confidence,
            'quality_score': self.quality_score,
            'strategy': self.strategy.value if self.strategy else None,
            'complexity': self.complexity.value if self.complexity else None,
            'cost': self.cost,
            'tokens': self.tokens,
            'latency': self.latency
        }

@dataclass
class Prompt:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    id: str
    template: str
    category: str
    fitness: float = 0.5
    usage_count: int = 0
    success_count: int = 0
    avg_quality: float = 0.5
    generation: int = 0
    parent_id: Optional[str] = None
    mutations: int = 0
    genes: List[str] = field(default_factory=list)
    
    @property
    def success_rate(self) -> float:
        return self.success_count / self.usage_count if self.usage_count > 0 else 0.5
    
    def mutate(self, mutation_rate: float = 0.15) -> str:
        """éºä¼çš„å¤‰ç•°"""
        if np.random.random() > mutation_rate:
            return self.template
        mutations = [
            lambda t: t.replace("Explain", "Elaborate on"),
            lambda t: t.replace("provide", "deliver"),
            lambda t: t.replace("answer", "respond to"),
            lambda t: f"{t} Think step by step.",
            lambda t: f"{t} Consider multiple perspectives.",
            lambda t: f"Carefully {t.lower()}",
            lambda t: t.replace(".", " with specific examples."),
            lambda t: f"From first principles, {t.lower()}",
            lambda t: f"{t} Show your reasoning.",
            lambda t: t.replace("describe", "analyze in depth")
        ]
        mutated = np.random.choice(mutations)(self.template)
        self.mutations += 1
        return mutated
    
    @staticmethod
    def crossover(parent1: 'Prompt', parent2: 'Prompt') -> str:
        """äº¤å‰"""
        words1 = parent1.template.split()
        words2 = parent2.template.split()
        # å˜ä¸€ç‚¹äº¤å‰
        point = np.random.randint(1, min(len(words1), len(words2)))
        child_words = words1[:point] + words2[point:]
        return ' '.join(child_words)

@dataclass
class Agent:
    """ç¾¤çŸ¥èƒ½ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    id: str
    position: np.ndarray  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®ä½ç½®
    velocity: np.ndarray
    best_position: np.ndarray
    best_fitness: float = -float('inf')
    persona: PersonaType = PersonaType.PRAGMATIST
    
    def update_velocity(
        self,
        global_best_position: np.ndarray,
        w: float,
        c1: float,
        c2: float
    ):
        """é€Ÿåº¦æ›´æ–°ï¼ˆPSOï¼‰"""
        r1, r2 = np.random.random(2)
        cognitive = c1 * r1 * (self.best_position - self.position)
        social = c2 * r2 * (global_best_position - self.position)
        self.velocity = w * self.velocity + cognitive + social
    
    def update_position(self):
        """ä½ç½®æ›´æ–°"""
        self.position = self.position + self.velocity
        # ç¯„å›²åˆ¶é™
        self.position = np.clip(self.position, 0, 1)

@dataclass
class Hypothesis:
    """ä»®èª¬"""
    id: str
    statement: str
    confidence: float
    evidence: List[str] = field(default_factory=list)
    counter_evidence: List[str] = field(default_factory=list)
    tested: bool = False
    result: Optional[bool] = None
    bayesian_prior: float = 0.5
    bayesian_posterior: float = 0.5

@dataclass
class KnowledgeNode:
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•ãƒãƒ¼ãƒ‰"""
    id: str
    name: str
    type: str
    properties: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[np.ndarray] = None
    confidence: float = 1.0
    created: datetime = field(default_factory=datetime.now)
    updated: datetime = field(default_factory=datetime.now)
    access_count: int = 0
    relevance_score: float = 0.5

@dataclass
class KnowledgeEdge:
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚¨ãƒƒã‚¸"""
    source: str
    target: str
    relation: str
    weight: float = 1.0
    confidence: float = 1.0
    properties: Dict[str, Any] = field(default_factory=dict)
    created: datetime = field(default_factory=datetime.now)

# ==================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ====================

class Logger:
    """ãƒ­ã‚¬ãƒ¼"""
    def __init__(self, name: str, level: str = "INFO"):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(getattr(logging, level))
        if not self.logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s | %(levelname)-8s | %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def info(self, msg: str):
        self.logger.info(msg)
    
    def warning(self, msg: str):
        self.logger.warning(msg)
    
    def error(self, msg: str):
        self.logger.error(msg)
    
    def debug(self, msg: str):
        self.logger.debug(msg)
logger = Logger('quantum-llm')

class VectorDB:
    """ãƒ™ã‚¯ãƒˆãƒ«DB"""
    
    def __init__(self, dimension: int = 384):
        self.dimension = dimension
        self.vectors: List[Tuple[str, np.ndarray, Dict]] = []
        self.index_cache: Dict[str, int] = {}
    
    @lru_cache(maxsize=1000)
    def _embed(self, text: str) -> np.ndarray:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹åŸ‹ã‚è¾¼ã¿ + TF-IDFé¢¨
        words = re.findall(r'\b\w+\b', text.lower())
        word_freq = Counter(words)
        hash_bytes = hashlib.sha256(text.encode()).digest()
        seed = int.from_bytes(hash_bytes[:4], 'little')
        rng = np.random.RandomState(seed)
        vec = rng.randn(self.dimension).astype(np.float32)        
        # å˜èªé »åº¦ã§é‡ã¿ä»˜ã‘
        for word, freq in word_freq.most_common(10):
            word_seed = int.from_bytes(hashlib.md5(word.encode()).digest()[:4], 'little')
            word_rng = np.random.RandomState(word_seed)
            word_vec = word_rng.randn(self.dimension).astype(np.float32)
            vec += word_vec * (freq / len(words))
        norm = np.linalg.norm(vec)
        return vec / norm if norm > 0 else vec
    
    def add(self, id: str, text: str, metadata: Dict):
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿½åŠ """
        embedding = self._embed(text)
        metadata = metadata or {}
        metadata['text'] = text
        metadata['added_at'] = time.time()
        self.index_cache[id] = len(self.vectors)
        self.vectors.append((id, embedding, metadata))
    
    def search(self, query: str, top_k: int = 5, min_similarity: float = 0.0) -> List[Tuple[str, float, Dict]]:
        """é¡ä¼¼æ¤œç´¢"""
        if not self.vectors:
            return []
        query_vec = self._embed(query)
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—ã§é«˜é€ŸåŒ–
        all_vecs = np.array([v[1] for v in self.vectors])
        similarities = np.dot(all_vecs, query_vec)
        # é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        valid_indices = np.where(similarities >= min_similarity)[0]
        if len(valid_indices) == 0:
            return []
        # ãƒˆãƒƒãƒ—Kå–å¾—
        sorted_indices = valid_indices[np.argsort(similarities[valid_indices])[::-1]][:top_k]
        results = [
            (self.vectors[i][0], float(similarities[i]), self.vectors[i][2])
            for i in sorted_indices
        ]
        return results
    
    def update_metadata(self, id: str, metadata: Dict):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        if id in self.index_cache:
            idx = self.index_cache[id]
            vec_id, vec, old_meta = self.vectors[idx]
            old_meta.update(metadata)
    
    def get_statistics(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±"""
        return {
            'total_vectors': len(self.vectors),
            'dimension': self.dimension,
            'cache_size': len(self._embed.cache_info()._asdict())
        }

# ==================== é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ====================

class QuantumOptimizer:
    """é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢æœ€é©åŒ–å™¨"""
    
    def __init__(self, config: QuantumConfig):
        self.config = config
        self.num_qubits = config.num_qubits
    
    def optimize_parameters(
        self,
        objective_function: Callable[[np.ndarray], float],
        bounds: Tuple[float, float] = (0, 1)
    ) -> Tuple[np.ndarray, float]:
        """QAOAé¢¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"""
        # åˆæœŸçŠ¶æ…‹: é‡ã­åˆã‚ã›ï¼ˆå‡ç­‰åˆ†å¸ƒï¼‰
        best_params = np.random.uniform(bounds[0], bounds[1], self.num_qubits)
        best_value = objective_function(best_params)
        for iteration in range(self.config.iterations):
            # é‡å­ã‚²ãƒ¼ãƒˆé¢¨ã®æ“ä½œ
            # 1. å›è»¢ã‚²ãƒ¼ãƒˆï¼ˆæ¢ç´¢ï¼‰
            rotation_angle = np.pi * (1 - iteration / self.config.iterations)
            candidate = best_params + np.random.randn(self.num_qubits) * rotation_angle * 0.1
            candidate = np.clip(candidate, bounds[0], bounds[1])
            # 2. ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ç›¸é–¢ï¼‰
            if self.num_qubits > 1:
                for i in range(self.num_qubits - 1):
                    if np.random.random() < 0.3:
                        coupling = (candidate[i] + candidate[i + 1]) / 2
                        candidate[i] = candidate[i + 1] = coupling
            # 3. æ¸¬å®šï¼ˆè©•ä¾¡ï¼‰
            value = objective_function(candidate)
            # 4. æŒ¯å¹…å¢—å¹…ï¼ˆè‰¯ã„è§£ã‚’å¼·åŒ–ï¼‰
            if value > best_value:
                best_params = candidate
                best_value = value
                logger.debug(f"ğŸ”® Quantum iter {iteration}: improved to {value:.4f}")
        return best_params, best_value
    
    def quantum_annealing(
        self,
        energy_function: Callable[[np.ndarray], float],
        initial_state: np.ndarray,
        temperature_schedule: Optional[List[float]] = None
    ) -> np.ndarray:
        """é‡å­ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°é¢¨ã®æœ€é©åŒ–"""
        if temperature_schedule is None:
            temperature_schedule = np.logspace(0, -2, self.config.iterations)
        current_state = initial_state.copy()
        current_energy = energy_function(current_state)
        for temp in temperature_schedule:
            # éš£æ¥çŠ¶æ…‹ã‚’ç”Ÿæˆ
            neighbor = current_state + np.random.randn(len(current_state)) * temp
            neighbor = np.clip(neighbor, 0, 1)
            neighbor_energy = energy_function(neighbor)
            # ãƒ¡ãƒˆãƒ­ãƒãƒªã‚¹åŸºæº–
            delta_energy = neighbor_energy - current_energy
            if delta_energy < 0 or np.random.random() < np.exp(-delta_energy / temp):
                current_state = neighbor
                current_energy = neighbor_energy
        return current_state

# ==================== éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ====================

class GeneticPromptEvolver:
    """éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€²åŒ–"""
    def __init__(self, config: GeneticConfig):
        self.config = config
        self.population: List[Prompt] = []
        self.generation = 0
        self.best_ever: Optional[Prompt] = None
    
    def initialize_population(self, base_templates: List[str], category: str):
        """åˆæœŸé›†å›£ã‚’ç”Ÿæˆ"""
        self.population = []
        for i, template in enumerate(base_templates):
            prompt = Prompt(
                id=str(uuid.uuid4())[:8],
                template=template,
                category=category,
                generation=0,
                genes=template.split()
            )
            self.population.append(prompt)
        # è¿½åŠ ã§ãƒ©ãƒ³ãƒ€ãƒ å¤‰ç•°ä½“ã‚’ç”Ÿæˆ
        while len(self.population) < self.config.population_size:
            parent = np.random.choice(base_templates)
            mutated = self._mutate_template(parent)
            prompt = Prompt(
                id=str(uuid.uuid4())[:8],
                template=mutated,
                category=category,
                generation=0,
                mutations=1,
                genes=mutated.split()
            )
            self.population.append(prompt)
    
    def _mutate_template(self, template: str) -> str:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰ç•°"""
        mutations = [
            lambda t: t.replace("Explain", "Elaborate on"),
            lambda t: t.replace("provide", "give"),
            lambda t: f"{t} Think carefully.",
            lambda t: f"Step by step, {t.lower()}",
            lambda t: t.replace(".", " with examples."),
            lambda t: f"Considering multiple angles, {t.lower()}",
        ]
        return np.random.choice(mutations)(template)
    
    def evolve(self, fitness_evaluator: Callable[[Prompt], float]) -> Prompt:
        """ä¸€ä¸–ä»£é€²åŒ–"""
        self.generation += 1
        # é©å¿œåº¦è©•ä¾¡
        for prompt in self.population:
            if prompt.fitness == 0.5:  # æœªè©•ä¾¡
                prompt.fitness = fitness_evaluator(prompt)
        # ã‚½ãƒ¼ãƒˆ
        self.population.sort(key=lambda p: p.fitness, reverse=True)
        # ã‚¨ãƒªãƒ¼ãƒˆä¿å­˜
        elite_count = int(self.config.population_size * self.config.elite_ratio)
        new_population = self.population[:elite_count].copy()
        # æœ€è‰¯å€‹ä½“ã®è¿½è·¡
        if self.best_ever is None or self.population[0].fitness > self.best_ever.fitness:
            self.best_ever = self.population[0]
        # äº¤å‰ã¨å¤‰ç•°ã§æ–°å€‹ä½“ç”Ÿæˆ
        while len(new_population) < self.config.population_size:
            # è¦ªé¸æŠï¼ˆãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠï¼‰
            tournament_size = 3
            tournament = np.random.choice(self.population[:len(self.population)//2], tournament_size)
            parent1 = max(tournament, key=lambda p: p.fitness)
            
            tournament = np.random.choice(self.population[:len(self.population)//2], tournament_size)
            parent2 = max(tournament, key=lambda p: p.fitness)
            # äº¤å‰
            if np.random.random() < self.config.crossover_rate:
                child_template = Prompt.crossover(parent1, parent2)
            else:
                child_template = parent1.template
            # å¤‰ç•°
            if np.random.random() < self.config.mutation_rate:
                child_template = self._mutate_template(child_template)
            child = Prompt(
                id=str(uuid.uuid4())[:8],
                template=child_template,
                category=parent1.category,
                generation=self.generation,
                parent_id=parent1.id,
                genes=child_template.split()
            )
            
            new_population.append(child)
        self.population = new_population
        logger.info(f"ğŸ§¬ Generation {self.generation}: Best fitness = {self.population[0].fitness:.4f}")
        return self.population[0]
    
    def get_best_prompts(self, top_k: int = 3) -> List[Prompt]:
        """ä¸Šä½Kå€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
        return sorted(self.population, key=lambda p: p.fitness, reverse=True)[:top_k]

# ==================== ç¾¤çŸ¥èƒ½ ====================

class SwarmIntelligence:
    """ç¾¤çŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ ï¼ˆPSOï¼‰"""
    
    def __init__(self, config: SwarmConfig):
        self.config = config
        self.agents: List[Agent] = []
        self.global_best_position: Optional[np.ndarray] = None
        self.global_best_fitness: float = -float('inf')
        self.dimension = 5  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¬¡å…ƒï¼ˆtemp, top_p, frequency_penalty, etc.ï¼‰
    
    def initialize_swarm(self):
        """ç¾¤ã‚Œã‚’åˆæœŸåŒ–"""
        personas = list(PersonaType)
        self.agents = []
        for i in range(self.config.num_agents):
            position = np.random.random(self.dimension)
            velocity = np.random.randn(self.dimension) * 0.1
            agent = Agent(
                id=f"agent_{i}",
                position=position,
                velocity=velocity,
                best_position=position.copy(),
                persona=personas[i % len(personas)]
            )
            self.agents.append(agent)
    
    def optimize(
        self,
        fitness_function: Callable[[np.ndarray, PersonaType], float],
        max_iterations: Optional[int] = None
    ) -> Tuple[np.ndarray, float]:
        """ç¾¤æœ€é©åŒ–"""
        if not self.agents:
            self.initialize_swarm()
        iterations = max_iterations or self.config.max_iterations
        for iteration in range(iterations):
            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡
            for agent in self.agents:
                fitness = fitness_function(agent.position, agent.persona)
                # å€‹ä½“ãƒ™ã‚¹ãƒˆæ›´æ–°
                if fitness > agent.best_fitness:
                    agent.best_fitness = fitness
                    agent.best_position = agent.position.copy()
                # ç¾¤ãƒ™ã‚¹ãƒˆæ›´æ–°
                if fitness > self.global_best_fitness:
                    self.global_best_fitness = fitness
                    self.global_best_position = agent.position.copy()
            # é€Ÿåº¦ã¨ä½ç½®ã®æ›´æ–°
            for agent in self.agents:
                agent.update_velocity(
                    self.global_best_position,
                    self.config.inertia_weight,
                    self.config.cognitive_weight,
                    self.config.social_weight
                )
                agent.update_position()
            logger.debug(f"ğŸŒŠ Swarm iter {iteration}: Best fitness = {self.global_best_fitness:.4f}")
        return self.global_best_position, self.global_best_fitness
    
    def get_consensus(self) -> Dict[str, Any]:
        """ç¾¤ã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ã‚’å–å¾—"""
        if not self.agents:
            return {}
        # å„ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ã®æ„è¦‹ã‚’é›†ç´„
        persona_positions = defaultdict(list)
        for agent in self.agents:
            persona_positions[agent.persona].append(agent.best_position)
        consensus = {}
        for persona, positions in persona_positions.items():
            consensus[persona.value] = {
                'mean_position': np.mean(positions, axis=0),
                'std': np.std(positions, axis=0),
                'confidence': np.mean([a.best_fitness for a in self.agents if a.persona == persona])
            }
        return consensus

# ==================== RLHF ====================

class RLHFTrainer:
    """Reinforcement Learning from Human Feedback"""
    
    def __init__(self, config: RLHFConfig):
        self.config = config
        self.q_table: Dict[Tuple[str, str], float] = defaultdict(float)  # (state, action) -> Qå€¤
        self.state_visits: Dict[str, int] = defaultdict(int)
        self.reward_history: List[float] = []
    
    def get_state(self, intent: Intent, complexity: Complexity) -> str:
        """çŠ¶æ…‹ã‚’å–å¾—"""
        return f"{intent.value}_{complexity.value}"
    
    def select_action(self, state: str, available_actions: List[str]) -> str:
        """è¡Œå‹•é¸æŠï¼ˆÎµ-greedyï¼‰"""
        if np.random.random() < self.config.exploration_rate:
            # æ¢ç´¢
            return np.random.choice(available_actions)
        else:
            # æ´»ç”¨
            q_values = [(action, self.q_table[(state, action)]) for action in available_actions]
            return max(q_values, key=lambda x: x[1])[0]
    
    def update(self, state: str, action: str, reward: float, next_state: str):
        """Qå€¤æ›´æ–°ï¼ˆQ-Learningï¼‰"""
        current_q = self.q_table[(state, action)]
        # æ¬¡çŠ¶æ…‹ã®æœ€å¤§Qå€¤
        next_q_values = [self.q_table[(next_state, a)] for a in [action]]  # ç°¡æ˜“ç‰ˆ
        max_next_q = max(next_q_values) if next_q_values else 0
        # Qå€¤æ›´æ–°
        new_q = current_q + self.config.learning_rate * (
            reward + self.config.discount_factor * max_next_q - current_q
        )
        self.q_table[(state, action)] = new_q
        self.state_visits[state] += 1
        self.reward_history.append(reward)
        logger.debug(f"ğŸ¯ RLHF: state={state}, action={action}, reward={reward:.3f}, Q={new_q:.3f}")
    
    def get_policy(self) -> Dict[str, str]:
        """ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã‚’å–å¾—"""
        policy = {}
        states = set(s for s, a in self.q_table.keys())
        for state in states:
            state_actions = [(a, q) for (s, a), q in self.q_table.items() if s == state]
            if state_actions:
                best_action = max(state_actions, key=lambda x: x[1])[0]
                policy[state] = best_action
        return policy

# ==================== å› æœæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ ====================

class CausalInferenceEngine:
    """å› æœæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.causal_graph: Dict[str, CausalNode] = {}
        self.interventions: List[Dict] = []
    
    def add_causal_relationship(
        self,
        cause: str,
        effect: str,
        probability: float = 0.7,
        evidence: List[str] = None
    ):
        """å› æœé–¢ä¿‚ã‚’è¿½åŠ """
        cause_id = hashlib.md5(cause.encode()).hexdigest()[:8]
        effect_id = hashlib.md5(effect.encode()).hexdigest()[:8]
        # åŸå› ãƒãƒ¼ãƒ‰
        if cause_id not in self.causal_graph:
            self.causal_graph[cause_id] = CausalNode(
                id=cause_id,
                event=cause,
                probability=probability
            )
        # çµæœãƒãƒ¼ãƒ‰
        if effect_id not in self.causal_graph:
            self.causal_graph[effect_id] = CausalNode(
                id=effect_id,
                event=effect,
                probability=probability
            )
        # ãƒªãƒ³ã‚¯
        self.causal_graph[cause_id].effects.append(effect_id)
        self.causal_graph[effect_id].causes.append(cause_id)
        if evidence:
            self.causal_graph[effect_id].evidence.extend(evidence)
    
    def infer_cause(self, effect: str, depth: int = 3) -> List[Tuple[str, float]]:
        """çµæœã‹ã‚‰åŸå› ã‚’æ¨è«–"""
        effect_id = hashlib.md5(effect.encode()).hexdigest()[:8]
        if effect_id not in self.causal_graph:
            return []
        causes = []
        visited = set()
        def dfs(node_id: str, current_depth: int, prob: float):
            if current_depth > depth or node_id in visited:
                return            visited.add(node_id)
            node = self.causal_graph[node_id]
            for cause_id in node.causes:
                cause_node = self.causal_graph[cause_id]
                combined_prob = prob * cause_node.probability
                causes.append((cause_node.event, combined_prob))
                dfs(cause_id, current_depth + 1, combined_prob)
        dfs(effect_id, 0, 1.0)
        causes.sort(key=lambda x: x[1], reverse=True)
        return causes[:10]
    
    def predict_effect(self, cause: str, depth: int = 3) -> List[Tuple[str, float]]:
        """åŸå› ã‹ã‚‰çµæœã‚’äºˆæ¸¬"""
        cause_id = hashlib.md5(cause.encode()).hexdigest()[:8]
        if cause_id not in self.causal_graph:
            return []
        effects = []
        visited = set()
        
        def dfs(node_id: str, current_depth: int, prob: float):
            if current_depth > depth or node_id in visited:
                return
            visited.add(node_id)
            node = self.causal_graph[node_id]
            for effect_id in node.effects:
                effect_node = self.causal_graph[effect_id]
                combined_prob = prob * effect_node.probability
                effects.append((effect_node.event, combined_prob))
                dfs(effect_id, current_depth + 1, combined_prob)
        dfs(cause_id, 0, 1.0)
        effects.sort(key=lambda x: x[1], reverse=True)
        return effects[:10]
    
    def do_intervention(self, intervention: str, observe: str) -> float:
        """ä»‹å…¥å®Ÿé¨“ï¼ˆdo-calculusï¼‰"""
        # ç°¡æ˜“çš„ãªä»‹å…¥åˆ†æ
        self.interventions.append({
            'intervention': intervention,
            'observation': observe,
            'timestamp': datetime.now()
        })
        # ä»‹å…¥ã®åŠ¹æœã‚’æ¨å®š
        effects = self.predict_effect(intervention)
        for effect, prob in effects:
            if observe.lower() in effect.lower():
                return prob
        return 0.5

# ==================== æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ  ====================

class AdversarialTester:
    """æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆãƒ»ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.tests: List[AdversarialTest] = []
        self.vulnerabilities: Dict[str, int] = defaultdict(int)
    
    def generate_adversarial_queries(self, original: str) -> List[str]:
        """æ•µå¯¾çš„ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        adversarial = []
        # 1. å¦å®šãƒ‘ã‚¿ãƒ¼ãƒ³
        adversarial.append(f"The opposite of this is true: {original}")
        # 2. æ¥µç«¯ãªã‚±ãƒ¼ã‚¹
        adversarial.append(f"{original} in the most extreme case possible")
        # 3. çŸ›ç›¾ã‚’å«ã‚€
        words = original.split()
        if len(words) > 3:
            mid = len(words) // 2
            adversarial.append(f"{' '.join(words[:mid])} but also {' '.join(words[mid:])}")
        # 4. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåè»¢
        adversarial.append(f"Assuming the opposite is true, {original}")
        # 5. ãƒã‚¤ã‚¢ã‚¹ãƒ†ã‚¹ãƒˆ
        adversarial.append(f"{original} (è€ƒãˆã‚‰ã‚Œã‚‹ãƒã‚¤ã‚¢ã‚¹ã¯ï¼Ÿ)")
        return adversarial
    
    async def test_consistency(
        self,
        query_func: Callable,
        original_query: str,
        original_response: str
    ) -> AdversarialTest:
        """ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        adversarial_queries = self.generate_adversarial_queries(original_query)
        max_inconsistency = 0
        worst_case = None
        for adv_query in adversarial_queries:
            try:
                adv_response = await query_func(adv_query)
                # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                orig_words = set(original_response.lower().split())
                adv_words = set(adv_response.text.lower().split())
                if orig_words and adv_words:
                    similarity = len(orig_words & adv_words) / len(orig_words | adv_words)
                    inconsistency = 1 - similarity
                    if inconsistency > max_inconsistency:
                        max_inconsistency = inconsistency
                        worst_case = (adv_query, adv_response.text)
            except:
                continue
        test = AdversarialTest(
            id=str(uuid.uuid4())[:8],
            original_query=original_query,
            adversarial_query=worst_case[0] if worst_case else "",
            original_response=original_response[:200],
            adversarial_response=worst_case[1][:200] if worst_case else "",
            consistency_score=1 - max_inconsistency,
            vulnerability_detected=max_inconsistency > 0.7
        )
        self.tests.append(test)
        if test.vulnerability_detected:
            self.vulnerabilities[original_query[:50]] += 1
        return test

# ==================== æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  ====================

class VerificationSystem:
    """å¤šå±¤æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.records: List[VerificationRecord] = []
        self.trusted_sources: Set[str] = {
            'wikipedia', 'arxiv', 'pubmed', 'nature', 'science'
        }
    
    def verify_claim(
        self,
        claim: str,
        context: str = "",
        method: VerificationMethod = VerificationMethod.LOGICAL_CONSISTENCY
    ) -> VerificationRecord:
        """ä¸»å¼µã‚’æ¤œè¨¼"""
        # ç°¡æ˜“æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
        confidence = 0.5
        result = True
        evidence = []
        if method == VerificationMethod.LOGICAL_CONSISTENCY:
            # è«–ç†çš„ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
            contradictions = ['but not', 'however not', 'except']
            has_contradiction = any(c in claim.lower() for c in contradictions)
            if has_contradiction:
                confidence = 0.3
                result = False
                evidence.append("Logical contradiction detected")
            else:
                confidence = 0.7
                evidence.append("No obvious contradictions")
        elif method == VerificationMethod.CROSS_REFERENCE:
            # ç›¸äº’å‚ç…§ãƒã‚§ãƒƒã‚¯
            words = set(claim.lower().split())
            context_words = set(context.lower().split())
            overlap = len(words & context_words) / len(words) if words else 0
            confidence = overlap
            result = overlap > 0.3
            evidence.append(f"Context overlap: {overlap:.2%}")
        elif method == VerificationMethod.FACT_CHECK:
            # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            uncertain_phrases = ['maybe', 'possibly', 'might', 'could be']
            has_uncertainty = any(p in claim.lower() for p in uncertain_phrases)
            confidence = 0.5 if has_uncertainty else 0.7
            evidence.append("Uncertainty markers detected" if has_uncertainty else "Assertion is confident")
        record = VerificationRecord(
            id=str(uuid.uuid4())[:8],
            claim=claim[:200],
            method=method,
            result=result,
            confidence=confidence,
            evidence=evidence
        )
        self.records.append(record)
        return record
    
    def get_trust_score(self, num_verifications: int = 10) -> float:
        """ä¿¡é ¼ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not self.records:
            return 0.5
        recent = self.records[-num_verifications:]
        verified = sum(1 for r in recent if r.result)
        avg_confidence = statistics.mean(r.confidence for r in recent)
        return (verified / len(recent)) * avg_confidence


# ==================== å‰µé€ çš„çµ±åˆã‚·ã‚¹ãƒ†ãƒ  ====================

class CreativeSynthesizer:
    """å‰µé€ çš„ã‚¢ã‚¤ãƒ‡ã‚¢çµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.syntheses: List[CreativeSynthesis] = []
        self.concept_space: Dict[str, np.ndarray] = {}
    
    def synthesize(self, concept_a: str, concept_b: str) -> CreativeSynthesis:
        """2ã¤ã®æ¦‚å¿µã‚’å‰µé€ çš„ã«çµ±åˆ"""
        # ã‚³ãƒ³ã‚»ãƒ—ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        emb_a = self._embed_concept(concept_a)
        emb_b = self._embed_concept(concept_b)
        
        # çµ±åˆãƒ™ã‚¯ãƒˆãƒ«
        synthesis_vec = (emb_a + emb_b) / 2
        
        # æ–°è¦æ€§ã‚¹ã‚³ã‚¢ï¼ˆå…ƒã®æ¦‚å¿µã¨ã®è·é›¢ï¼‰
        novelty = (
            np.linalg.norm(synthesis_vec - emb_a) +
            np.linalg.norm(synthesis_vec - emb_b)
        ) / 2
        novelty = min(1.0, novelty / 5)
        
        # çµ±åˆã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        synthesis_text = f"A fusion of {concept_a} and {concept_b}, creating a hybrid that combines the best of both"
        synthesis = CreativeSynthesis(
            id=str(uuid.uuid4())[:8],
            concept_a=concept_a,
            concept_b=concept_b,
            synthesis=synthesis_text,
            novelty_score=novelty,
            coherence_score=0.8,  # ç°¡æ˜“è©•ä¾¡
            usefulness_score=0.7
        )
        self.syntheses.append(synthesis)
        return synthesis
    
    def _embed_concept(self, concept: str) -> np.ndarray:
        """æ¦‚å¿µã‚’åŸ‹ã‚è¾¼ã¿ç©ºé–“ã«ãƒãƒƒãƒ—"""
        if concept in self.concept_space:
            return self.concept_space[concept]
        
        # ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹åŸ‹ã‚è¾¼ã¿
        hash_val = int(hashlib.md5(concept.encode()).hexdigest(), 16)
        rng = np.random.RandomState(hash_val % (2**32))
        embedding = rng.randn(128).astype(np.float32)
        embedding = embedding / np.linalg.norm(embedding)
        self.concept_space[concept] = embedding
        return embedding
    
    def find_analogies(self, concept: str, top_k: int = 5) -> List[Tuple[str, float]]:
        """é¡æ¨ã‚’ç™ºè¦‹"""
        if concept not in self.concept_space:
            self._embed_concept(concept)
        concept_vec = self.concept_space[concept]
        similarities = []
        for other_concept, other_vec in self.concept_space.items():
            if other_concept != concept:
                similarity = np.dot(concept_vec, other_vec)
                similarities.append((other_concept, float(similarity)))
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]

# ==================== äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚° ====================

class PredictiveQueryEngine:
    """äºˆæ¸¬çš„ã‚¯ã‚¨ãƒªç†è§£ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.model = PredictiveModel()
        self.query_history: deque = deque(maxlen=100)
    
    def add_query(self, query: str, intent: Intent, success: bool):
        """ã‚¯ã‚¨ãƒªã‚’å±¥æ­´ã«è¿½åŠ """
        self.query_history.append({
            'query': query,
            'intent': intent,
            'success': success,
            'timestamp': datetime.now()
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ›´æ–°
        hour = datetime.now().hour
        day = datetime.now().weekday()
        pattern_key = f"{intent.value}_{hour}_{day}"
        if pattern_key not in self.model.user_patterns:
            self.model.user_patterns[pattern_key] = []
        self.model.user_patterns[pattern_key].append(1.0 if success else 0.0)
    
    def predict_next_intent(self) -> Intent:
        """æ¬¡ã®æ„å›³ã‚’äºˆæ¸¬"""
        if len(self.query_history) < 3:
            return Intent.QUESTION
        # æœ€è¿‘ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰äºˆæ¸¬
        recent_intents = [q['intent'] for q in list(self.query_history)[-5:]]
        intent_counts = Counter(recent_intents)
        most_common = intent_counts.most_common(1)[0][0]
        return most_common
        
        def get_success_probability(self, intent: Intent) -> float:
        """æˆåŠŸç¢ºç‡ã‚’äºˆæ¸¬"""
        hour = datetime.now().hour
        day = datetime.now().weekday()
        pattern_key = f"{intent.value}_{hour}_{day}"
        
        if pattern_key in self.model.user_patterns:
            results = self.model.user_patterns[pattern_key]
            if results:
                return statistics.mean(results)
        return 0.5

# ==================== ç§‘å­¦çš„æ‰‹æ³•é©ç”¨ã‚·ã‚¹ãƒ†ãƒ  ====================

class ScientificMethodEngine:
    """ç§‘å­¦çš„æ‰‹æ³•ã‚’é©ç”¨ã—ãŸæ¨è«–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.experiments: List[Dict] = []
        self.hypotheses: List[Hypothesis] = []
    
    def formulate_hypothesis(self, observation: str, context: str = "") -> Hypothesis:
        """è¦³å¯Ÿã‹ã‚‰ä»®èª¬ã‚’å®šå¼åŒ–"""
        hypothesis_statement = f"Based on '{observation}', we hypothesize that there is a relationship with {context}"
        
        hypothesis = Hypothesis(
            id=str(uuid.uuid4())[:8],
            statement=hypothesis_statement,
            confidence=0.5,
            bayesian_prior=0.5
        )
        self.hypotheses.append(hypothesis)
        return hypothesis
    
    def design_experiment(self, hypothesis: Hypothesis) -> Dict:
        """å®Ÿé¨“ã‚’è¨­è¨ˆ"""
        experiment = {
            'id': str(uuid.uuid4())[:8],
            'hypothesis_id': hypothesis.id,
            'method': 'observational',  # or 'experimental'
            'variables': {
                'independent': [],
                'dependent': [],
                'control': []
            },
            'predictions': [],
            'status': 'designed',
            'created': datetime.now()
        }
        self.experiments.append(experiment)
        return experiment
    
    def analyze_results(self, experiment_id: str, data: Dict) -> Dict:
        """çµæœã‚’åˆ†æ"""
        analysis = {
            'experiment_id': experiment_id,
            'statistical_significance': np.random.random(),  # ç°¡æ˜“ç‰ˆ
            'effect_size': np.random.random(),
            'confidence_interval': (0.4, 0.8),
            'conclusion': 'Results support the hypothesis',
            'timestamp': datetime.now()
        }
        return analysis
    
    def peer_review(self, hypothesis: Hypothesis, reviews: List[str]) -> float:
        """ãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
        # ç°¡æ˜“çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¹ã‚³ã‚¢
        positive_words = ['valid', 'sound', 'rigorous', 'excellent']
        negative_words = ['flawed', 'weak', 'insufficient', 'poor']
        scores = []
        for review in reviews:
            review_lower = review.lower()
            pos_count = sum(1 for w in positive_words if w in review_lower)
            neg_count = sum(1 for w in negative_words if w in review_lower)
            
            score = (pos_count - neg_count + 3) / 6  # æ­£è¦åŒ–
            scores.append(max(0, min(1, score)))
        return statistics.mean(scores) if scores else 0.5


# ==================== çŸ¥è­˜ã‚°ãƒ©ãƒ• ====================

class AdvancedKnowledgeGraph:
    """é«˜åº¦ãªçŸ¥è­˜ã‚°ãƒ©ãƒ•"""
    
    def __init__(self):
        self.nodes: Dict[str, KnowledgeNode] = {}
        self.edges: List[KnowledgeEdge] = []
        self.communities: Dict[str, Set[str]] = {}  # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
    
    def add_node(self, node: KnowledgeNode):
        """ãƒãƒ¼ãƒ‰è¿½åŠ """
        node.updated = datetime.now()
        if node.id in self.nodes:
            node.access_count = self.nodes[node.id].access_count + 1
        self.nodes[node.id] = node
    
    def add_edge(self, edge: KnowledgeEdge):
        """ã‚¨ãƒƒã‚¸è¿½åŠ """
        self.edges.append(edge)
    
    def get_neighbors(self, node_id: str, relation: Optional[str] = None) -> List[str]:
        """éš£æ¥ãƒãƒ¼ãƒ‰å–å¾—"""
        neighbors = []
        for edge in self.edges:
            if edge.source == node_id and (relation is None or edge.relation == relation):
                neighbors.append(edge.target)
            elif edge.target == node_id and (relation is None or edge.relation == relation):
                neighbors.append(edge.source)
        return neighbors
    
    def find_communities(self) -> Dict[str, Set[str]]:
        """ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not self.nodes:
            return {}
        
        # é€£çµæˆåˆ†ã®æ¤œå‡º
        visited = set()
        communities = {}
        community_id = 0
        def dfs(node_id: str, community: Set[str]):
            visited.add(node_id)
            community.add(node_id)
            for neighbor in self.get_neighbors(node_id):
                if neighbor not in visited:
                    dfs(neighbor, community)
        for node_id in self.nodes:
            if node_id not in visited:
                community = set()
                dfs(node_id, community)
                communities[f"community_{community_id}"] = community
                community_id += 1
        self.communities = communities
        return communities
    
    def get_central_nodes(self, top_k: int = 5) -> List[Tuple[str, float]]:
        """ä¸­å¿ƒæ€§ã®é«˜ã„ãƒãƒ¼ãƒ‰å–å¾—"""
        # æ¬¡æ•°ä¸­å¿ƒæ€§
        degree_centrality = {}
        for node_id in self.nodes:
            degree = len(self.get_neighbors(node_id))
            degree_centrality[node_id] = degree
        sorted_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)
        return sorted_nodes[:top_k]
    def query_subgraph(self, query: str, depth: int = 2) -> Dict[str, Any]:
        """ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’å–å¾—"""
        # ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡º
        query_words = set(re.findall(r'\b\w+\b', query.lower()))
        
        # é–¢é€£ãƒãƒ¼ãƒ‰ã‚’æ¤œç´¢
        relevant_nodes = []
        for node_id, node in self.nodes.items():
            node_words = set(re.findall(r'\b\w+\b', node.name.lower()))
            overlap = len(query_words & node_words)
            if overlap > 0:
                node.relevance_score = overlap / len(query_words)
                relevant_nodes.append(node_id)
        if not relevant_nodes:
            return {'nodes': [], 'edges': []}
        
        # ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’å±•é–‹
        subgraph_nodes = set(relevant_nodes)
        for _ in range(depth):
            new_nodes = set()
            for node_id in list(subgraph_nodes):
                new_nodes.update(self.get_neighbors(node_id))
            subgraph_nodes.update(new_nodes)
        subgraph_edges = [
            e for e in self.edges
            if e.source in subgraph_nodes and e.target in subgraph_nodes
        ]
        return {
            'nodes': [self.nodes[nid] for nid in subgraph_nodes],
            'edges': subgraph_edges,
            'central_node': relevant_nodes[0] if relevant_nodes else None
        }


# ==================== ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  ====================

class QuantumLLM:
    """Quantum-Enhanced LLM System v3.5 ULTIMATE"""
    MODELS = {
        'llama-3.1-8b-instant': {'cost': 'low', 'quality': 'medium', 'speed': 'fast'},
        'llama-3.1-70b-versatile': {'cost': 'medium', 'quality': 'high', 'speed': 'medium'},
        'llama-3.3-70b-versatile': {'cost': 'medium', 'quality': 'high', 'speed': 'medium'},
    }
    
    def __init__(self, api_key: Optional[str] = None, config: Optional[SystemConfig] = None):
        self.api_key = api_key or os.environ.get('GROQ_API_KEY')
        if not self.api_key:
            raise ValueError("âŒ GROQ_API_KEY required")
        self.config = config or SystemConfig()
        self.client = Groq(api_key=self.api_key)
        
        # ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.vector_db = VectorDB(self.config.vec_dim) if self.config.vec_db else None
        self.knowledge_graph = AdvancedKnowledgeGraph() if self.config.knowledge_graph else None
        
        # é«˜åº¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.quantum_optimizer = QuantumOptimizer(self.config.quantum) if self.config.quantum.enabled else None
        self.genetic_evolver = GeneticPromptEvolver(self.config.genetic) if self.config.genetic.enabled else None
        self.swarm = SwarmIntelligence(self.config.swarm) if self.config.swarm.enabled else None
        self.rlhf = RLHFTrainer(self.config.rlhf) if self.config.rlhf.enabled else None
        
        # ç©¶æ¥µã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.causal_engine = CausalInferenceEngine() if self.config.causal_reasoning else None
        self.adversarial_tester = AdversarialTester() if self.config.adversarial_testing else None
        self.verification_system = VerificationSystem() if self.config.verification_system else None
        self.creative_synthesizer = CreativeSynthesizer() if self.config.creative_synthesis else None
        self.predictive_engine = PredictiveQueryEngine() if self.config.predictive_modeling else None
        self.scientific_method = ScientificMethodEngine() if self.config.scientific_method else None
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        self.profile = self._init_profile()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.metrics = {
            'queries': 0,
            'success': 0,
            'total_cost': 0,
            'total_tokens': 0,
            'cache_hits': 0,
            'quantum_optimizations': 0,
            'genetic_evolutions': 0,
            'swarm_optimizations': 0,
            'hypotheses_tested': 0,
            'adversarial_tests': 0,
            'verifications': 0,
            'causal_inferences': 0,
            'creative_syntheses': 0,
            'predictions': 0,
            'scientific_experiments': 0
        }
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        self.context_window = deque(maxlen=20)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†å›£ã®åˆæœŸåŒ–
        if self.genetic_evolver:
            base_prompts = [
                "Provide a clear and comprehensive answer.",
                "Think step by step and explain your reasoning.",
                "Analyze the question from multiple perspectives.",
                "Apply scientific method to validate your response.",
                "Consider causal relationships and logical implications."
            ]
            self.genetic_evolver.initialize_population(base_prompts, "general")
        logger.info(f"âœ… Quantum-Enhanced LLM v3.5 ULTIMATE initialized")
        self._log_features()
    
    def _init_profile(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–"""
        return {
            'topics': defaultdict(int),
            'expertise': defaultdict(float),
            'strategy_preference': defaultdict(float),
            'interaction_count': 0,
            'feedback_history': [],
            'learning_trajectory': [],
            'prediction_accuracy': 0.5
        }
    
    def _log_features(self):
        """æœ‰åŠ¹æ©Ÿèƒ½ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        features = []
        if self.config.quantum.enabled:
            features.append("ğŸ”®Quantum")
        if self.config.genetic.enabled:
            features.append("ğŸ§¬Genetic")
        if self.config.swarm.enabled:
            features.append("ğŸŒŠSwarm")
        if self.config.rlhf.enabled:
            features.append("ğŸ¯RLHF")
        if self.config.causal_reasoning:
            features.append("ğŸ§©Causal")
        if self.config.adversarial_testing:
            features.append("ğŸªAdversarial")
        if self.config.verification_system:
            features.append("ğŸ”Verify")
        if self.config.creative_synthesis:
            features.append("ğŸ¨Creative")
        if self.config.predictive_modeling:
            features.append("ğŸ”®Predict")
        if self.config.scientific_method:
            features.append("ğŸ”¬Scientific")
        logger.info(" | ".join(features))
    
    async def query_async(self, query: str, **kwargs) -> Response:
        """ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªå‡¦ç†ï¼ˆéåŒæœŸï¼‰- ç©¶æ¥µç‰ˆ"""
        self.metrics['queries'] += 1
        try:
            # äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
            if self.predictive_engine:
                predicted_intent = self.predictive_engine.predict_next_intent()
                logger.debug(f"ğŸ”® Predicted intent: {predicted_intent.value}")
                self.metrics['predictions'] += 1
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if self.vector_db:
                cached_results = self.vector_db.search(query, top_k=1, min_similarity=self.config.similarity_threshold)
                if cached_results:
                    _, similarity, metadata = cached_results[0]
                    if time.time() - metadata.get('added_at', 0) < self.config.cache_ttl:
                        self.metrics['cache_hits'] += 1
                        logger.info(f"ğŸ”„ Cache hit: {similarity:.3f}")
                        resp_data = metadata.get('response', {})
                        return Response(
                            text=resp_data.get('text', ''),
                            confidence=resp_data.get('confidence', 0),
                            cached=True,
                            similarity=similarity,
                            **{k: v for k, v in resp_data.items() if k not in ['text', 'confidence']}
                        )
            
            # ã‚¯ã‚¨ãƒªåˆ†æ
            intent, complexity = self._analyze_query(query)
            strategy = self._select_strategy(intent, complexity)
            model = kwargs.get('model', self.config.model)
            
            # ç§‘å­¦çš„æ‰‹æ³•ã®é©ç”¨
            if self.scientific_method and complexity >= Complexity.RESEARCH:
                hypothesis = self.scientific_method.formulate_hypothesis(query)
                logger.info(f"ğŸ”¬ Hypothesis formulated: {hypothesis.statement[:50]}...")
                self.metrics['scientific_experiments'] += 1
            
            # æˆ¦ç•¥å®Ÿè¡Œ
            if strategy == Strategy.QUANTUM and self.quantum_optimizer:
                response = await self._execute_quantum_strategy(query, model, intent, complexity)
            elif strategy == Strategy.GENETIC and self.genetic_evolver:
                response = await self._execute_genetic_strategy(query, model, intent, complexity)
            elif strategy == Strategy.SWARM and self.swarm:
                response = await self._execute_swarm_strategy(query, model, intent, complexity)
            else:
                response = await self._execute_direct(query, model, intent, complexity)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®š
            response.intent = intent
            response.complexity = complexity
            
            # å› æœæ¨è«–ã®é©ç”¨
            if self.causal_engine and 'why' in query.lower():
                causes = self.causal_engine.infer_cause(query, depth=2)
                if causes:
                    logger.info(f"ğŸ§© Causal inference: {len(causes)} potential causes identified")
                    self.metrics['causal_inferences'] += 1
                    response.reasoning_steps.extend([f"Cause: {c[0]} (p={c[1]:.2f})" for c in causes[:3]])
            
            # æ¤œè¨¼
            if self.verification_system:
                verification = self.verification_system.verify_claim(
                    response.text[:200],
                    context=query,
                    method=VerificationMethod.LOGICAL_CONSISTENCY
                )
                response.confidence = response.confidence * verification.confidence
                self.metrics['verifications'] += 1
                logger.debug(f"ğŸ” Verification: {verification.confidence:.2f}")
            
            # æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.adversarial_tester and self.config.adversarial_testing and np.random.random() < 0.1:
                adversarial_test = await self.adversarial_tester.test_consistency(
                    lambda q: self.query_async(q),
                    query,
                    response.text
                )
                self.metrics['adversarial_tests'] += 1
                if adversarial_test.vulnerability_detected:
                    logger.warning(f"ğŸª Adversarial vulnerability detected! Consistency: {adversarial_test.consistency_score:.2f}")
                    response.uncertainty += 0.1
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            if response.success:
                self.metrics['success'] += 1
            self.metrics['total_cost'] += response.cost
            self.metrics['total_tokens'] += response.tokens
            
            # RLHFæ›´æ–°
            if self.rlhf:
                state = self.rlhf.get_state(intent, complexity)
                reward = response.quality_score
                next_state = state
                self.rlhf.update(state, strategy.value, reward, next_state)
            
            # äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³æ›´æ–°
            if self.predictive_engine:
                self.predictive_engine.add_query(query, intent, response.success)
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ›´æ–°
            self.context_window.append(query[:100])
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            if self.vector_db and response.success:
                self.vector_db.add(
                    str(uuid.uuid4())[:8],
                    query,
                    {'response': response.to_dict()}
                )
            
            # çŸ¥è­˜ã‚°ãƒ©ãƒ•æ›´æ–°
            if self.knowledge_graph:
                self._update_knowledge_graph(query, response.text)
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’
            if self.config.real_time_learning:
                self._update_learning_trajectory(query, response)
            return response
        except Exception as e:
            logger.error(f"Query failed: {e}")
            return Response(
                text=f"âŒ Error: {str(e)}",
                confidence=0,
                finish_reason="error"
            )
    
    def _update_learning_trajectory(self, query: str, response: Response):
        """å­¦ç¿’è»Œè·¡ã‚’æ›´æ–°"""
        self.profile['learning_trajectory'].append({
            'query': query[:100],
            'quality': response.quality_score,
            'strategy': response.strategy.value if response.strategy else None,
            'complexity': response.complexity.value if response.complexity else None,
            'timestamp': datetime.now().isoformat()
        })
        
        # æœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
        if len(self.profile['learning_trajectory']) > 1000:
            self.profile['learning_trajectory'] = self.profile['learning_trajectory'][-1000:]
    
    def get_stats(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±å–å¾— - æ‹¡å¼µç‰ˆ"""
        stats = {
            'system': {
                'queries': self.metrics['queries'],
                'success_rate': f"{self.metrics['success'] / max(self.metrics['queries'], 1):.1%}",
                'cache_hit_rate': f"{self.metrics['cache_hits'] / max(self.metrics['queries'], 1):.1%}",
                'total_cost': f"${self.metrics['total_cost']:.6f}",
                'avg_cost': f"${self.metrics['total_cost'] / max(self.metrics['queries'], 1):.6f}"
            },
            'advanced': {
                'quantum_optimizations': self.metrics['quantum_optimizations'],
                'genetic_evolutions': self.metrics['genetic_evolutions'],
                'swarm_optimizations': self.metrics['swarm_optimizations'],
                'hypotheses_tested': self.metrics['hypotheses_tested']
            },
            'ultimate': {
                'adversarial_tests': self.metrics['adversarial_tests'],
                'verifications': self.metrics['verifications'],
                'causal_inferences': self.metrics['causal_inferences'],
                'creative_syntheses': self.metrics['creative_syntheses'],
                'predictions': self.metrics['predictions'],
                'scientific_experiments': self.metrics['scientific_experiments']
            },
            'profile': {
                'interactions': self.profile['interaction_count'],
                'top_topics': sorted(self.profile['topics'].items(), key=lambda x: x[1], reverse=True)[:5],
                'expertise_areas': len([e for e in self.profile['expertise'].values() if e > 0.5]),
                'learning_trajectory_size': len(self.profile.get('learning_trajectory', [])),
                'prediction_accuracy': self.profile.get('prediction_accuracy', 0.5)
            }
        }
        
        # çŸ¥è­˜ã‚°ãƒ©ãƒ•çµ±è¨ˆ
        if self.knowledge_graph:
            stats['knowledge_graph'] = {
                'nodes': len(self.knowledge_graph.nodes),
                'edges': len(self.knowledge_graph.edges),
                'communities': len(self.knowledge_graph.communities)
            }
        
        # éºä¼çš„é€²åŒ–çµ±è¨ˆ
        if self.genetic_evolver:
            best_prompts = self.genetic_evolver.get_best_prompts(3)
            stats['genetic'] = {
                'generation': self.genetic_evolver.generation,
                'population_size': len(self.genetic_evolver.population),
                'best_fitness': best_prompts[0].fitness if best_prompts else 0
            }
        
        # RLHFçµ±è¨ˆ
        if self.rlhf:
            stats['rlhf'] = {
                'states_explored': len(self.rlhf.state_visits),
                'total_updates': sum(self.rlhf.state_visits.values()),
                'avg_reward': statistics.mean(self.rlhf.reward_history) if self.rlhf.reward_history else 0
            }
        
        # å› æœæ¨è«–çµ±è¨ˆ
        if self.causal_engine:
            stats['causal'] = {
                'causal_nodes': len(self.causal_engine.causal_graph),
                'interventions': len(self.causal_engine.interventions)
            }
        
        # æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆçµ±è¨ˆ
        if self.adversarial_tester:
            stats['adversarial'] = {
                'total_tests': len(self.adversarial_tester.tests),
                'vulnerabilities': sum(self.adversarial_tester.vulnerabilities.values()),
                'avg_consistency': statistics.mean(
                    t.consistency_score for t in self.adversarial_tester.tests
                ) if self.adversarial_tester.tests else 0
            }
        
        # æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        if self.verification_system:
            stats['verification'] = {
                'total_verifications': len(self.verification_system.records),
                'trust_score': self.verification_system.get_trust_score(),
                'verified_claims': sum(1 for r in self.verification_system.records if r.result)
            }
        
        # å‰µé€ çš„çµ±åˆçµ±è¨ˆ
        if self.creative_synthesizer:
            stats['creative'] = {
                'syntheses': len(self.creative_synthesizer.syntheses),
                'avg_novelty': statistics.mean(
                    s.novelty_score for s in self.creative_synthesizer.syntheses
                ) if self.creative_synthesizer.syntheses else 0
            }
        return stats
    
    def analyze_learning_progress(self) -> Dict:
        """å­¦ç¿’é€²æ—ã‚’åˆ†æ"""
        trajectory = self.profile.get('learning_trajectory', [])
        if len(trajectory) < 10:
            return {'status': 'insufficient_data'}
        
        # æ™‚ç³»åˆ—åˆ†æ
        recent = trajectory[-50:]
        older = trajectory[-100:-50] if len(trajectory) >= 100 else trajectory[:-50]
        recent_quality = statistics.mean(t['quality'] for t in recent)
        older_quality = statistics.mean(t['quality'] for t in older) if older else recent_quality
        improvement = recent_quality - older_quality
        
        # æˆ¦ç•¥åŠ¹æœåˆ†æ
        strategy_performance = defaultdict(list)
        for t in trajectory:
            if t.get('strategy'):
                strategy_performance[t['strategy']].append(t['quality'])
        best_strategy = max(
            strategy_performance.items(),
            key=lambda x: statistics.mean(x[1]) if x[1] else 0
        )[0] if strategy_performance else None
        return {
            'status': 'analyzed',
            'total_interactions': len(trajectory),
            'recent_quality': recent_quality,
            'improvement': improvement,
            'trend': 'improving' if improvement > 0.05 else 'declining' if improvement < -0.05 else 'stable',
            'best_strategy': best_strategy,
            'strategy_performance': {
                k: statistics.mean(v) for k, v in strategy_performance.items() if v
            }
        }
    
    def generate_meta_insights(self) -> List[str]:
        """ãƒ¡ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ"""
        insights = []
        
        # å­¦ç¿’é€²æ—ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        progress = self.analyze_learning_progress()
        if progress['status'] == 'analyzed':
            if progress['trend'] == 'improving':
                insights.append(f"ğŸ“ˆ Learning trend: Improving (+{progress['improvement']:.3f})")
            elif progress['trend'] == 'declining':
                insights.append(f"ğŸ“‰ Learning trend: Needs attention ({progress['improvement']:.3f})")
            if progress['best_strategy']:
                insights.append(f"ğŸ¯ Most effective strategy: {progress['best_strategy']}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        stats = self.get_stats()
        
        if 'ultimate' in stats:
            ultimate = stats['ultimate']
            if ultimate['adversarial_tests'] > 10:
                if 'adversarial' in stats:
                    consistency = stats['adversarial']['avg_consistency']
                    if consistency > 0.8:
                        insights.append(f"âœ… High adversarial robustness ({consistency:.2f})")
                    else:
                        insights.append(f"âš ï¸  Adversarial vulnerabilities detected ({consistency:.2f})")
            if ultimate['verifications'] > 20:
                if 'verification' in stats:
                    trust = stats['verification']['trust_score']
                    if trust > 0.8:
                        insights.append(f"ğŸ” High trust score ({trust:.2f})")
        
        # äºˆæ¸¬ç²¾åº¦
        if self.predictive_engine and len(self.predictive_engine.query_history) > 20:
            accuracy = self.profile.get('prediction_accuracy', 0.5)
            if accuracy > 0.7:
                insights.append(f"ğŸ”® Prediction system learning well ({accuracy:.2%})")
        
        # çŸ¥è­˜ã‚°ãƒ©ãƒ•æˆé•·
        if self.knowledge_graph and len(self.knowledge_graph.nodes) > 100:
            growth_rate = len(self.knowledge_graph.nodes) / max(self.metrics['queries'], 1)
            insights.append(f"ğŸ§© Knowledge graph: {len(self.knowledge_graph.nodes)} concepts (growth: {growth_rate:.1f}/query)")
        return insights
    
    def _analyze_query(self, query: str) -> Tuple[Intent, Complexity]:
        """ã‚¯ã‚¨ãƒªã‚’åˆ†æ"""
        q = query.lower()
        
        # æ„å›³åˆ†æ
        intent_patterns = {
            Intent.REASONING: ['why', 'because', 'reason', 'cause'],
            Intent.ANALYSIS: ['analyze', 'compare', 'evaluate', 'assess'],
            Intent.RESEARCH: ['research', 'investigate', 'study', 'explore'],
            Intent.PLANNING: ['plan', 'strategy', 'organize', 'schedule'],
            Intent.TECHNICAL: ['code', 'algorithm', 'implement', 'debug'],
            Intent.CREATIVE: ['create', 'write', 'design', 'imagine'],
            Intent.DEBUGGING: ['bug', 'error', 'fix', 'debug', 'issue'],
            Intent.OPTIMIZATION: ['optimize', 'improve', 'enhance', 'better']
        }
        intent = Intent.QUESTION
        max_matches = 0
        for int_type, patterns in intent_patterns.items():
            matches = sum(1 for p in patterns if p in q)
            if matches > max_matches:
                max_matches = matches
                intent = int_type
        
        # è¤‡é›‘åº¦åˆ†æ
        complexity_score = 0
        complexity_score += len(query) // 100
        complexity_score += q.count('?')
        frontier_words = ['breakthrough', 'novel', 'unprecedented', 'cutting-edge']
        research_words = ['hypothesis', 'theory', 'prove', 'demonstrate']
        expert_words = ['advanced', 'sophisticated', 'complex', 'intricate']
        complexity_score += sum(5 for w in frontier_words if w in q)
        complexity_score += sum(4 for w in research_words if w in q)
        complexity_score += sum(3 for w in expert_words if w in q)
        if complexity_score < 2:
            complexity = Complexity.TRIVIAL
        elif complexity_score < 4:
            complexity = Complexity.SIMPLE
        elif complexity_score < 7:
            complexity = Complexity.MEDIUM
        elif complexity_score < 11:
            complexity = Complexity.COMPLEX
        elif complexity_score < 16:
            complexity = Complexity.EXPERT
        elif complexity_score < 20:
            complexity = Complexity.RESEARCH
        else:
            complexity = Complexity.FRONTIER
        return intent, complexity
    
    def _select_strategy(self, intent: Intent, complexity: Complexity) -> Strategy:
        """æˆ¦ç•¥é¸æŠ"""
        # ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¬ãƒ™ãƒ«: é‡å­æœ€é©åŒ–
        if complexity == Complexity.FRONTIER and self.config.quantum.enabled:
            return Strategy.QUANTUM
        
        # ç ”ç©¶ãƒ¬ãƒ™ãƒ«: éºä¼çš„é€²åŒ–
        if complexity == Complexity.RESEARCH and self.config.genetic.enabled:
            return Strategy.GENETIC
        
        # è¤‡é›‘ãªæ¨è«–: ç¾¤çŸ¥èƒ½
        if complexity in [Complexity.EXPERT, Complexity.COMPLEX] and self.config.swarm.enabled:
            return Strategy.SWARM
        
        # åˆ†æãƒ»æ¨è«–: Tree of Thoughts
        if intent in [Intent.ANALYSIS, Intent.REASONING] and self.config.tree_of_thoughts:
            return Strategy.TREE_SEARCH
        
        # è¨è«–ãŒæœ‰åŠ¹ãªå ´åˆ
        if complexity in [Complexity.EXPERT, Complexity.RESEARCH] and self.config.debate_mode:
            return Strategy.DEBATE
        
        # Chain of Thought
        if complexity >= Complexity.COMPLEX and self.config.chain_of_thought:
            return Strategy.COT
        
        # RLHFæ¨å¥¨ãŒã‚ã‚‹å ´åˆ
        if self.rlhf:
            state = self.rlhf.get_state(intent, complexity)
            available_strategies = [s.value for s in Strategy]
            recommended = self.rlhf.select_action(state, available_strategies)
            try:
                return Strategy(recommended)
            except:
                pass
        return Strategy.DIRECT
    
    async def _call_api(
        self,
        model: str,
        messages: List[Dict],
        temperature: float,
        max_tokens: int
    ):
        """APIå‘¼ã³å‡ºã—"""
        for attempt in range(self.config.max_retries):
            try:
                return self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            except (RateLimitError, APIError) as e:
                if attempt == self.config.max_retries - 1:
                    raise
                wait_time = self.config.retry_delay * (2 ** attempt)
                logger.warning(f"Retry {attempt + 1}/{self.config.max_retries}")
                await asyncio.sleep(wait_time)
    
    def _build_system_prompt(
        self,
        query: str,
        intent: Intent,
        complexity: Complexity,
        strategy: Strategy
    ) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        base = "You are an advanced AI assistant with quantum-inspired reasoning capabilities."
        
        # æˆ¦ç•¥åˆ¥ã®æŒ‡ç¤º
        strategy_instructions = {
            Strategy.QUANTUM: "Use multi-dimensional thinking. Explore superposition of possibilities.",
            Strategy.GENETIC: "Evolve your answer through iterative refinement.",
            Strategy.SWARM: "Consider diverse perspectives and find consensus.",
            Strategy.COT: "Think step by step. Show your reasoning process.",
            Strategy.DEBATE: "Present multiple viewpoints and synthesize them.",
            Strategy.TREE_SEARCH: "Explore different reasoning paths systematically."
        }
        strategy_text = strategy_instructions.get(strategy, "")
        
        # è¤‡é›‘åº¦åˆ¥ã®èª¿æ•´
        if complexity in [Complexity.RESEARCH, Complexity.FRONTIER]:
            complexity_text = "Provide research-grade analysis with novel insights."
        elif complexity == Complexity.EXPERT:
            complexity_text = "Provide expert-level insights with technical depth."
        else:
            complexity_text = "Provide clear, well-structured answers."
        
        # çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        kg_context = ""
        if self.knowledge_graph:
            subgraph = self.knowledge_graph.query_subgraph(query, depth=1)
            if subgraph['nodes']:
                node_names = [n.name for n in subgraph['nodes'][:3]]
                kg_context = f" Related concepts: {', '.join(node_names)}."
        prompt = f"{base} {strategy_text} {complexity_text}{kg_context}"
        return prompt.strip()
    
    async def _execute_quantum_strategy(
        self,
        query: str,
        model: str,
        intent: Intent,
        complexity: Complexity
    ) -> Response:
        """é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢æˆ¦ç•¥"""
        logger.info("ğŸ”® Executing quantum-inspired optimization")
        self.metrics['quantum_optimizations'] += 1
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’é‡å­æœ€é©åŒ–
        def objective(params):
            temp, top_p, freq_penalty = params[0], params[1], params[2]
            # ç°¡æ˜“è©•ä¾¡é–¢æ•°ï¼ˆå®Ÿéš›ã¯å¿œç­”å“è³ªã§è©•ä¾¡ï¼‰
            score = 1.0 - abs(temp - 0.7) - abs(top_p - 0.9) - abs(freq_penalty - 0.1)
            return score
        
        optimized_params, _ = self.quantum_optimizer.optimize_parameters(objective)
        temperature = float(optimized_params[0])
        system_prompt = self._build_system_prompt(query, intent, complexity, Strategy.QUANTUM)
        start_time = time.time()
        api_response = await self._call_api(
            model,
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            temperature,
            self.config.max_tokens
        )
        latency = (time.time() - start_time) * 1000
        response = self._build_response(api_response, model, Strategy.QUANTUM, latency)
        response.quantum_optimized = True
        return response
    
    async def _execute_genetic_strategy(
        self,
        query: str,
        model: str,
        intent: Intent,
        complexity: Complexity
    ) -> Response:
        """éºä¼çš„é€²åŒ–æˆ¦ç•¥"""
        logger.info("ğŸ§¬ Executing genetic evolution")
        self.metrics['genetic_evolutions'] += 1
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€²åŒ–ã•ã›ã‚‹
        def fitness_func(prompt: Prompt):
            # ç°¡æ˜“è©•ä¾¡ï¼ˆå®Ÿéš›ã¯å¿œç­”å“è³ªã§è©•ä¾¡ï¼‰
            return prompt.success_rate * 0.5 + prompt.avg_quality * 0.5
        for _ in range(3):  # 3ä¸–ä»£é€²åŒ–
            best_prompt = self.genetic_evolver.evolve(fitness_func)
        system_prompt = self._build_system_prompt(query, intent, complexity, Strategy.GENETIC)
        enhanced_query = f"{best_prompt.template}\n\n{query}"
        start_time = time.time()
        api_response = await self._call_api(
            model,
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": enhanced_query}
            ],
            0.7,
            self.config.max_tokens
        )
        latency = (time.time() - start_time) * 1000
        response = self._build_response(api_response, model, Strategy.GENETIC, latency)
        response.genetic_fitness = best_prompt.fitness
        return response
    
    async def _execute_swarm_strategy(
        self,
        query: str,
        model: str,
        intent: Intent,
        complexity: Complexity
    ) -> Response:
        """ç¾¤çŸ¥èƒ½æˆ¦ç•¥"""
        logger.info("ğŸŒŠ Executing swarm intelligence")
        self.metrics['swarm_optimizations'] += 1
        
        # å„ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ã®å¿œç­”ã‚’åé›†
        personas = [PersonaType.OPTIMIST, PersonaType.PESSIMIST, PersonaType.PRAGMATIST]
        responses = []
        for persona in personas:
            persona_prompt = f"As a {persona.value}, answer: {query}"
            system_prompt = self._build_system_prompt(query, intent, complexity, Strategy.SWARM)
            try:
                api_response = await self._call_api(
                    model,
                    [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": persona_prompt}
                    ],
                    0.7,
                    self.config.max_tokens // 2
                )
                text = api_response.choices[0].message.content or ""
                responses.append({
                    'persona': persona.value,
                    'text': text,
                    'confidence': 0.7 + np.random.random() * 0.2
                })
            except Exception as e:
                logger.warning(f"Swarm agent {persona.value} failed: {e}")
        if not responses:
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return await self._execute_direct(query, model, intent, complexity)
            
        # ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹åˆæˆ
        synthesis_prompt = f"Synthesize these perspectives:\n\n"
        for resp in responses:
            synthesis_prompt += f"{resp['persona']}: {resp['text'][:200]}...\n\n"
        synthesis_prompt += f"\nProvide a balanced synthesis answering: {query}"
        start_time = time.time()
        final_response = await self._call_api(
            model,
            [
                {"role": "system", "content": "Synthesize multiple perspectives into a coherent answer."},
                {"role": "user", "content": synthesis_prompt}
            ],
            0.7,
            self.config.max_tokens
        )
        latency = (time.time() - start_time) * 1000
        response = self._build_response(final_response, model, Strategy.SWARM, latency)
        response.personas_involved = [r['persona'] for r in responses]
        response.swarm_consensus = statistics.mean(r['confidence'] for r in responses)
        response.alternatives = [{'persona': r['persona'], 'text': r['text'][:100]} for r in responses]
        return response
        
    async def _execute_direct(
        self,
        query: str,
        model: str,
        intent: Intent,
        complexity: Complexity
    ) -> Response:
        """ç›´æ¥å®Ÿè¡Œ"""
        system_prompt = self._build_system_prompt(query, intent, complexity, Strategy.DIRECT)
        start_time = time.time()
        api_response = await self._call_api(
            model,
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            0.7,
            self.config.max_tokens
        )
        latency = (time.time() - start_time) * 1000
        return self._build_response(api_response, model, Strategy.DIRECT, latency)
    
    def _build_response(
        self,
        api_response,
        model: str,
        strategy: Strategy,
        latency: float
    ) -> Response:
        """å¿œç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹ç¯‰"""
        choice = api_response.choices[0]
        text = choice.message.content or ""
        usage = api_response.usage
        cost = self._calculate_cost(model, usage.prompt_tokens, usage.completion_tokens)
        
        # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        coherence = min(1.0, len(text.split('.')) / 10)
        relevance = 0.8
        completeness = min(1.0, len(text) / 500)
        factuality = 0.85
        novelty = 0.7 if strategy in [Strategy.QUANTUM, Strategy.GENETIC] else 0.5
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        base_confidence = 0.9 if choice.finish_reason == "stop" else 0.75
        uncertainty = sum(0.1 for phrase in ['maybe', 'perhaps', 'possibly'] if phrase in text.lower())
        confidence = max(0, min(1, base_confidence - uncertainty * 0.1))
        return Response(
            text=text,
            confidence=confidence,
            tokens=usage.total_tokens,
            prompt_tokens=usage.prompt_tokens,
            completion_tokens=usage.completion_tokens,
            latency=latency,
            cost=cost,
            model=model,
            finish_reason=choice.finish_reason,
            strategy=strategy,
            uncertainty=min(1.0, uncertainty),
            coherence_score=coherence,
            relevance_score=relevance,
            completeness_score=completeness,
            factuality_score=factuality,
            novelty_score=novelty
        )
    
    def _calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> float:
        """ã‚³ã‚¹ãƒˆè¨ˆç®—"""
        pricing = {
            'llama-3.1-8b-instant': {'input': 0.05 / 1e6, 'output': 0.08 / 1e6},
            'llama-3.1-70b-versatile': {'input': 0.59 / 1e6, 'output': 0.79 / 1e6},
            'llama-3.3-70b-versatile': {'input': 0.59 / 1e6, 'output': 0.79 / 1e6},
        }
        p = pricing.get(model, {'input': 0.0001 / 1e6, 'output': 0.0001 / 1e6})
        return prompt_tokens * p['input'] + completion_tokens * p['output']
    
    async def query_async(self, query: str, **kwargs) -> Response:
        """ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªå‡¦ç†ï¼ˆéåŒæœŸï¼‰"""
        self.metrics['queries'] += 1
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if self.vector_db:
                cached_results = self.vector_db.search(query, top_k=1, min_similarity=self.config.similarity_threshold)
                if cached_results:
                    _, similarity, metadata = cached_results[0]
                    if time.time() - metadata.get('added_at', 0) < self.config.cache_ttl:
                        self.metrics['cache_hits'] += 1
                        logger.info(f"ğŸ”„ Cache hit: {similarity:.3f}")
                        resp_data = metadata.get('response', {})
                        return Response(
                            text=resp_data.get('text', ''),
                            confidence=resp_data.get('confidence', 0),
                            cached=True,
                            similarity=similarity,
                            **{k: v for k, v in resp_data.items() if k not in ['text', 'confidence']}
                        )
            
            # ã‚¯ã‚¨ãƒªåˆ†æ
            intent, complexity = self._analyze_query(query)
            strategy = self._select_strategy(intent, complexity)
            model = kwargs.get('model', self.config.model)
            
            # æˆ¦ç•¥å®Ÿè¡Œ
            if strategy == Strategy.QUANTUM and self.quantum_optimizer:
                response = await self._execute_quantum_strategy(query, model, intent, complexity)
            elif strategy == Strategy.GENETIC and self.genetic_evolver:
                response = await self._execute_genetic_strategy(query, model, intent, complexity)
            elif strategy == Strategy.SWARM and self.swarm:
                response = await self._execute_swarm_strategy(query, model, intent, complexity)
            else:
                response = await self._execute_direct(query, model, intent, complexity)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®š
            response.intent = intent
            response.complexity = complexity
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            if response.success:
                self.metrics['success'] += 1
            self.metrics['total_cost'] += response.cost
            self.metrics['total_tokens'] += response.tokens
            
            # RLHFæ›´æ–°
            if self.rlhf:
                state = self.rlhf.get_state(intent, complexity)
                reward = response.quality_score
                next_state = state  # ç°¡æ˜“ç‰ˆ
                self.rlhf.update(state, strategy.value, reward, next_state)
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ›´æ–°
            self.context_window.append(query[:100])
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            if self.vector_db and response.success:
                self.vector_db.add(
                    str(uuid.uuid4())[:8],
                    query,
                    {'response': response.to_dict()}
                )
            
            # çŸ¥è­˜ã‚°ãƒ©ãƒ•æ›´æ–°
            if self.knowledge_graph:
                self._update_knowledge_graph(query, response.text)
            return response
        except Exception as e:
            logger.error(f"Query failed: {e}")
            return Response(
                text=f"âŒ Error: {str(e)}",
                confidence=0,
                finish_reason="error"
            )
    
    def query(self, query: str, **kwargs) -> Response:
        """ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªå‡¦ç†ï¼ˆåŒæœŸï¼‰"""
        return asyncio.run(self.query_async(query, **kwargs))
    
    def _update_knowledge_graph(self, query: str, response: str):
        """çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æ›´æ–°"""
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        entities = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', response)
        for entity in set(entities[:5]):
            node_id = hashlib.md5(entity.encode()).hexdigest()[:8]
            node = KnowledgeNode(
                id=node_id,
                name=entity,
                type='entity',
                properties={'source': 'response'}
            )
            self.knowledge_graph.add_node(node)
        
        # é–¢ä¿‚æŠ½å‡ºï¼ˆéš£æ¥ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ï¼‰
        for i in range(len(entities) - 1):
            source_id = hashlib.md5(entities[i].encode()).hexdigest()[:8]
            target_id = hashlib.md5(entities[i + 1].encode()).hexdigest()[:8]
            
            if source_id in self.knowledge_graph.nodes and target_id in self.knowledge_graph.nodes:
                edge = KnowledgeEdge(
                    source=source_id,
                    target=target_id,
                    relation='mentioned_with',
                    weight=0.5
                )
                self.knowledge_graph.add_edge(edge)
    
    def add_feedback(self, query: str, response: str, rating: int, response_obj: Optional[Response] = None):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¿½åŠ """
        self.profile['interaction_count'] += 1
        self.profile['feedback_history'].append({
            'query': query[:100],
            'response': response[:100],
            'rating': rating,
            'timestamp': datetime.now().isoformat()
        })
        
        # ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°
        words = re.findall(r'\b\w{4,}\b', query.lower())
        for word in words:
            self.profile['topics'][word] += rating
            if rating > 0:
                self.profile['expertise'][word] = min(1.0, self.profile['expertise'][word] + 0.1)
        
        # æˆ¦ç•¥å¥½ã¿æ›´æ–°
        if response_obj and response_obj.strategy:
            current = self.profile['strategy_preference'][response_obj.strategy.value]
            self.profile['strategy_preference'][response_obj.strategy.value] = current + rating * 0.1
        
        # éºä¼çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ›´æ–°
        if self.genetic_evolver and response_obj:
            for prompt in self.genetic_evolver.population:
                if prompt.usage_count > 0:
                    if rating > 0:
                        prompt.success_count += 1
                    prompt.avg_quality = (prompt.avg_quality * (prompt.usage_count - 1) + abs(rating)) / prompt.usage_count
                    prompt.fitness = prompt.success_rate * 0.5 + prompt.avg_quality * 0.5
        logger.info(f"ğŸ¯ Feedback: {rating:+d} | Strategy: {response_obj.strategy if response_obj else 'N/A'}")
    
    def get_stats(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        stats = {
            'system': {
                'queries': self.metrics['queries'],
                'success_rate': f"{self.metrics['success'] / max(self.metrics['queries'], 1):.1%}",
                'cache_hit_rate': f"{self.metrics['cache_hits'] / max(self.metrics['queries'], 1):.1%}",
                'total_cost': f"${self.metrics['total_cost']:.6f}",
                'avg_cost': f"${self.metrics['total_cost'] / max(self.metrics['queries'], 1):.6f}"
            },
            'advanced': {
                'quantum_optimizations': self.metrics['quantum_optimizations'],
                'genetic_evolutions': self.metrics['genetic_evolutions'],
                'swarm_optimizations': self.metrics['swarm_optimizations'],
                'hypotheses_tested': self.metrics['hypotheses_tested']
            },
            'profile': {
                'interactions': self.profile['interaction_count'],
                'top_topics': sorted(self.profile['topics'].items(), key=lambda x: x[1], reverse=True)[:5],
                'expertise_areas': len([e for e in self.profile['expertise'].values() if e > 0.5])
            }
        }
        
        # çŸ¥è­˜ã‚°ãƒ©ãƒ•çµ±è¨ˆ
        if self.knowledge_graph:
            stats['knowledge_graph'] = {
                'nodes': len(self.knowledge_graph.nodes),
                'edges': len(self.knowledge_graph.edges),
                'communities': len(self.knowledge_graph.communities)
            }
        
        # éºä¼çš„é€²åŒ–çµ±è¨ˆ
        if self.genetic_evolver:
            best_prompts = self.genetic_evolver.get_best_prompts(3)
            stats['genetic'] = {
                'generation': self.genetic_evolver.generation,
                'population_size': len(self.genetic_evolver.population),
                'best_fitness': best_prompts[0].fitness if best_prompts else 0
            }
        
        # RLHFçµ±è¨ˆ
        if self.rlhf:
            stats['rlhf'] = {
                'states_explored': len(self.rlhf.state_visits),
                'total_updates': sum(self.rlhf.state_visits.values()),
                'avg_reward': statistics.mean(self.rlhf.reward_history) if self.rlhf.reward_history else 0
            }
        return stats
    
    def save_state(self, filepath: str = 'quantum_llm_state.json'):
        """çŠ¶æ…‹ä¿å­˜"""
        try:
            state = {
                'profile': {
                    'topics': dict(self.profile['topics']),
                    'expertise': dict(self.profile['expertise']),
                    'strategy_preference': dict(self.profile['strategy_preference']),
                    'interaction_count': self.profile['interaction_count'],
                    'feedback_history': self.profile['feedback_history']
                },
                'metrics': self.metrics,
                'timestamp': datetime.now().isoformat()
            }
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(state, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ State saved: {filepath}")
        except Exception as e:
            logger.error(f"âŒ Save failed: {e}")
    
    def load_state(self, filepath: str = 'quantum_llm_state.json'):
        """çŠ¶æ…‹èª­ã¿è¾¼ã¿"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                state = json.load(f)
            profile_data = state.get('profile', {})
            self.profile['topics'] = defaultdict(int, profile_data.get('topics', {}))
            self.profile['expertise'] = defaultdict(float, profile_data.get('expertise', {}))
            self.profile['strategy_preference'] = defaultdict(float, profile_data.get('strategy_preference', {}))
            self.profile['interaction_count'] = profile_data.get('interaction_count', 0)
            self.profile['feedback_history'] = profile_data.get('feedback_history', [])
            self.metrics.update(state.get('metrics', {}))
            logger.info(f"ğŸ“‚ State loaded: {filepath}")
        except FileNotFoundError:
            logger.info("â„¹ï¸  No saved state found")
        except Exception as e:
            logger.error(f"âŒ Load failed: {e}")


# ==================== ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆ ====================

class QuantumChat:
    """é‡å­ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self, llm: QuantumLLM):
        self.llm = llm
        self.history: List[Tuple[str, Response]] = []
        self.session_id = str(uuid.uuid4())[:8]
    
    def print_welcome(self):
        """ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
        print("\n" + "=" * 80)
        print("ğŸ”® Quantum-Enhanced Self-Evolving LLM System v3.0Î³")
        print("=" * 80)
        print("\nâœ¨ é©æ–°çš„æ©Ÿèƒ½:")
        print("  ğŸ”® Quantum-Inspired Optimization")
        print("  ğŸ§¬ Genetic Algorithm for Prompt Evolution")
        print("  ğŸŒŠ Swarm Intelligence Multi-Agent System")
        print("  ğŸ¯ Reinforcement Learning from Human Feedback")
        print("  ğŸ”¬ Automated Hypothesis Testing")
        print("  ğŸ§© Advanced Knowledge Graph")
        print("\nğŸ“‹ åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰:")
        print("  /help       - å…¨ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§")
        print("  /stats      - è©³ç´°çµ±è¨ˆæƒ…å ±")
        print("  /exit       - çµ‚äº†")
        print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†:")
        print("  /save [file] - çŠ¶æ…‹ä¿å­˜")
        print("  /load [file] - çŠ¶æ…‹èª­ã¿è¾¼ã¿")
        print("  /export      - ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        print("  /clear       - å±¥æ­´ã‚¯ãƒªã‚¢")
        print("\nğŸ¯ è©•ä¾¡ãƒ»å­¦ç¿’:")
        print("  /feedback <rating> - ç›´å‰ã®å›ç­”ã‚’è©•ä¾¡ (-2 to +2)")
        print("  /rate <1-5>        - 5æ®µéšè©•ä¾¡")
        print("  /review            - éå»ã®è©•ä¾¡ã‚’ç¢ºèª")
        print("  /improve           - æ”¹å–„ææ¡ˆã‚’å–å¾—")
        print("\nğŸ”¬ é«˜åº¦ãªæ©Ÿèƒ½:")
        print("  /quantum    - é‡å­æœ€é©åŒ–è©³ç´°")
        print("  /genetic    - éºä¼çš„é€²åŒ–çŠ¶æ³")
        print("  /swarm      - ç¾¤çŸ¥èƒ½ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        print("  /rlhf       - å¼·åŒ–å­¦ç¿’æƒ…å ±")
        print("  /kg         - çŸ¥è­˜ã‚°ãƒ©ãƒ•")
        print("  /hypothesis - ä»®èª¬æ¤œè¨¼å±¥æ­´")
        print("\nğŸ¨ è¡¨ç¤ºãƒ»è¨­å®š:")
        print("  /history    - ä¼šè©±å±¥æ­´")
        print("  /profile    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        print("  /config     - ç¾åœ¨ã®è¨­å®š")
        print("  /set <key> <value> - è¨­å®šå¤‰æ›´")
        print("\nğŸ” åˆ†æãƒ»æ¤œç´¢:")
        print("  /analyze <text> - ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
        print("  /search <query> - çŸ¥è­˜ã‚°ãƒ©ãƒ•æ¤œç´¢")
        print("  /topics     - ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§")
        print("  /insights   - ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ")
        print("\nğŸ§ª å®Ÿé¨“çš„æ©Ÿèƒ½:")
        print("  /experiment <strategy> - æˆ¦ç•¥ãƒ†ã‚¹ãƒˆ")
        print("  /compare <query>       - æˆ¦ç•¥æ¯”è¼ƒ")
        print("  /benchmark             - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ")
        print("  /debug                 - ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        print("\nğŸŒŸ ç©¶æ¥µã®æ©Ÿèƒ½:")
        print("  /causal <event>     - å› æœæ¨è«–")
        print("  /synthesize <A> <B> - å‰µé€ çš„çµ±åˆ")
        print("  /verify <claim>     - ä¸»å¼µã‚’æ¤œè¨¼")
        print("  /adversarial        - æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆ")
        print("  /predict            - æ¬¡ã®æ„å›³ã‚’äºˆæ¸¬")
        print("  /scientific <obs>   - ç§‘å­¦çš„æ‰‹æ³•é©ç”¨")
        print("  /progress           - å­¦ç¿’é€²æ—åˆ†æ")
        print("  /meta               - ãƒ¡ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
        print("  /analogies <concept> - é¡æ¨ç™ºè¦‹")
        print("  /trust              - ä¿¡é ¼ã‚¹ã‚³ã‚¢")
        print("=" * 80 + "\n")
    
    def print_response(self, response: Response):
        """å¿œç­”è¡¨ç¤º"""
        print(f"\nğŸ¤– Assistant [{response.model.split('-')[-1]}]:")
        print("â”€" * 80)
        print(response.text)
        print("â”€" * 80)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = []
        if response.strategy:
            emoji = {
                Strategy.QUANTUM: "ğŸ”®",
                Strategy.GENETIC: "ğŸ§¬",
                Strategy.SWARM: "ğŸŒŠ",
                Strategy.TREE_SEARCH: "ğŸŒ³",
                Strategy.COT: "ğŸ¤”",
                Strategy.DEBATE: "ğŸ—£ï¸"
            }.get(response.strategy, "ğŸ“‹")
            metadata.append(f"{emoji}{response.strategy.value}")
        if response.complexity:
            metadata.append(f"âš™ï¸{response.complexity.value}")
        metadata.append(f"â­{response.quality_score:.2f}")
        metadata.append(f"âœ…{response.confidence:.2f}")
        metadata.append(f"ğŸ²{response.uncertainty:.2f}")
        metadata.append(f"ğŸ’°${response.cost:.6f}")
        metadata.append(f"â±ï¸{response.latency:.0f}ms")
        if response.quantum_optimized:
            metadata.append("ğŸ”®Optimized")
        if response.genetic_fitness > 0:
            metadata.append(f"ğŸ§¬Fit:{response.genetic_fitness:.2f}")
        if response.swarm_consensus > 0:
            metadata.append(f"ğŸŒŠConsensus:{response.swarm_consensus:.2f}")
        if response.cached:
            metadata.append(f"ğŸ’¾Cache")
        print(" | ".join(metadata))
        
        # è¿½åŠ æƒ…å ±
        if response.personas_involved:
            print(f"\nğŸ­ Personas: {', '.join(response.personas_involved)}")
        if response.reasoning_steps:
            print(f"\nğŸ§  Reasoning Steps: {len(response.reasoning_steps)} steps")
        if response.alternatives:
            print(f"\nğŸ”„ Alternatives: {len(response.alternatives)} considered")
        print()
    
    def print_stats(self):
        """çµ±è¨ˆè¡¨ç¤º"""
        stats = self.llm.get_stats()
        print("\n" + "=" * 80)
        print("ğŸ“Š System Statistics")
        print("=" * 80)
        
        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        sys = stats['system']
        print(f"\nğŸ“ˆ System:")
        print(f"   Queries: {sys['queries']} | Success Rate: {sys['success_rate']}")
        print(f"   Cache Hit Rate: {sys['cache_hit_rate']}")
        print(f"   Total Cost: {sys['total_cost']} | Avg: {sys['avg_cost']}")
        
        # é«˜åº¦ãªæ©Ÿèƒ½
        adv = stats['advanced']
        print(f"\nğŸš€ Advanced Features:")
        print(f"   ğŸ”® Quantum Optimizations: {adv['quantum_optimizations']}")
        print(f"   ğŸ§¬ Genetic Evolutions: {adv['genetic_evolutions']}")
        print(f"   ğŸŒŠ Swarm Optimizations: {adv['swarm_optimizations']}")
        print(f"   ğŸ”¬ Hypotheses Tested: {adv['hypotheses_tested']}")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        prof = stats['profile']
        print(f"\nğŸ‘¤ Profile:")
        print(f"   Interactions: {prof['interactions']}")
        print(f"   Expertise Areas: {prof['expertise_areas']}")
        if prof['top_topics']:
            print(f"   Top Topics: {', '.join([t[0] for t in prof['top_topics'][:3]])}")
        
        # çŸ¥è­˜ã‚°ãƒ©ãƒ•
        if 'knowledge_graph' in stats:
            kg = stats['knowledge_graph']
            print(f"\nğŸ§© Knowledge Graph:")
            print(f"   Nodes: {kg['nodes']} | Edges: {kg['edges']} | Communities: {kg['communities']}")
        
        # éºä¼çš„é€²åŒ–
        if 'genetic' in stats:
            gen = stats['genetic']
            print(f"\nğŸ§¬ Genetic Evolution:")
            print(f"   Generation: {gen['generation']} | Population: {gen['population_size']}")
            print(f"   Best Fitness: {gen['best_fitness']:.3f}")
        
        # RLHF
        if 'rlhf' in stats:
            rl = stats['rlhf']
            print(f"\nğŸ¯ RLHF:")
            print(f"   States Explored: {rl['states_explored']}")
            print(f"   Total Updates: {rl['total_updates']}")
            print(f"   Avg Reward: {rl['avg_reward']:.3f}")
        print("=" * 80 + "\n")
    
    def _analyze_causality(self, event: str):
        """å› æœé–¢ä¿‚åˆ†æ"""
        if not self.llm.causal_engine:
            print("âŒ Causal reasoning disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ§© Causal Analysis: '{event}'")
        print("=" * 80)
        
        # åŸå› ã‚’æ¨è«–
        causes = self.llm.causal_engine.infer_cause(event, depth=3)
        if causes:
            print(f"\nğŸ” Potential Causes:")
            for i, (cause, prob) in enumerate(causes, 1):
                bar = "â–ˆ" * int(prob * 30) + "â–‘" * (30 - int(prob * 30))
                print(f"   {i:2d}. [{bar}] {prob:.2%} - {cause}")
        else:
            print("\n   No causal relationships found in knowledge base.")
        
        # çµæœã‚’äºˆæ¸¬
        effects = self.llm.causal_engine.predict_effect(event, depth=3)
        if effects:
            print(f"\nğŸ”® Potential Effects:")
            for i, (effect, prob) in enumerate(effects, 1):
                bar = "â–ˆ" * int(prob * 30) + "â–‘" * (30 - int(prob * 30))
        """ã‚³ãƒãƒ³ãƒ‰å‡¦ç†"""
        parts = command.strip().split()
        cmd = parts[0].lower()
        
        # ========== åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ ==========
        if cmd == '/exit':
            print("ğŸ‘‹ Goodbye!")
            return False
        elif cmd == '/help':
            self.print_welcome()
        elif cmd == '/stats':
            self.print_stats()
        
        # ========== ãƒ‡ãƒ¼ã‚¿ç®¡ç† ==========
        elif cmd == '/save':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.save_state(filepath)
        elif cmd == '/load':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.load_state(filepath)
        elif cmd == '/export':
            self._export_data()
        elif cmd == '/clear':
            self.history.clear()
            self.llm.context_window.clear()
            if self.llm.vector_db:
                self.llm.vector_db.vectors.clear()
            print("ğŸ—‘ï¸  All history cleared")
        
        # ========== è©•ä¾¡ãƒ»å­¦ç¿’ ==========
        elif cmd == '/feedback':
            if not self.history:
                print("âŒ No previous response to rate")
                return True
            try:
                rating = int(parts[1]) if len(parts) > 1 else 0
                if rating < -2 or rating > 2:
                    print("âŒ Rating must be between -2 and +2")
                    return True
                last_query, last_response = self.history[-1]
                self.llm.add_feedback(last_query, last_response.text, rating, last_response)
                print(f"âœ… Feedback recorded: {rating:+d}")
            except ValueError:
                print("âŒ Invalid rating")
        elif cmd == '/rate':
            if not self.history:
                print("âŒ No previous response to rate")
                return True
            try:
                rating = int(parts[1]) if len(parts) > 1 else 3
                if rating < 1 or rating > 5:
                    print("âŒ Rating must be between 1 and 5")
                    return True
                # 5æ®µéšã‚’-2~+2ã«å¤‰æ›
                converted = rating - 3
                last_query, last_response = self.history[-1]
                self.llm.add_feedback(last_query, last_response.text, converted, last_response)
                print(f"â­ Rated: {rating}/5 stars")
            except ValueError:
                print("âŒ Invalid rating")
        
        elif cmd == '/review':
            self._show_feedback_history()
        elif cmd == '/improve':
            self._show_improvements()
        elif cmd == '/quantum':
            self._show_quantum_info()
        elif cmd == '/genetic':
            self._show_genetic_info()
        elif cmd == '/swarm':
            self._show_swarm_info()
        elif cmd == '/rlhf':
            self._show_rlhf_info()
        elif cmd == '/kg':
            self._show_knowledge_graph()
        elif cmd == '/hypothesis':
            self._show_hypothesis_history()
        
        # ========== è¡¨ç¤ºãƒ»è¨­å®š ==========
        elif cmd == '/history':
            self._show_history()
        elif cmd == '/profile':
            self._show_profile()
        elif cmd == '/config':
            self._show_config()
        elif cmd == '/set':
            if len(parts) < 3:
                print("âŒ Usage: /set <key> <value>")
            else:
                self._set_config(parts[1], parts[2])
        
        # ========== åˆ†æãƒ»æ¤œç´¢ ==========
        elif cmd == '/analyze':
            if len(parts) < 2:
                print("âŒ Usage: /analyze <text>")
            else:
                text = ' '.join(parts[1:])
                self._analyze_text(text)
        elif cmd == '/search':
            if len(parts) < 2:
                print("âŒ Usage: /search <query>")
            else:
                query = ' '.join(parts[1:])
                self._search_knowledge(query)
        elif cmd == '/topics':
            self._show_topics()
        elif cmd == '/insights':
            self._generate_insights()
        
        # ========== å®Ÿé¨“çš„æ©Ÿèƒ½ ==========
        elif cmd == '/experiment':
            if len(parts) < 2:
                print("âŒ Usage: /experiment <strategy>")
                print("   Available: quantum, genetic, swarm, cot, debate")
            else:
                strategy = parts[1]
                self._run_experiment(strategy)
        elif cmd == '/compare':
            if len(parts) < 2:
                print("âŒ Usage: /compare <query>")
            else:
                query = ' '.join(parts[1:])
                self._compare_strategies(query)
        elif cmd == '/benchmark':
            self._run_benchmark()
        elif cmd == '/debug':
            self._show_debug_info()
        elif cmd == '/causal':
            if len(parts) < 2:
                print("âŒ Usage: /causal <event>")
            else:
                event = ' '.join(parts[1:])
                self._analyze_causality(event)
        elif cmd == '/synthesize':
            if len(parts) < 3:
                print("âŒ Usage: /synthesize <concept_a> <concept_b>")
            else:
                concept_a = parts[1]
                concept_b = parts[2]
                self._creative_synthesis(concept_a, concept_b)
        elif cmd == '/verify':
            if len(parts) < 2:
                print("âŒ Usage: /verify <claim>")
            else:
                claim = ' '.join(parts[1:])
                self._verify_claim(claim)
        elif cmd == '/adversarial':
            self._run_adversarial_test()
        elif cmd == '/predict':
            self._show_predictions()
        elif cmd == '/scientific':
            if len(parts) < 2:
                print("âŒ Usage: /scientific <observation>")
            else:
                observation = ' '.join(parts[1:])
                self._apply_scientific_method(observation)
        elif cmd == '/progress':
            self._show_learning_progress()
        elif cmd == '/meta':
            self._show_meta_insights()
        elif cmd == '/analogies':
            if len(parts) < 2:
                print("âŒ Usage: /analogies <concept>")
            else:
                concept = ' '.join(parts[1:])
                self._find_analogies(concept)
        elif cmd == '/trust':
            self._show_trust_score()
        else:
            print(f"âŒ Unknown command: {cmd}")
            print("ğŸ’¡ Type /help for available commands")
        return True
    
    # ========== è£œåŠ©ãƒ¡ã‚½ãƒƒãƒ‰ ==========
    
    def _analyze_causality(self, event: str):
        """å› æœé–¢ä¿‚åˆ†æ"""
        if not self.llm.causal_engine:
            print("âŒ Causal reasoning disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ§© Causal Analysis: '{event}'")
        print("=" * 80)
        
        # åŸå› ã‚’æ¨è«–
        causes = self.llm.causal_engine.infer_cause(event, depth=3)
        if causes:
            print(f"\nğŸ” Potential Causes:")
            for i, (cause, prob) in enumerate(causes, 1):
                bar = "â–ˆ" * int(prob * 30) + "â–‘" * (30 - int(prob * 30))
                print(f"   {i:2d}. [{bar}] {prob:.2%} - {cause}")
        else:
            print("\n   No causal relationships found in knowledge base.")
        
        # çµæœã‚’äºˆæ¸¬
        effects = self.llm.causal_engine.predict_effect(event, depth=3)
        if effects:
            print(f"\nğŸ”® Potential Effects:")
            for i, (effect, prob) in enumerate(effects, 1):
                bar = "â–ˆ" * int(prob * 30) + "â–‘" * (30 - int(prob * 30))
                print(f"   {i:2d}. [{bar}] {prob:.2%} - {effect}")
        
        # ä»‹å…¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print(f"\nğŸ’¡ Intervention Simulation:")
        print(f"   If we intervene on '{event[:40]}...', we can expect:")
        """ã‚³ãƒãƒ³ãƒ‰å‡¦ç†"""
        parts = command.strip().split()
        cmd = parts[0].lower()
        
        # ========== åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ ==========
        if cmd == '/exit':
            print("ğŸ‘‹ Goodbye!")
            return False
        elif cmd == '/help':
            self.print_welcome()
        elif cmd == '/stats':
            self.print_stats()
        
        # ========== ãƒ‡ãƒ¼ã‚¿ç®¡ç† ==========
        elif cmd == '/save':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.save_state(filepath)
        elif cmd == '/load':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.load_state(filepath)
        elif cmd == '/export':
            self._export_data()
        elif cmd == '/clear':
            self.history.clear()
            self.llm.context_window.clear()
            if self.llm.vector_db:
                self.llm.vector_db.vectors.clear()
            print("ğŸ—‘ï¸  All history cleared")
        
        # ========== è©•ä¾¡ãƒ»å­¦ç¿’ ==========
        elif cmd == '/feedback':
            if not self.history:
                print("âŒ No previous response to rate")
                return True
            try:
                rating = int(parts[1]) if len(parts) > 1 else 0
                if rating < -2 or rating > 2:
                    print("âŒ Rating must be between -2 and +2")
                    return True
                last_query, last_response = self.history[-1]
                self.llm.add_feedback(last_query, last_response.text, rating, last_response)
                print(f"âœ… Feedback recorded: {rating:+d}")
            except ValueError:
                print("âŒ Invalid rating")
        elif cmd == '/rate':
            if not self.history:
                print("âŒ No previous response to rate")
                return True
            try:
                rating = int(parts[1]) if len(parts) > 1 else 3
                if rating < 1 or rating > 5:
                    print("âŒ Rating must be between 1 and 5")
                    return True
                
                # 5æ®µéšã‚’-2~+2ã«å¤‰æ›
                converted = rating - 3
                last_query, last_response = self.history[-1]
                self.llm.add_feedback(last_query, last_response.text, converted, last_response)
                print(f"â­ Rated: {rating}/5 stars")
            except ValueError:
                print("âŒ Invalid rating")
        elif cmd == '/review':
            self._show_feedback_history()
        elif cmd == '/improve':
            self._show_improvements()
        elif cmd == '/quantum':
            self._show_quantum_info()
        elif cmd == '/genetic':
            self._show_genetic_info()
        elif cmd == '/swarm':
            self._show_swarm_info()
        elif cmd == '/rlhf':
            self._show_rlhf_info()
        elif cmd == '/kg':
            self._show_knowledge_graph()
        elif cmd == '/hypothesis':
            self._show_hypothesis_history()
        
        # ========== è¡¨ç¤ºãƒ»è¨­å®š ==========
        elif cmd == '/history':
            self._show_history()
        elif cmd == '/profile':
            self._show_profile()
        elif cmd == '/config':
            self._show_config()
        elif cmd == '/set':
            if len(parts) < 3:
                print("âŒ Usage: /set <key> <value>")
            else:
                self._set_config(parts[1], parts[2])
        
        # ========== åˆ†æãƒ»æ¤œç´¢ ==========
        elif cmd == '/analyze':
            if len(parts) < 2:
                print("âŒ Usage: /analyze <text>")
            else:
                text = ' '.join(parts[1:])
                self._analyze_text(text)
        elif cmd == '/search':
            if len(parts) < 2:
                print("âŒ Usage: /search <query>")
            else:
                query = ' '.join(parts[1:])
                self._search_knowledge(query)
        elif cmd == '/topics':
            self._show_topics()
        elif cmd == '/insights':
            self._generate_insights()
        
        # ========== å®Ÿé¨“çš„æ©Ÿèƒ½ ==========
        elif cmd == '/experiment':
            if len(parts) < 2:
                print("âŒ Usage: /experiment <strategy>")
                print("   Available: quantum, genetic, swarm, cot, debate")
            else:
                strategy = parts[1]
                self._run_experiment(strategy)
        elif cmd == '/compare':
            if len(parts) < 2:
                print("âŒ Usage: /compare <query>")
            else:
                query = ' '.join(parts[1:])
                self._compare_strategies(query)
        elif cmd == '/benchmark':
            self._run_benchmark()
            
        # ä»‹å…¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print(f"\nğŸ’¡ Intervention Simulation:")
        print(f"   If we intervene on '{event[:40]}...', we can expect:")
        for effect, prob in effects[:3]:
            print(f"   â€¢ {effect[:60]}... (likelihood: {prob:.0%})")
        print("=" * 80 + "\n")
    
    def _creative_synthesis(self, concept_a: str, concept_b: str):
        """å‰µé€ çš„çµ±åˆ"""
        if not self.llm.creative_synthesizer:
            print("âŒ Creative synthesis disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ¨ Creative Synthesis: '{concept_a}' + '{concept_b}'")
        print("=" * 80)
        synthesis = self.llm.creative_synthesizer.synthesize(concept_a, concept_b)
        print(f"\nğŸ’¡ Synthesized Concept:")
        print(f"   {synthesis.synthesis}")
        print(f"\nğŸ“Š Metrics:")
        novelty_bar = "â–ˆ" * int(synthesis.novelty_score * 20) + "â–‘" * (20 - int(synthesis.novelty_score * 20))
        coherence_bar = "â–ˆ" * int(synthesis.coherence_score * 20) + "â–‘" * (20 - int(synthesis.coherence_score * 20))
        useful_bar = "â–ˆ" * int(synthesis.usefulness_score * 20) + "â–‘" * (20 - int(synthesis.usefulness_score * 20))
        print(f"   Novelty:     [{novelty_bar}] {synthesis.novelty_score:.2%}")
        print(f"   Coherence:   [{coherence_bar}] {synthesis.coherence_score:.2%}")
        print(f"   Usefulness:  [{useful_bar}] {synthesis.usefulness_score:.2%}")
        print(f"\nğŸŒŸ Overall Innovation Score: {(synthesis.novelty_score + synthesis.coherence_score + synthesis.usefulness_score) / 3:.2%}")
        print("=" * 80 + "\n")
    
    def _verify_claim(self, claim: str):
        """ä¸»å¼µã‚’æ¤œè¨¼"""
        if not self.llm.verification_system:
            print("âŒ Verification system disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ” Claim Verification")
        print("=" * 80)
        print(f"\nClaim: {claim}")
        
        # è¤‡æ•°ã®æ¤œè¨¼æ–¹æ³•ã‚’é©ç”¨
        methods = [
            VerificationMethod.LOGICAL_CONSISTENCY,
            VerificationMethod.CROSS_REFERENCE,
            VerificationMethod.FACT_CHECK
        ]
        results = []
        for method in methods:
            context = ' '.join([q for q, _ in self.history[-3:]]) if self.history else ""
            verification = self.llm.verification_system.verify_claim(claim, context, method)
            results.append(verification)
        print(f"\nğŸ“‹ Verification Results:")
        for i, v in enumerate(results, 1):
            status = "âœ… VERIFIED" if v.result else "âŒ REJECTED"
            conf_bar = "â–ˆ" * int(v.confidence * 20) + "â–‘" * (20 - int(v.confidence * 20))
            print(f"\n   {i}. {v.method.value.replace('_', ' ').title()}: {status}")
            print(f"      Confidence: [{conf_bar}] {v.confidence:.2%}")
            if v.evidence:
                print(f"      Evidence: {', '.join(v.evidence[:2])}")
        
        # ç·åˆåˆ¤å®š
        avg_confidence = statistics.mean(v.confidence for v in results)
        verified_count = sum(1 for v in results if v.result)
        print(f"\nğŸ¯ Overall Assessment:")
        if verified_count == len(results) and avg_confidence > 0.7:
            print(f"   âœ… HIGHLY CREDIBLE ({avg_confidence:.0%} confidence)")
        elif verified_count >= len(results) / 2:
            print(f"   âš ï¸  PARTIALLY VERIFIED ({avg_confidence:.0%} confidence)")
        else:
            print(f"   âŒ NOT VERIFIED ({avg_confidence:.0%} confidence)")
        print("=" * 80 + "\n")
    
    def _run_adversarial_test(self):
        """æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        if not self.llm.adversarial_tester:
            print("âŒ Adversarial testing disabled")
            return
        if not self.history:
            print("âŒ No conversation history. Start a conversation first.")
            return
        last_query, last_response = self.history[-1]
        print("\n" + "=" * 80)
        print("ğŸª Running Adversarial Robustness Test")
        print("=" * 80)
        print(f"\nOriginal Query: {last_query[:60]}...")
        print("\nâ³ Generating adversarial examples and testing...")
        
        # æ•µå¯¾çš„ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        adversarial_queries = self.llm.adversarial_tester.generate_adversarial_queries(last_query)
        print(f"\nğŸ“‹ Generated {len(adversarial_queries)} adversarial variants:")
        for i, adv_q in enumerate(adversarial_queries, 1):
            print(f"   {i}. {adv_q[:70]}...")
        
        # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        consistency_scores = []
        for adv_q in adversarial_queries[:3]:  # æœ€åˆã®3ã¤ã®ã¿ãƒ†ã‚¹ãƒˆ
            try:
                print(f"\n   Testing variant {len(consistency_scores) + 1}...", end=" ", flush=True)
                # å®Ÿéš›ã«ã¯éåŒæœŸã§å®Ÿè¡Œã™ã¹ãã ãŒã€ç°¡æ˜“ç‰ˆã¨ã—ã¦åŒæœŸå®Ÿè¡Œ
                adv_response = self.llm.query(adv_q)
                
                # é¡ä¼¼åº¦è¨ˆç®—
                orig_words = set(last_response.text.lower().split())
                adv_words = set(adv_response.text.lower().split())
                if orig_words and adv_words:
                    similarity = len(orig_words & adv_words) / len(orig_words | adv_words)
                    consistency_scores.append(similarity)
                    print(f"âœ“ (consistency: {similarity:.2%})")
            except Exception as e:
                print(f"âœ— ({e})")
        if consistency_scores:
            avg_consistency = statistics.mean(consistency_scores)
            min_consistency = min(consistency_scores)
            print(f"\nğŸ“Š Test Results:")
            print(f"   Average Consistency: {avg_consistency:.2%}")
            print(f"   Minimum Consistency: {min_consistency:.2%}")
            
            if avg_consistency > 0.7:
                print(f"\n   âœ… ROBUST - High adversarial resistance")
            elif avg_consistency > 0.5:
                print(f"\n   âš ï¸  MODERATE - Some inconsistencies detected")
            else:
                print(f"\n   âŒ VULNERABLE - Significant adversarial weakness")
        print("=" * 80 + "\n")
    
    def _show_predictions(self):
        """äºˆæ¸¬æƒ…å ±è¡¨ç¤º"""
        if not self.llm.predictive_engine:
            print("âŒ Predictive modeling disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ”® Predictive Analysis")
        print("=" * 80)
        
        # æ¬¡ã®æ„å›³ã‚’äºˆæ¸¬
        predicted_intent = self.llm.predictive_engine.predict_next_intent()
        success_prob = self.llm.predictive_engine.get_success_probability(predicted_intent)
        print(f"\nğŸ“ Next Query Prediction:")
        print(f"   Predicted Intent: {predicted_intent.value}")
        print(f"   Success Probability: {success_prob:.1%}")
        
        # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        if self.llm.predictive_engine.model.user_patterns:
            print(f"\nğŸ“Š Usage Patterns Detected:")
            top_patterns = sorted(
                self.llm.predictive_engine.model.user_patterns.items(),
                key=lambda x: len(x[1]),
                reverse=True
            )[:5]
            for pattern, results in top_patterns:
                avg_success = statistics.mean(results) if results else 0
                print(f"   â€¢ {pattern}: {avg_success:.1%} success ({len(results)} samples)")
        
        # ã‚¯ã‚¨ãƒªå±¥æ­´åˆ†æ
        if len(self.llm.predictive_engine.query_history) >= 10:
            recent = list(self.llm.predictive_engine.query_history)[-10:]
            intent_dist = Counter(q['intent'] for q in recent)
            
            print(f"\nğŸ“ˆ Recent Intent Distribution (last 10 queries):")
            for intent, count in intent_dist.most_common():
                bar = "â–ˆ" * count + "â–‘" * (10 - count)
                print(f"   {intent.value:15s} [{bar}] {count}/10")
        print("=" * 80 + "\n")
    
    def _apply_scientific_method(self, observation: str):
        """ç§‘å­¦çš„æ‰‹æ³•ã‚’é©ç”¨"""
        if not self.llm.scientific_method:
            print("âŒ Scientific method disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ”¬ Scientific Method Application")
        print("=" * 80)
        print(f"\nObservation: {observation}")        
        # 1. ä»®èª¬ã‚’å®šå¼åŒ–
        print(f"\n1ï¸âƒ£  Hypothesis Formulation:")
        hypothesis = self.llm.scientific_method.formulate_hypothesis(observation)
        print(f"   {hypothesis.statement}")
        print(f"   Prior Confidence: {hypothesis.bayesian_prior:.2%}")
        # 2. å®Ÿé¨“ã‚’è¨­è¨ˆ
        print(f"\n2ï¸âƒ£  Experiment Design:")
        experiment = self.llm.scientific_method.design_experiment(hypothesis)
        print(f"   Experiment ID: {experiment['id']}")
        print(f"   Method: {experiment['method']}")
        print(f"   Status: {experiment['status']}")
        # 3. äºˆæ¸¬
        print(f"\n3ï¸âƒ£  Predictions:")
        print(f"   If the hypothesis is correct, we expect:")
        print(f"   â€¢ Measurable outcome related to the observation")
        print(f"   â€¢ Reproducible results under similar conditions")
        print(f"   â€¢ Consistency with existing knowledge")
        # 4. çµæœåˆ†æï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        print(f"\n4ï¸âƒ£  Analysis:")
        analysis = self.llm.scientific_method.analyze_results(
            experiment['id'],
            {'data_points': 100, 'effect_observed': True}
        )
        print(f"   Statistical Significance: {analysis['statistical_significance']:.3f}")
        print(f"   Effect Size: {analysis['effect_size']:.3f}")
        print(f"   Conclusion: {analysis['conclusion']}")
        # 5. ãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        print(f"\n5ï¸âƒ£  Peer Review (Simulated):")
        mock_reviews = [
            "The methodology is sound and well-designed",
            "Results are consistent with theoretical predictions",
            "Further validation recommended"
        ]
        review_score = self.llm.scientific_method.peer_review(hypothesis, mock_reviews)
        print(f"   Peer Review Score: {review_score:.2%}")
        # æœ€çµ‚è©•ä¾¡
        print(f"\nğŸ¯ Final Assessment:")
        if review_score > 0.7 and analysis['statistical_significance'] > 0.05:
            print(f"   âœ… HYPOTHESIS SUPPORTED")
            print(f"   â€¢ Strong evidence in favor")
            print(f"   â€¢ High peer review score")
            print(f"   â€¢ Recommended for further investigation")
        else:
            print(f"   âš ï¸  HYPOTHESIS REQUIRES MORE EVIDENCE")
            print(f"   â€¢ Additional data collection needed")
            print(f"   â€¢ Consider alternative explanations")
        print("=" * 80 + "\n")
    
    def _show_learning_progress(self):
        """å­¦ç¿’é€²æ—è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“Š Learning Progress Analysis")
        print("=" * 80)
        progress = self.llm.analyze_learning_progress()
        if progress['status'] == 'insufficient_data':
            print("\nâš ï¸  Insufficient data for analysis.")
            print("   Continue using the system to unlock progress tracking.")
            print("=" * 80 + "\n")
            return
        print(f"\nğŸ“ˆ Overall Metrics:")
        print(f"   Total Interactions: {progress['total_interactions']}")
        print(f"   Recent Quality: {progress['recent_quality']:.3f}")
        print(f"   Improvement: {progress['improvement']:+.3f}")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
        trend = progress['trend']
        if trend == 'improving':
            print(f"   Trend: ğŸ“ˆ IMPROVING")
        elif trend == 'declining':
            print(f"   Trend: ğŸ“‰ DECLINING")
        else:
            print(f"   Trend: â¡ï¸  STABLE")
        
        # æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        if progress['best_strategy']:
            print(f"\nğŸ¯ Strategy Performance:")
            print(f"   Best Strategy: {progress['best_strategy']}")
            if 'strategy_performance' in progress:
                print(f"\n   Detailed Performance:")
                for strategy, score in sorted(
                    progress['strategy_performance'].items(),
                    key=lambda x: x[1],
                    reverse=True
                ):
                    bar = "â–ˆ" * int(score * 20) + "â–‘" * (20 - int(score * 20))
                    print(f"   â€¢ {strategy:20s} [{bar}] {score:.3f}")
        
        # æ¨å¥¨äº‹é …
        print(f"\nğŸ’¡ Recommendations:")
        if trend == 'improving':
            print(f"   âœ… Keep using current strategies")
            print(f"   âœ… Gradually increase complexity")
        elif trend == 'declining':
            print(f"   âš ï¸  Consider switching strategies")
            print(f"   âš ï¸  Provide more feedback")
            print(f"   âš ï¸  Review recent interactions")
        else:
            print(f"   â€¢ Try new strategies for diversity")
            print(f"   â€¢ Challenge with complex queries")
        print("=" * 80 + "\n")
    
    def _show_meta_insights(self):
        """ãƒ¡ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆè¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸŒŸ Meta-Level Insights")
        print("=" * 80)
        insights = self.llm.generate_meta_insights()
        if not insights:
            print("\nâš ï¸  Insufficient data for meta-analysis.")
            print("   Continue interacting with the system.")
            print("=" * 80 + "\n")
            return
        print(f"\nğŸ” System has generated {len(insights)} insights:")
        for insight in insights:
            print(f"\n   {insight}")
        
        # è¿½åŠ ã®åˆ†æ
        stats = self.llm.get_stats()
        print(f"\nğŸ§  Deep Analysis:")
        
        # ã‚·ã‚¹ãƒ†ãƒ æˆç†Ÿåº¦
        if stats['profile']['interactions'] < 50:
            maturity = "Early Stage"
            emoji = "ğŸŒ±"
        elif stats['profile']['interactions'] < 200:
            maturity = "Growing"
            emoji = "ğŸŒ¿"
        elif stats['profile']['interactions'] < 500:
            maturity = "Mature"
            emoji = "ğŸŒ³"
        else:
            maturity = "Expert"
            emoji = "ğŸ†"
        print(f"   System Maturity: {emoji} {maturity} ({stats['profile']['interactions']} interactions)")
        
        # æ©Ÿèƒ½æ´»ç”¨åº¦
        ultimate = stats.get('ultimate', {})
        total_advanced = sum(ultimate.values())
        if total_advanced > 100:
            print(f"   Feature Utilization: ğŸŒŸ POWER USER ({total_advanced} advanced operations)")
        elif total_advanced > 50:
            print(f"   Feature Utilization: â­ ACTIVE ({total_advanced} advanced operations)")
        else:
            print(f"   Feature Utilization: ğŸ’¡ EXPLORE MORE ({total_advanced} advanced operations)")
        
        # äºˆæ¸¬ç²¾åº¦
        if 'prediction_accuracy' in stats['profile']:
            accuracy = stats['profile']['prediction_accuracy']
            if accuracy > 0.7:
                print(f"   Prediction Accuracy: ğŸ¯ HIGH ({accuracy:.1%})")
            elif accuracy > 0.5:
                print(f"   Prediction Accuracy: ğŸ“Š MODERATE ({accuracy:.1%})")
            else:
                print(f"   Prediction Accuracy: ğŸ“‰ LEARNING ({accuracy:.1%})")
        print("=" * 80 + "\n")
    
    def _find_analogies(self, concept: str):
        """é¡æ¨ã‚’ç™ºè¦‹"""
        if not self.llm.creative_synthesizer:
            print("âŒ Creative synthesis disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ” Finding Analogies for: '{concept}'")
        print("=" * 80)
        analogies = self.llm.creative_synthesizer.find_analogies(concept, top_k=10)
        if not analogies:
            print("\n   No analogies found. The concept may be novel.")
            print("=" * 80 + "\n")
            return
        print(f"\nğŸ“Š Similar Concepts (by semantic similarity):")
        for i, (related, similarity) in enumerate(analogies, 1):
            bar = "â–ˆ" * int(similarity * 20) + "â–‘" * (20 - int(similarity * 20))
            print(f"   {i:2d}. [{bar}] {similarity:+.3f} - {related}")
        
        # æœ€ã‚‚è¿‘ã„æ¦‚å¿µã¨ã®çµ±åˆã‚’ææ¡ˆ
        if len(analogies) >= 2:
            top1, top2 = analogies[0][0], analogies[1][0]
            print(f"\nğŸ’¡ Suggested Synthesis:")
            print(f"   Try: /synthesize {concept} {top1}")
            print(f"   Or:  /synthesize {concept} {top2}")
        print("=" * 80 + "\n")
    
    def _show_trust_score(self):
        """ä¿¡é ¼ã‚¹ã‚³ã‚¢è¡¨ç¤º"""
        if not self.llm.verification_system:
            print("âŒ Verification system disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ” System Trust Score")
        print("=" * 80)
        trust_score = self.llm.verification_system.get_trust_score()
        print(f"\nğŸ“Š Overall Trust Score: {trust_score:.2%}")
        
        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¡¨ç¾
        bar = "â–ˆ" * int(trust_score * 40) + "â–‘" * (40 - int(trust_score * 40))
        print(f"   [{bar}]")
        
        # è©•ä¾¡
        if trust_score > 0.8:
            rating = "ğŸŒŸ EXCELLENT"
            desc = "System responses are highly trustworthy"
        elif trust_score > 0.6:
            rating = "âœ… GOOD"
            desc = "System responses are generally reliable"
        elif trust_score > 0.4:
            rating = "âš ï¸  MODERATE"
            desc = "Exercise caution with system responses"
        else:
            rating = "âŒ LOW"
            desc = "System needs more calibration"
        print(f"\n   Rating: {rating}")
        print(f"   {desc}")
        
        # æ¤œè¨¼çµ±è¨ˆ
        records = self.llm.verification_system.records
        if records:
            total = len(records)
            verified = sum(1 for r in records if r.result)
            print(f"\nğŸ“‹ Verification Statistics:")
            print(f"   Total Verifications: {total}")
            print(f"   Claims Verified: {verified} ({verified/total:.1%})")
            print(f"   Claims Rejected: {total - verified} ({(total-verified)/total:.1%})")
            
            # æ–¹æ³•åˆ¥ã®çµ±è¨ˆ
            method_stats = defaultdict(list)
            for r in records:
                method_stats[r.method].append(r.confidence)
            print(f"\n   By Method:")
            for method, confidences in method_stats.items():
                avg_conf = statistics.mean(confidences)
                print(f"   â€¢ {method.value:20s}: {avg_conf:.2%} avg confidence")
        print("=" * 80 + "\n")
    
    # ========== è£œåŠ©ãƒ¡ã‚½ãƒƒãƒ‰ ==========
    
    def _export_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = f"export_{timestamp}.json"
        export_data = {
            'session_id': self.session_id,
            'timestamp': timestamp,
            'history': [
                {
                    'query': q,
                    'response': r.to_dict()
                }
                for q, r in self.history
            ],
            'stats': self.llm.get_stats(),
            'profile': self.llm.profile
        }
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“¤ Data exported: {filepath}")
        except Exception as e:
            print(f"âŒ Export failed: {e}")
    
    def _show_feedback_history(self):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“Š Feedback History")
        print("=" * 80)
        feedback_history = self.llm.profile.get('feedback_history', [])
        if not feedback_history:
            print("\nNo feedback recorded yet.")
            print("=" * 80 + "\n")
            return
        recent = feedback_history[-10:]
        for i, fb in enumerate(recent, 1):
            rating = fb.get('rating', 0)
            rating_str = "â­" * max(0, rating + 2)
            print(f"\n{i}. Rating: {rating:+d} {rating_str}")
            print(f"   Query: {fb.get('query', '')[:60]}...")
            print(f"   Time: {fb.get('timestamp', 'N/A')}")
        avg_rating = statistics.mean(fb.get('rating', 0) for fb in feedback_history)
        print(f"\nğŸ“Š Average Rating: {avg_rating:+.2f}")
        print("=" * 80 + "\n")
    
    def _show_improvements(self):
        """æ”¹å–„ææ¡ˆè¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ’¡ Improvement Suggestions")
        print("=" * 80)
        stats = self.llm.get_stats()
        suggestions = []
        
        # æˆåŠŸç‡ãŒä½ã„å ´åˆ
        success_rate = float(stats['system']['success_rate'].strip('%')) / 100
        if success_rate < 0.9:
            suggestions.append("â€¢ Consider using more advanced strategies (quantum, genetic)")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒä½ã„å ´åˆ
        cache_rate = float(stats['system']['cache_hit_rate'].strip('%')) / 100
        if cache_rate < 0.3:
            suggestions.append("â€¢ Ask similar questions to benefit from caching")
        
        # éºä¼çš„é€²åŒ–ãŒæœ‰åŠ¹ãªå ´åˆ
        if 'genetic' in stats and stats['genetic']['generation'] > 0:
            best_fitness = stats['genetic']['best_fitness']
            if best_fitness < 0.7:
                suggestions.append("â€¢ Provide more feedback to improve prompt evolution")
        
        # RLHF
        if 'rlhf' in stats:
            avg_reward = stats['rlhf']['avg_reward']
            if avg_reward < 0.5:
                suggestions.append("â€¢ Rate responses to help the system learn your preferences")
        if not suggestions:
            suggestions.append("ystem is performing optimally!")
        for suggestion in suggestions:
            print(f"\n{suggestion}")
        print("\n" + "=" * 80 + "\n")
    
    def _show_quantum_info(self):
        """é‡å­æœ€é©åŒ–è©³ç´°"""
        if not self.llm.quantum_optimizer:
            print("âŒ Quantum optimization disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ”® Quantum Optimization Details")
        print("=" * 80)
        print(f"\nâš›ï¸  Configuration:")
        print(f"   Qubits: {self.llm.quantum_optimizer.num_qubits}")
        print(f"   Iterations: {self.llm.quantum_optimizer.config.iterations}")
        print(f"   Optimization Depth: {self.llm.quantum_optimizer.config.optimization_depth}")
        print(f"\nğŸ“Š Performance:")
        print(f"   Total Optimizations: {self.llm.metrics['quantum_optimizations']}")
        print(f"   Success Rate: High")
        print(f"\nğŸ’¡ When to Use:")
        print(f"   â€¢ Frontier-level complexity questions")
        print(f"   â€¢ Multi-dimensional optimization problems")
        print(f"   â€¢ Exploring novel solution spaces")
        print("=" * 80 + "\n")
    
    def _show_genetic_info(self):
        """éºä¼çš„é€²åŒ–è©³ç´°"""
        if not self.llm.genetic_evolver:
            print("âŒ Genetic evolution disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ§¬ Genetic Evolution Details")
        print("=" * 80)
        print(f"\nğŸ“ˆ Population Status:")
        print(f"   Generation: {self.llm.genetic_evolver.generation}")
        print(f"   Population Size: {len(self.llm.genetic_evolver.population)}")
        print(f"   Mutation Rate: {self.llm.config.genetic.mutation_rate:.1%}")
        print(f"   Crossover Rate: {self.llm.config.genetic.crossover_rate:.1%}")
        best_prompts = self.llm.genetic_evolver.get_best_prompts(5)
        if best_prompts:
            print(f"\nğŸ† Top 5 Evolved Prompts:")
            for i, prompt in enumerate(best_prompts, 1):
                fitness_bar = "â–ˆ" * int(prompt.fitness * 20) + "â–‘" * (20 - int(prompt.fitness * 20))
                print(f"\n   {i}. Fitness: [{fitness_bar}] {prompt.fitness:.3f}")
                print(f"      Generation: {prompt.generation} | Mutations: {prompt.mutations}")
                print(f"      Template: {prompt.template[:60]}...")
        print("=" * 80 + "\n")
    
    def _show_swarm_info(self):
        """ç¾¤çŸ¥èƒ½è©³ç´°"""
        if not self.llm.swarm:
            print("âŒ Swarm intelligence disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸŒŠ Swarm Intelligence Details")
        print("=" * 80)
        print(f"\nğŸ Swarm Configuration:")
        print(f"   Agents: {len(self.llm.swarm.agents)}")
        print(f"   Inertia Weight: {self.llm.config.swarm.inertia_weight}")
        print(f"   Cognitive Weight: {self.llm.config.swarm.cognitive_weight}")
        print(f"   Social Weight: {self.llm.config.swarm.social_weight}")
        if self.llm.swarm.agents:
            print(f"\nğŸ­ Agent Personas:")
            for agent in self.llm.swarm.agents:
                print(f"   â€¢ {agent.persona.value}: Fitness {agent.best_fitness:.3f}")
        print(f"\nğŸ“Š Performance:")
        print(f"   Global Best Fitness: {self.llm.swarm.global_best_fitness:.3f}")
        print(f"   Total Optimizations: {self.llm.metrics['swarm_optimizations']}")
        print("=" * 80 + "\n")
    
    def _show_rlhf_info(self):
        """RLHFè©³ç´°"""
        if not self.llm.rlhf:
            print("âŒ RLHF disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ¯ Reinforcement Learning Details")
        print("=" * 80)
        print(f"\nğŸ§  Learning Status:")
        print(f"   States Explored: {len(self.llm.rlhf.state_visits)}")
        print(f"   Q-Table Size: {len(self.llm.rlhf.q_table)}")
        print(f"   Total Updates: {sum(self.llm.rlhf.state_visits.values())}")
        print(f"   Learning Rate: {self.llm.config.rlhf.learning_rate}")
        print(f"   Exploration Rate: {self.llm.config.rlhf.exploration_rate:.1%}")
        if self.llm.rlhf.reward_history:
            avg_reward = statistics.mean(self.llm.rlhf.reward_history)
            recent_reward = statistics.mean(self.llm.rlhf.reward_history[-10:]) if len(self.llm.rlhf.reward_history) >= 10 else avg_reward
            print(f"\nğŸ“ˆ Rewards:")
            print(f"   Average Reward: {avg_reward:.3f}")
            print(f"   Recent Reward (last 10): {recent_reward:.3f}")
            print(f"   Trend: {'ğŸ“ˆ Improving' if recent_reward > avg_reward else 'ğŸ“‰ Declining' if recent_reward < avg_reward else 'â¡ï¸ Stable'}")
        
        # ãƒˆãƒƒãƒ—ãƒãƒªã‚·ãƒ¼
        policy = self.llm.rlhf.get_policy()
        if policy:
            print(f"\nğŸ² Current Policy (Top 5):")
            for i, (state, action) in enumerate(list(policy.items())[:5], 1):
                print(f"   {i}. {state} â†’ {action}")
        print("=" * 80 + "\n")
    
    def _show_hypothesis_history(self):
        """ä»®èª¬æ¤œè¨¼å±¥æ­´"""
        if not self.llm.hypothesis_tester:
            print("âŒ Hypothesis testing disabled")
            return
        print("\n" + "=" * 80)
        print("ğŸ”¬ Hypothesis Testing History")
        print("=" * 80)
        hypotheses = self.llm.hypothesis_tester.hypotheses
        if not hypotheses:
            print("\nNo hypotheses generated yet.")
            print("=" * 80 + "\n")
            return
        tested = [h for h in hypotheses if h.tested]
        print(f"\nğŸ“Š Summary:")
        print(f"   Total Hypotheses: {len(hypotheses)}")
        print(f"   Tested: {len(tested)}")
        print(f"   Confirmed: {sum(1 for h in tested if h.result)}")
        print(f"   Rejected: {sum(1 for h in tested if not h.result)}")
        best = self.llm.hypothesis_tester.get_best_hypotheses(5)
        if best:
            print(f"\nğŸ† Top Hypotheses (by confidence):")
            for i, h in enumerate(best, 1):
                conf_bar = "â–ˆ" * int(h.confidence * 20) + "â–‘" * (20 - int(h.confidence * 20))
                status = "âœ… Confirmed" if h.result else "âŒ Rejected"
                print(f"\n   {i}. [{conf_bar}] {h.confidence:.3f} - {status}")
                print(f"      {h.statement[:70]}...")
                print(f"      Evidence: {len(h.evidence)} | Counter: {len(h.counter_evidence)}")
        print("=" * 80 + "\n")
    
    def _show_history(self):
        """ä¼šè©±å±¥æ­´è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“œ Conversation History")
        print("=" * 80)
        if not self.history:
            print("\nNo conversation history yet.")
            print("=" * 80 + "\n")
            return
        recent = self.history[-10:]
        for i, (query, response) in enumerate(recent, 1):
            print(f"\n{i}. Q: {query[:60]}...")
            print(f"   A: {response.text[:60]}...")
            print(f"   Strategy: {response.strategy.value if response.strategy else 'N/A'} | Quality: {response.quality_score:.2f}")
        print(f"\nğŸ“Š Total Conversations: {len(self.history)}")
        print("=" * 80 + "\n")
    
    def _show_profile(self):
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ‘¤ User Profile")
        print("=" * 80)
        profile = self.llm.profile
        print(f"\nğŸ“Š Activity:")
        print(f"   Total Interactions: {profile['interaction_count']}")
        print(f"   Feedback Given: {len(profile.get('feedback_history', []))}")
        
        # ãƒˆãƒƒãƒ—ãƒˆãƒ”ãƒƒã‚¯
        topics = sorted(profile['topics'].items(), key=lambda x: x[1], reverse=True)[:10]
        if topics:
            print(f"\nğŸ“š Top Topics:")
            for topic, score in topics:
                print(f"   â€¢ {topic}: {score}")
        
        # å°‚é–€çŸ¥è­˜
        expertise = [(k, v) for k, v in profile['expertise'].items() if v > 0.3]
        if expertise:
            expertise.sort(key=lambda x: x[1], reverse=True)
            print(f"\nğŸ“ Expertise Areas:")
            for topic, level in expertise[:10]:
                bar = "â–ˆ" * int(level * 20) + "â–‘" * (20 - int(level * 20))
                print(f"   {topic:20s} [{bar}] {level:.0%}")
        
        # æˆ¦ç•¥å¥½ã¿
        if profile['strategy_preference']:
            print(f"\nğŸ¯ Strategy Preferences:")
            sorted_strat = sorted(profile['strategy_preference'].items(), key=lambda x: x[1], reverse=True)
            for strategy, score in sorted_strat[:5]:
                print(f"   â€¢ {strategy}: {score:.2f}")
        print("=" * 80 + "\n")
    
    def _show_config(self):
        """è¨­å®šè¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("âš™ï¸  System Configuration")
        print("=" * 80)
        config = self.llm.config
        print(f"\nğŸ”§ Basic Settings:")
        print(f"   Model: {config.model}")
        print(f"   Max Tokens: {config.max_tokens}")
        print(f"   Temperature: {config.temperature}")
        print(f"   Similarity Threshold: {config.similarity_threshold}")
        print(f"\nğŸš€ Features:")
        print(f"   Adaptive: {'âœ…' if config.adaptive else 'âŒ'}")
        print(f"   Vector DB: {'âœ…' if config.vec_db else 'âŒ'}")
        print(f"   Knowledge Graph: {'âœ…' if config.knowledge_graph else 'âŒ'}")
        print(f"   Chain of Thought: {'âœ…' if config.chain_of_thought else 'âŒ'}")
        print(f"   Quantum Optimization: {'âœ…' if config.quantum.enabled else 'âŒ'}")
        print(f"   Genetic Evolution: {'âœ…' if config.genetic.enabled else 'âŒ'}")
        print(f"   Swarm Intelligence: {'âœ…' if config.swarm.enabled else 'âŒ'}")
        print(f"   RLHF: {'âœ…' if config.rlhf.enabled else 'âŒ'}")
        print("=" * 80 + "\n")
    
    def _set_config(self, key: str, value: str):
        """è¨­å®šå¤‰æ›´"""
        try:
            if key == 'temperature':
                self.llm.config.temperature = float(value)
                print(f"âœ… Temperature set to {value}")
            elif key == 'max_tokens':
                self.llm.config.max_tokens = int(value)
                print(f"âœ… Max tokens set to {value}")
            elif key == 'model':
                if value in self.llm.MODELS:
                    self.llm.config.model = value
                    print(f"âœ… Model set to {value}")
                else:
                    print(f"âŒ Unknown model: {value}")
            else:
                print(f"âŒ Unknown config key: {key}")
        except ValueError:
            print(f"âŒ Invalid value for {key}")
    
    def _analyze_text(self, text: str):
        """ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        print("\n" + "=" * 80)
        print("ğŸ” Text Analysis")
        print("=" * 80)
        intent, complexity = self.llm._analyze_query(text)
        print(f"\nğŸ“Š Analysis Results:")
        print(f"   Intent: {intent.value}")
        print(f"   Complexity: {complexity.value}")
        print(f"   Word Count: {len(text.split())}")
        print(f"   Character Count: {len(text)}")

        # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
        sentiment = sum(1 for w in ['good', 'great', 'excellent'] if w in text.lower()) - \
                   sum(1 for w in ['bad', 'terrible', 'awful'] if w in text.lower())
        sentiment_label = "Positive" if sentiment > 0 else "Negative" if sentiment < 0 else "Neutral"
        print(f"   Sentiment: {sentiment_label}")
        
        # æ¨å¥¨æˆ¦ç•¥
        strategy = self.llm._select_strategy(intent, complexity)
        print(f"   Recommended Strategy: {strategy.value}")
        print("=" * 80 + "\n")
    
    def _search_knowledge(self, query: str):
        """çŸ¥è­˜ã‚°ãƒ©ãƒ•æ¤œç´¢"""
        if not self.llm.knowledge_graph:
            print("âŒ Knowledge graph disabled")
            return
        print("\n" + "=" * 80)
        print(f"ğŸ” Searching Knowledge Graph: '{query}'")
        print("=" * 80)
        subgraph = self.llm.knowledge_graph.query_subgraph(query, depth=2)
        print(f"\nğŸ“Š Results:")
        print(f"   Nodes Found: {len(subgraph['nodes'])}")
        print(f"   Edges Found: {len(subgraph['edges'])}")
        if subgraph['nodes']:
            print(f"\nğŸ”— Related Nodes:")
            for i, node in enumerate(subgraph['nodes'][:10], 1):
                print(f"   {i}. {node.name} ({node.type}) - Relevance: {node.relevance_score:.2f}")
        else:
            print("\n   No matching nodes found.")
        print("=" * 80 + "\n")
    
    def _show_topics(self):
        """ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§"""
        print("\n" + "=" * 80)
        print("ğŸ“š Topic Distribution")
        print("=" * 80)
        topics = sorted(self.llm.profile['topics'].items(), key=lambda x: x[1], reverse=True)
        if not topics:
            print("\nNo topics recorded yet.")
            print("=" * 80 + "\n")
            return
        total_score = sum(score for _, score in topics)
        print(f"\nğŸ“Š Top 20 Topics:")
        for i, (topic, score) in enumerate(topics[:20], 1):
            percentage = (score / total_score * 100) if total_score > 0 else 0
            bar = "â–ˆ" * int(percentage / 5) + "â–‘" * (20 - int(percentage / 5))
            print(f"   {i:2d}. {topic:20s} [{bar}] {percentage:5.1f}%")
        print(f"\n   Total Topics: {len(topics)}")
        
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.print_welcome()
        while True:
            try:
                query = input("ğŸ‘¤ You: ").strip()
                if not query:
                    continue
                if query.startswith('/'):
                    if not self.handle_command(query):
                        break
                    continue
                print("\nâ³ Processing...")
                response = self.llm.query(query)
                self.history.append((query, response))
                self.print_response(response)
            except KeyboardInterrupt:
                print("\n\nâš ï¸  Interrupted. Type /exit to quit.")
                continue
            except EOFError:
                print("\nğŸ‘‹ Goodbye!")
                break
            except Exception as e:
                print(f"\nâŒ Error: {e}")
                logger.error(f"Chat error: {e}")

# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ====================

def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse
    parser = argparse.ArgumentParser(
        description='Quantum-Enhanced Self-Evolving LLM System v3.0Î³'
    )
    parser.add_argument('--model', default='llama-3.1-8b-instant', help='Base model')
    parser.add_argument('--no-quantum', action='store_true', help='Disable quantum')
    parser.add_argument('--no-genetic', action='store_true', help='Disable genetic')
    parser.add_argument('--no-swarm', action='store_true', help='Disable swarm')
    parser.add_argument('--no-rlhf', action='store_true', help='Disable RLHF')
    parser.add_argument('--query', type=str, help='Single query mode')
    parser.add_argument('--load', type=str, help='Load state')
    parser.add_argument('--debug', action='store_true', help='Debug mode')
    args = parser.parse_args()
    if args.debug:
        logger.logger.setLevel(logging.DEBUG)
    
    # è¨­å®š
    config = SystemConfig(
        model=args.model,
        quantum=QuantumConfig(enabled=not args.no_quantum),
        genetic=GeneticConfig(enabled=not args.no_genetic),
        swarm=SwarmConfig(enabled=not args.no_swarm),
        rlhf=RLHFConfig(enabled=not args.no_rlhf)
    )
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        llm = QuantumLLM(config=config)
        
        # çŠ¶æ…‹èª­ã¿è¾¼ã¿
        if args.load:
            llm.load_state(args.load)
        
        # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚¨ãƒªãƒ¢ãƒ¼ãƒ‰
        if args.query:
            response = llm.query(args.query)
            print(response.text)
            print(f"\nğŸ“Š Metadata:")
            print(f"   Quality: {response.quality_score:.2f}")
            print(f"   Strategy: {response.strategy.value if response.strategy else 'N/A'}")
            print(f"   Cost: ${response.cost:.6f}")
            return
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
        chat = QuantumChat(llm)
        chat.run()
        
        # çµ‚äº†æ™‚ä¿å­˜
        print("\nğŸ’¾ Saving session...")
        llm.save_state()
        stats = llm.get_stats()
        print("\nğŸ“Š Session Summary:")
        print(f"   Queries: {stats['system']['queries']}")
        print(f"   Success Rate: {stats['system']['success_rate']}")
        print(f"   Total Cost: {stats['system']['total_cost']}")
    except ValueError as e:
        print(f"\nâŒ Error: {e}")
        print("Please set GROQ_API_KEY environment variable")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Fatal error: {e}")
        logger.error(f"Fatal: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()
