#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Discord Bot for Quantum-Enhanced Self-Evolving Enterprise LLM System v3.5Î³
ç©¶æ¥µã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’Discordã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«

ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—:
1. pip install discord.py groq numpy scipy
2. export GROQ_API_KEY='your_groq_key'
3. export DISCORD_BOT_TOKEN='your_discord_token'
4. åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«enterprise-llm-chat-verÎ±-5.pyã‚’é…ç½®
5. python discord_quantum_bot.py

æ©Ÿèƒ½:
ğŸ”® Quantum-Inspired Optimization
ğŸ§¬ Genetic Algorithm Prompt Evolution
ğŸŒŠ Swarm Intelligence Multi-Agent
ğŸ¯ RLHF (Reinforcement Learning from Human Feedback)
ğŸ”¬ Scientific Method Application
ğŸ§© Causal Inference Engine
ğŸ¨ Creative Synthesis System
ğŸ” Advanced Verification System
"""

import os
import sys
import asyncio
import discord
from discord import app_commands
from datetime import datetime
import json
from typing import Optional, Dict, List
import traceback

# å…ƒã®Quantum LLMã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    sys.path.insert(0, os.path.dirname(__file__))
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒã‚¤ãƒ•ãƒ³ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«å¤‰æ›ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import importlib.util
    spec = importlib.util.spec_from_file_location(
        "quantum_llm",
        "enterprise-llm-chat-verÎ±-5.py"
    )
    quantum_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(quantum_module)
    
    QuantumLLM = quantum_module.QuantumLLM
    SystemConfig = quantum_module.SystemConfig
    QuantumConfig = quantum_module.QuantumConfig
    GeneticConfig = quantum_module.GeneticConfig
    SwarmConfig = quantum_module.SwarmConfig
    RLHFConfig = quantum_module.RLHFConfig
    Intent = quantum_module.Intent
    Complexity = quantum_module.Complexity
    Strategy = quantum_module.Strategy
    
except Exception as e:
    print(f"âŒ Cannot import Quantum LLM module: {e}")
    print("Make sure enterprise-llm-chat-verÎ±-5.py is in the same directory")
    sys.exit(1)

# Discord Botè¨­å®š
intents = discord.Intents.default()
intents.message_content = True
intents.members = True

bot = discord.Client(intents=intents)
tree = app_commands.CommandTree(bot)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
llm: Optional[QuantumLLM] = None

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ä¼šè©±å±¥æ­´
user_conversations: Dict[int, list] = {}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
session_data = {
    'start_time': datetime.now(),
    'total_queries': 0,
    'successful_queries': 0,
    'quantum_optimizations': 0,
    'genetic_evolutions': 0,
    'swarm_optimizations': 0
}

# ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ç®¡ç†
talk_mode_users: Dict[int, bool] = {}  # è¿½åŠ 


# ==================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ====================

def create_progress_bar(value: float, length: int = 20) -> str:
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”Ÿæˆ"""
    filled = int(value * length)
    return "â–ˆ" * filled + "â–‘" * (length - filled)


def format_response_embed(response, query: str, user: discord.User) -> discord.Embed:
    """å¿œç­”ã‚’Embedã«æ•´å½¢"""
    # ã‚«ãƒ©ãƒ¼é¸æŠ
    if response.quality_score > 0.8:
        color = discord.Color.green()
    elif response.quality_score > 0.6:
        color = discord.Color.blue()
    else:
        color = discord.Color.orange()
    
    # æˆ¦ç•¥çµµæ–‡å­—
    strategy_emoji = {
        Strategy.QUANTUM: "ğŸ”®",
        Strategy.GENETIC: "ğŸ§¬",
        Strategy.SWARM: "ğŸŒŠ",
        Strategy.TREE_SEARCH: "ğŸŒ³",
        Strategy.COT: "ğŸ¤”",
        Strategy.DEBATE: "ğŸ—£ï¸",
        Strategy.DIRECT: "ğŸ“"
    }
    
    emoji = strategy_emoji.get(response.strategy, "ğŸ’¬")
    
    embed = discord.Embed(
        title=f"{emoji} Quantum AI Response",
        description=response.text[:4000] if len(response.text) <= 4000 else response.text[:3997] + "...",
        color=color,
        timestamp=datetime.now()
    )
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    metadata_lines = []
    
    if response.strategy:
        metadata_lines.append(f"**Strategy**: {response.strategy.value}")
    if response.complexity:
        metadata_lines.append(f"**Complexity**: {response.complexity.value}")
    if response.intent:
        metadata_lines.append(f"**Intent**: {response.intent.value}")
    
    metadata_lines.append(f"**Quality**: {response.quality_score:.2%}")
    metadata_lines.append(f"**Confidence**: {response.confidence:.2%}")
    
    if response.quantum_optimized:
        metadata_lines.append("**ğŸ”® Quantum Optimized**")
    if response.genetic_fitness > 0:
        metadata_lines.append(f"**ğŸ§¬ Fitness**: {response.genetic_fitness:.2f}")
    if response.swarm_consensus > 0:
        metadata_lines.append(f"**ğŸŒŠ Consensus**: {response.swarm_consensus:.2%}")
    
    embed.add_field(
        name="ğŸ“Š Analysis",
        value="\n".join(metadata_lines),
        inline=False
    )
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    perf_lines = [
        f"**Latency**: {response.latency:.0f}ms",
        f"**Tokens**: {response.tokens}",
        f"**Cost**: ${response.cost:.6f}"
    ]
    
    if response.cached:
        perf_lines.append("**ğŸ’¾ Cached Response**")
    
    embed.add_field(
        name="âš¡ Performance",
        value="\n".join(perf_lines),
        inline=False
    )
    
    # å“è³ªã‚¹ã‚³ã‚¢
    if any([response.coherence_score, response.relevance_score, response.completeness_score]):
        quality_bar = create_progress_bar(response.quality_score)
        embed.add_field(
            name="â­ Quality Breakdown",
            value=f"Overall: [{quality_bar}] {response.quality_score:.0%}\n"
                  f"Coherence: {response.coherence_score:.0%} | "
                  f"Relevance: {response.relevance_score:.0%} | "
                  f"Completeness: {response.completeness_score:.0%}",
            inline=False
        )
    
    # æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—
    if response.reasoning_steps and len(response.reasoning_steps) > 0:
        steps_preview = "\n".join(f"{i+1}. {step[:80]}" for i, step in enumerate(response.reasoning_steps[:3]))
        embed.add_field(
            name="ğŸ§  Reasoning Steps",
            value=steps_preview,
            inline=False
        )
    
    # ãƒšãƒ«ã‚½ãƒŠæƒ…å ±
    if response.personas_involved:
        embed.add_field(
            name="ğŸ­ Personas Consulted",
            value=", ".join(response.personas_involved),
            inline=False
        )
    
    embed.set_footer(text=f"Query by {user.name}")
    
    return embed

# ==================== Botã‚¤ãƒ™ãƒ³ãƒˆ ====================

# å®šæœŸä¿å­˜ã‚¿ã‚¹ã‚¯ï¼ˆon_readyã®å¤–ã«å®šç¾©ï¼‰
async def auto_save():
    """å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    await bot.wait_until_ready()
    while not bot.is_closed():
        await asyncio.sleep(1800)  # 30åˆ†
        if llm:
            try:
                llm.save_state('discord_quantum_state.json')
                print('ğŸ’¾ Auto-saved state')
            except Exception as e:
                print(f'âŒ Auto-save failed: {e}')

@bot.event
async def on_ready():
    """Botèµ·å‹•æ™‚ - çµ±åˆç‰ˆ"""
    global llm
    
    print(f'âœ… {bot.user} logged in')
    print(f'ğŸ¤– Bot ID: {bot.user.id}')
    print(f'ğŸŒ Servers: {len(bot.guilds)}')
    print('=' * 80)
    
    # Quantum LLMã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    try:
        config = SystemConfig(
            model='llama-3.1-8b-instant',
            adaptive=True,
            multi_armed_bandit=True,
            long_term_memory=True,
            knowledge_graph=True,
            chain_of_thought=True,
            self_reflection=True,
            ensemble_learning=True,
            metacognition=True,
            tree_of_thoughts=True,
            debate_mode=True,
            critic_system=True,
            confidence_calibration=True,
            active_learning=True,
            curriculum_learning=True,
            quantum=QuantumConfig(enabled=True),
            genetic=GeneticConfig(enabled=True),
            swarm=SwarmConfig(enabled=True),
            rlhf=RLHFConfig(enabled=True),
            adversarial_testing=True,
            causal_reasoning=True,
            creative_synthesis=True,
            predictive_modeling=True,
            verification_system=True,
            scientific_method=True,
            real_time_learning=True,
            meta_learning=True
        )
        
        llm = QuantumLLM(config=config)
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        try:
            llm.load_state('discord_quantum_state.json')
            print('ğŸ“‚ Loaded existing state')
        except:
            print('â„¹ï¸  Starting fresh session')
        
        print('ğŸš€ Quantum LLM System ready')
        print('ğŸ”® All advanced features enabled')
        
    except Exception as e:
        print(f'âŒ LLM initialization error: {e}')
        traceback.print_exc()
        sys.exit(1)
    
    # ğŸ”§ ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’åŒæœŸï¼ˆã‚¯ãƒªã‚¢ã¯å‰Šé™¤ï¼‰
    try:
        print('ğŸ”„ Syncing commands...')
        
        # ã‚³ãƒãƒ³ãƒ‰ã‚’åŒæœŸï¼ˆæ—¢å­˜ã®ã‚³ãƒãƒ³ãƒ‰ã¯è‡ªå‹•çš„ã«ä¸Šæ›¸ãã•ã‚Œã‚‹ï¼‰
        synced = await tree.sync()
        print(f'âœ… Synced {len(synced)} slash commands')
        
        # åŒæœŸã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ä¸€è¦§ã‚’è¡¨ç¤º
        if synced:
            print('ğŸ“‹ Available commands:')
            for cmd in synced:
                print(f'   â€¢ /{cmd.name}: {cmd.description}')
        else:
            print('âš ï¸ No commands were synced!')
        
    except Exception as e:
        print(f'âŒ Command sync error: {e}')
        traceback.print_exc()
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¨­å®š
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.listening,
            name="/help | ğŸ”® Quantum AI"
        )
    )
    
    print('=' * 80)
    print('âœ¨ Bot is ready to use!')
    
    # å®šæœŸä¿å­˜ã‚¿ã‚¹ã‚¯é–‹å§‹
    bot.loop.create_task(auto_save())


@bot.event
async def on_message(message: discord.Message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡æ™‚"""
    if message.author.bot:
        return
    
    user_id = message.author.id
    
    # ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    if user_id in talk_mode_users and talk_mode_users[user_id]:
        # ä¼šè©±ãƒ¢ãƒ¼ãƒ‰: å…¨ã¦ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åå¿œ
        query = message.content.strip()
        
        if not query:
            return
        
        # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã¯ç„¡è¦–
        if query.startswith('/'):
            return
        
        await handle_query(message, query)
        return
    
    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå ´åˆã¯ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¾“æ¥é€šã‚Šï¼‰
    if bot.user in message.mentions:
        query = message.content.replace(f'<@{bot.user.id}>', '').strip()
        
        if not query:
            await message.channel.send('â“ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„')
            return
        
        await handle_query(message, query)


async def handle_query(message: discord.Message, query: str):
    """ã‚¯ã‚¨ãƒªå‡¦ç†"""
    if not llm:
        await message.channel.send('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“')
        return
    
    user_id = message.author.id
    
    # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
    async with message.channel.typing():
        try:
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            response = await llm.query_async(query)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            session_data['total_queries'] += 1
            if response.success:
                session_data['successful_queries'] += 1
            if response.quantum_optimized:
                session_data['quantum_optimizations'] += 1
            if response.genetic_fitness > 0:
                session_data['genetic_evolutions'] += 1
            if response.swarm_consensus > 0:
                session_data['swarm_optimizations'] += 1
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã«è¿½åŠ 
            if user_id not in user_conversations:
                user_conversations[user_id] = []
            
            user_conversations[user_id].append({
                'query': query[:200],
                'response': response.text[:200],
                'quality': response.quality_score,
                'strategy': response.strategy.value if response.strategy else None,
                'timestamp': datetime.now().isoformat()
            })
            
            # æœ€æ–°50ä»¶ã®ã¿ä¿æŒ
            if len(user_conversations[user_id]) > 50:
                user_conversations[user_id] = user_conversations[user_id][-50:]
            
            # Embedä½œæˆ
            embed = format_response_embed(response, query, message.author)
            
            await message.reply(embed=embed)
            
            # é•·ã„å¿œç­”ã¯åˆ†å‰²é€ä¿¡
            if len(response.text) > 4000:
                remaining = response.text[4000:]
                chunks = [remaining[i:i+1900] for i in range(0, len(remaining), 1900)]
                for chunk in chunks:
                    await message.channel.send(f"```\n{chunk}\n```")
            
        except Exception as e:
            error_embed = discord.Embed(
                title="âŒ Error",
                description=f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                color=discord.Color.red()
            )
            await message.reply(embed=error_embed)
            print(f"Error: {e}")
            traceback.print_exc()

# ==================== ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ ====================

@tree.command(name='swarm', description='ç¾¤çŸ¥èƒ½ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º')
async def swarm_command(interaction: discord.Interaction):
    """ç¾¤çŸ¥èƒ½"""
    # deferã‚’è¿½åŠ 
    await interaction.response.defer()
    
    if not llm or not llm.swarm:
        await interaction.followup.send('âŒ ç¾¤çŸ¥èƒ½ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    embed = discord.Embed(
        title="ğŸŒŠ Swarm Intelligence",
        description="å¤šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤çŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ ",
        color=discord.Color.blue()
    )
    
    swarm = llm.swarm
    
    embed.add_field(
        name="ğŸ Swarm Configuration",
        value=f"**Agents**: {len(swarm.agents)}\n"
              f"**Inertia**: {llm.config.swarm.inertia_weight}\n"
              f"**Cognitive**: {llm.config.swarm.cognitive_weight}\n"
              f"**Social**: {llm.config.swarm.social_weight}",
        inline=True
    )
    
    if swarm.agents:
        personas_str = "\n".join([
            f"â€¢ {agent.persona.value}: {agent.best_fitness:.3f}"
            for agent in swarm.agents
        ])
        embed.add_field(
            name="ğŸ­ Agent Personas",
            value=personas_str,
            inline=True
        )
    
    embed.add_field(
        name="ğŸ“Š Performance",
        value=f"**Global Best**: {swarm.global_best_fitness:.3f}\n"
              f"**Total Optimizations**: {llm.metrics['swarm_optimizations']}",
        inline=False
    )
    
    await interaction.followup.send(embed=embed)


# ==================== è¿½åŠ ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ãƒãƒ³ãƒ‰ ====================

@tree.command(name='clear', description='ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢')
async def clear_command(interaction: discord.Interaction):
    """å±¥æ­´ã‚¯ãƒªã‚¢"""
    # deferã‚’è¿½åŠ 
    await interaction.response.defer(ephemeral=True)
    
    user_id = interaction.user.id
    
    if user_id in user_conversations:
        del user_conversations[user_id]
    
    if llm:
        llm.context_window.clear()
    
    await interaction.followup.send('ğŸ—‘ï¸ ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ', ephemeral=True)
@tree.command(name='talk', description='AIã¨ã®ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆ')
@app_commands.describe(mode='ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã®ON/OFF')
@app_commands.choices(mode=[
    app_commands.Choice(name='ON', value='on'),
    app_commands.Choice(name='OFF', value='off')
])
async def talk_command(interaction: discord.Interaction, mode: str):
    """ä¼šè©±ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ"""
    # æœ€åˆã«å¿œç­”ã‚’ç¢ºä¿ï¼ˆé‡è¦ï¼ï¼‰
    await interaction.response.defer(ephemeral=True)
    
    user_id = interaction.user.id
    
    if mode.lower() == 'on':
        # ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ³
        talk_mode_users[user_id] = True
        embed = discord.Embed(
            title="ğŸ’¬ Talk Mode: ON",
            description="ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼\n"
                       "ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ã¨ã€AIãŒè‡ªå‹•çš„ã«è¿”ç­”ã—ã¾ã™",
            color=discord.Color.green()
        )
        embed.add_field(
            name="ğŸ¯ ä½¿ã„æ–¹",
            value="â€¢ æ™®é€šã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ã ã‘ã§OK\n"
                  "â€¢ `/talk mode:off` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†\n"
                  "â€¢ `/clear` ã§ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ",
            inline=False
        )
        embed.add_field(
            name="âœ¨ æ©Ÿèƒ½",
            value="â€¢ å…¨ã¦ã®é«˜åº¦ãªAIæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½\n"
                  "â€¢ ä¼šè©±å±¥æ­´ãŒè‡ªå‹•çš„ã«ä¿å­˜\n"
                  "â€¢ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã—ãŸè¿”ç­”",
            inline=False
        )
        embed.add_field(
            name="âš ï¸ æ³¨æ„",
            value="â€¢ Botã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯åå¿œã—ã¾ã›ã‚“\n"
                  "â€¢ ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯åå¿œã—ã¾ã›ã‚“",
            inline=False
        )
    else:  # mode == 'off'
        # ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ•
        if user_id in talk_mode_users:
            talk_mode_users[user_id] = False
            del talk_mode_users[user_id]
        
        embed = discord.Embed(
            title="ğŸ’¬ Talk Mode: OFF",
            description="ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã—ãŸ",
            color=discord.Color.red()
        )
        embed.add_field(
            name="â„¹ï¸ ä½¿ã„æ–¹",
            value="`/talk mode:on` ã§ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã§ãã¾ã™\n"
                  "Botã«ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆ@llmï¼‰ã—ã¦è³ªå•ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™",
            inline=False
        )
    
    # deferã—ãŸå¾Œã¯followupã‚’ä½¿ç”¨
    await interaction.followup.send(embed=embed, ephemeral=True)

@tree.command(name='analogies', description='æ¦‚å¿µã®é¡æ¨ã‚’ç™ºè¦‹')
async def analogies_command(interaction: discord.Interaction, concept: str):
    """é¡æ¨ç™ºè¦‹"""
    if not llm or not llm.creative_synthesizer:
        await interaction.response.send_message('âŒ å‰µé€ çš„çµ±åˆãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    analogies = llm.creative_synthesizer.find_analogies(concept, top_k=10)
    
    if not analogies:
        await interaction.followup.send(f'ğŸ” "{concept}" ã®é¡æ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
        return
    
    embed = discord.Embed(
        title=f"ğŸ” Analogies for: {concept}",
        color=discord.Color.blue()
    )
    
    analogies_str = "\n".join([
        f"{i}. {create_progress_bar(sim, 15)} {sim:+.3f} - {related}"
        for i, (related, sim) in enumerate(analogies[:8], 1)
    ])
    
    embed.add_field(
        name="ğŸ“Š Similar Concepts",
        value=analogies_str,
        inline=False
    )
    
    if len(analogies) >= 2:
        top1, top2 = analogies[0][0], analogies[1][0]
        embed.add_field(
            name="ğŸ’¡ Suggested Syntheses",
            value=f"Try: `/synthesize {concept} {top1}`\n"
                  f"Or: `/synthesize {concept} {top2}`",
            inline=False
        )
    
    await interaction.followup.send(embed=embed)

@tree.command(name='trust', description='ã‚·ã‚¹ãƒ†ãƒ ã®ä¿¡é ¼ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º')
async def trust_command(interaction: discord.Interaction):
    """ä¿¡é ¼ã‚¹ã‚³ã‚¢"""
    # deferã‚’è¿½åŠ 
    await interaction.response.defer()
    
    if not llm or not llm.verification_system:
        await interaction.followup.send('âŒ æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    trust_score = llm.verification_system.get_trust_score()
    
    embed = discord.Embed(
        title="ğŸ” System Trust Score",
        color=discord.Color.blue()
    )
    
    # ä¿¡é ¼ã‚¹ã‚³ã‚¢
    trust_bar = create_progress_bar(trust_score, 30)
    embed.add_field(
        name="ğŸ“Š Overall Trust",
        value=f"[{trust_bar}] **{trust_score:.0%}**",
        inline=False
    )
    
    # è©•ä¾¡
    if trust_score > 0.8:
        rating = "ğŸŒŸ EXCELLENT"
        desc = "Responses are highly trustworthy"
        color = discord.Color.green()
    elif trust_score > 0.6:
        rating = "âœ… GOOD"
        desc = "Responses are generally reliable"
        color = discord.Color.blue()
    elif trust_score > 0.4:
        rating = "âš ï¸ MODERATE"
        desc = "Exercise caution with responses"
        color = discord.Color.orange()
    else:
        rating = "âŒ LOW"
        desc = "System needs more calibration"
        color = discord.Color.red()
    
    embed.color = color
    embed.add_field(
        name="ğŸ¯ Rating",
        value=f"{rating}\n{desc}",
        inline=False
    )
    
    # æ¤œè¨¼çµ±è¨ˆ
    records = llm.verification_system.records
    if records:
        total = len(records)
        verified = sum(1 for r in records if r.result)
        
        embed.add_field(
            name="ğŸ“‹ Verification Statistics",
            value=f"**Total**: {total}\n"
                  f"**Verified**: {verified} ({verified/total:.0%})\n"
                  f"**Rejected**: {total - verified} ({(total-verified)/total:.0%})",
            inline=False
        )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='adversarial', description='æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ')
async def adversarial_command(interaction: discord.Interaction):
    """æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆ"""
    if not llm or not llm.adversarial_tester:
        await interaction.response.send_message('âŒ æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    user_id = interaction.user.id
    
    if user_id not in user_conversations or not user_conversations[user_id]:
        await interaction.response.send_message('âŒ ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    last_conv = user_conversations[user_id][-1]
    last_query = last_conv['query']
    
    embed = discord.Embed(
        title="ğŸª Adversarial Robustness Test",
        description=f"Testing query: {last_query[:60]}...",
        color=discord.Color.orange()
    )
    
    # æ•µå¯¾çš„ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
    adversarial_queries = llm.adversarial_tester.generate_adversarial_queries(last_query)
    
    embed.add_field(
        name="ğŸ“‹ Generated Variants",
        value=f"Generated {len(adversarial_queries)} adversarial examples",
        inline=False
    )
    
    # ç°¡æ˜“ãƒ†ã‚¹ãƒˆï¼ˆ3ã¤ã®ã¿ï¼‰
    consistency_scores = []
    for i, adv_q in enumerate(adversarial_queries[:3], 1):
        try:
            adv_response = await llm.query_async(adv_q)  # ä¿®æ­£
            
            # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ï¼‰
            orig_words = set(last_conv['response'].lower().split())
            adv_words = set(adv_response.text.lower().split())
            
            if orig_words and adv_words:
                similarity = len(orig_words & adv_words) / len(orig_words | adv_words)
                consistency_scores.append(similarity)
        except Exception as e:
            print(f"Adversarial test error: {e}")
            pass
    
    if consistency_scores:
        import statistics
        avg_consistency = statistics.mean(consistency_scores)
        min_consistency = min(consistency_scores)
        
        consist_bar = create_progress_bar(avg_consistency, 20)
        
        embed.add_field(
            name="ğŸ“Š Test Results",
            value=f"**Average Consistency**: [{consist_bar}] {avg_consistency:.0%}\n"
                  f"**Minimum Consistency**: {min_consistency:.0%}\n"
                  f"**Variants Tested**: {len(consistency_scores)}",
            inline=False
        )
        
        # è©•ä¾¡
        if avg_consistency > 0.7:
            assessment = "âœ… ROBUST - High adversarial resistance"
            color = discord.Color.green()
        elif avg_consistency > 0.5:
            assessment = "âš ï¸ MODERATE - Some inconsistencies"
            color = discord.Color.orange()
        else:
            assessment = "âŒ VULNERABLE - Significant weaknesses"
            color = discord.Color.red()
        
        embed.color = color
        embed.add_field(
            name="ğŸ¯ Assessment",
            value=assessment,
            inline=False
        )
    
    await interaction.followup.send(embed=embed)

@tree.command(name='export', description='ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
async def export_command(interaction: discord.Interaction):
    """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    user_id = interaction.user.id
    
    if user_id not in user_conversations or not user_conversations[user_id]:
        await interaction.response.send_message('âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True, ephemeral=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"export_{interaction.user.name}_{timestamp}.json"
    
    export_data = {
        'user': {
            'id': user_id,
            'name': interaction.user.name
        },
        'session_id': f"{user_id}_{timestamp}",
        'timestamp': timestamp,
        'conversations': user_conversations[user_id],
        'summary': {
            'total_conversations': len(user_conversations[user_id]),
            'avg_quality': statistics.mean(c['quality'] for c in user_conversations[user_id]),
            'strategies_used': list(set(c['strategy'] for c in user_conversations[user_id] if c['strategy']))
        }
    }
    
    try:
        import io
        
        # JSONã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
        file = discord.File(
            io.BytesIO(json_str.encode('utf-8')),
            filename=filename
        )
        
        await interaction.followup.send(
            'ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ',
            file=file,
            ephemeral=True
        )
    except Exception as e:
        await interaction.followup.send(f'âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}', ephemeral=True)


@tree.command(name='compare', description='è¤‡æ•°ã®æˆ¦ç•¥ã‚’æ¯”è¼ƒ')
async def compare_command(interaction: discord.Interaction, query: str):
    """æˆ¦ç•¥æ¯”è¼ƒ"""
    if not llm:
        await interaction.response.send_message('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    embed = discord.Embed(
        title="ğŸ”¬ Strategy Comparison",
        description=f"Query: {query[:100]}",
        color=discord.Color.blue()
    )
    
    # è¤‡æ•°æˆ¦ç•¥ã§ãƒ†ã‚¹ãƒˆ
    strategies = [Strategy.DIRECT, Strategy.COT, Strategy.QUANTUM] if llm.quantum_optimizer else [Strategy.DIRECT, Strategy.COT]
    
    results = []
    for strategy in strategies:
        try:
            # ä¸€æ™‚çš„ã«æˆ¦ç•¥ã‚’å›ºå®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
            response = await llm.query_async(query)  # ä¿®æ­£
            results.append({
                'strategy': strategy.value if hasattr(strategy, 'value') else str(strategy),
                'quality': response.quality_score,
                'confidence': response.confidence,
                'latency': response.latency,
                'cost': response.cost
            })
        except Exception as e:
            print(f"Compare error for {strategy}: {e}")
            pass
    
    if results:
        # çµæœã‚’æ¯”è¼ƒ
        for i, result in enumerate(results, 1):
            quality_bar = create_progress_bar(result['quality'], 15)
            
            embed.add_field(
                name=f"{i}. {result['strategy'].upper()}",
                value=f"Quality: [{quality_bar}] {result['quality']:.0%}\n"
                      f"Confidence: {result['confidence']:.0%}\n"
                      f"Latency: {result['latency']:.0f}ms\n"
                      f"Cost: ${result['cost']:.6f}",
                inline=True
            )
        
        # æœ€è‰¯æˆ¦ç•¥
        best = max(results, key=lambda x: x['quality'])
        embed.add_field(
            name="ğŸ† Best Strategy",
            value=f"**{best['strategy'].upper()}** with {best['quality']:.0%} quality",
            inline=False
        )
    else:
        embed.add_field(
            name="âŒ Error",
            value="å…¨ã¦ã®æˆ¦ç•¥ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
            inline=False
        )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='benchmark', description='ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ')
async def benchmark_command(interaction: discord.Interaction):
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    if not llm:
        await interaction.response.send_message('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    if not interaction.user.guild_permissions.administrator:
        await interaction.response.send_message('âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ç®¡ç†è€…ã®ã¿ä½¿ç”¨ã§ãã¾ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    embed = discord.Embed(
        title="âš¡ System Benchmark",
        description="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...",
        color=discord.Color.gold()
    )
    
    test_queries = [
        "What is 2+2?",
        "Explain quantum computing briefly",
        "Write a Python function for Fibonacci"
    ]
    
    results = []
    for query in test_queries:
        import time
        start = time.time()
        try:
            response = await llm.query_async(query)  # ä¿®æ­£
            elapsed = (time.time() - start) * 1000
            
            results.append({
                'query': query[:30],
                'latency': elapsed,
                'quality': response.quality_score,
                'strategy': response.strategy.value if response.strategy else 'direct'
            })
        except Exception as e:
            print(f"Benchmark error for '{query}': {e}")
            continue
    
    if not results:
        await interaction.followup.send('âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆãŒå…¨ã¦å¤±æ•—ã—ã¾ã—ãŸ')
        return
    
    # çµ±è¨ˆ
    import statistics
    avg_latency = statistics.mean(r['latency'] for r in results)
    avg_quality = statistics.mean(r['quality'] for r in results)
    
    embed.description = f"**Tests**: {len(results)}\n" \
                       f"**Avg Latency**: {avg_latency:.0f}ms\n" \
                       f"**Avg Quality**: {avg_quality:.0%}"
    
    # å„ãƒ†ã‚¹ãƒˆçµæœ
    for i, result in enumerate(results, 1):
        embed.add_field(
            name=f"Test {i}: {result['query']}...",
            value=f"Latency: {result['latency']:.0f}ms\n"
                  f"Quality: {result['quality']:.0%}\n"
                  f"Strategy: {result['strategy']}",
            inline=True
        )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='config', description='ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’è¡¨ç¤º')
async def config_command(interaction: discord.Interaction):
    """è¨­å®šè¡¨ç¤º"""
    if not llm:
        await interaction.response.send_message('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    config = llm.config
    
    embed = discord.Embed(
        title="âš™ï¸ System Configuration",
        color=discord.Color.blue()
    )
    
    # åŸºæœ¬è¨­å®š
    embed.add_field(
        name="ğŸ”§ Basic Settings",
        value=f"**Model**: {config.model}\n"
              f"**Max Tokens**: {config.max_tokens}\n"
              f"**Temperature**: {config.temperature}\n"
              f"**Similarity Threshold**: {config.similarity_threshold:.2f}",
        inline=False
    )
    
    # æ©Ÿèƒ½ãƒ•ãƒ©ã‚°
    features = []
    if config.adaptive: features.append("âœ… Adaptive")
    if config.vec_db: features.append("âœ… Vector DB")
    if config.knowledge_graph: features.append("âœ… Knowledge Graph")
    if config.chain_of_thought: features.append("âœ… Chain of Thought")
    if config.quantum.enabled: features.append("âœ… Quantum")
    if config.genetic.enabled: features.append("âœ… Genetic")
    if config.swarm.enabled: features.append("âœ… Swarm")
    if config.rlhf.enabled: features.append("âœ… RLHF")
    
    embed.add_field(
        name="ğŸš€ Enabled Features",
        value="\n".join(features) if features else "No features enabled",
        inline=False
    )
    
    ultimate_features = []
    if config.adversarial_testing: ultimate_features.append("âœ… Adversarial Testing")
    if config.causal_reasoning: ultimate_features.append("âœ… Causal Reasoning")
    if config.creative_synthesis: ultimate_features.append("âœ… Creative Synthesis")
    if config.predictive_modeling: ultimate_features.append("âœ… Predictive Modeling")
    if config.verification_system: ultimate_features.append("âœ… Verification System")
    if config.scientific_method: ultimate_features.append("âœ… Scientific Method")
    
    if ultimate_features:
        embed.add_field(
            name="ğŸŒŸ Ultimate Features",
            value="\n".join(ultimate_features),
            inline=False
        )
    
    await interaction.response.send_message(embed=embed)


@tree.command(name='about', description='Botã«ã¤ã„ã¦')
async def about_command(interaction: discord.Interaction):
    """About"""
    embed = discord.Embed(
        title="ğŸ”® Quantum-Enhanced AI Assistant",
        description="ç©¶æ¥µã®è‡ªå·±é€²åŒ–å‹ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºLLMã‚·ã‚¹ãƒ†ãƒ  v3.5Î³ ULTIMATE",
        color=discord.Color.purple()
    )
    
    embed.add_field(
        name="âœ¨ Core Technologies",
        value="â€¢ ğŸ”® Quantum-Inspired Optimization (QAOA)\n"
              "â€¢ ğŸ§¬ Genetic Algorithm Evolution\n"
              "â€¢ ğŸŒŠ Swarm Intelligence (PSO)\n"
              "â€¢ ğŸ¯ Reinforcement Learning (RLHF)\n"
              "â€¢ ğŸ§© Dynamic Knowledge Graph\n"
              "â€¢ ğŸ” Multi-Layer Verification",
        inline=False
    )
    
    embed.add_field(
        name="ğŸŒŸ Ultimate Features",
        value="â€¢ ğŸ§© Causal Inference Engine\n"
              "â€¢ ğŸ¨ Creative Synthesis System\n"
              "â€¢ ğŸ”¬ Scientific Method Application\n"
              "â€¢ ğŸª Adversarial Testing\n"
              "â€¢ ğŸ”® Predictive Modeling\n"
              "â€¢ ğŸ“Š Meta-Learning & Analysis",
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“Š Stats",
        value=f"**Servers**: {len(bot.guilds)}\n"
              f"**Uptime**: {(datetime.now() - session_data['start_time']).seconds // 3600}h\n"
              f"**Total Queries**: {session_data['total_queries']}\n"
              f"**Success Rate**: {session_data['successful_queries']/max(session_data['total_queries'],1):.0%}",
        inline=False
    )
    
    embed.add_field(
        name="ğŸ”— Commands",
        value="Use `/help` to see all available commands",
        inline=False
    )
    
    embed.set_footer(text="Powered by GROQ & Claude.ai")
    
    await interaction.response.send_message(embed=embed)


# ==================== ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ====================

@bot.event
async def on_app_command_error(interaction: discord.Interaction, error: app_commands.AppCommandError):
    """ã‚³ãƒãƒ³ãƒ‰ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    if isinstance(error, app_commands.CommandOnCooldown):
        await interaction.response.send_message(
            f'â³ ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ã§ã™ã€‚{error.retry_after:.1f}ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚',
            ephemeral=True
        )
    elif isinstance(error, app_commands.MissingPermissions):
        await interaction.response.send_message(
            'âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚',
            ephemeral=True
        )
    else:
        print(f'Command error: {error}')
        traceback.print_exc()
        
        if not interaction.response.is_done():
            await interaction.response.send_message(
                f'âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)}',
                ephemeral=True
            )

@tree.command(name='rlhf', description='å¼·åŒ–å­¦ç¿’æƒ…å ±ã‚’è¡¨ç¤º')
async def rlhf_command(interaction: discord.Interaction):
    """RLHF"""
    # deferã‚’è¿½åŠ 
    await interaction.response.defer()
    
    if not llm or not llm.rlhf:
        await interaction.followup.send('âŒ RLHFãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    embed = discord.Embed(
        title="ğŸ¯ Reinforcement Learning from Human Feedback",
        description="äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰å­¦ç¿’",
        color=discord.Color.orange()
    )
    
    rlhf = llm.rlhf
    
    embed.add_field(
        name="ğŸ§  Learning Status",
        value=f"**States Explored**: {len(rlhf.state_visits)}\n"
              f"**Q-Table Size**: {len(rlhf.q_table)}\n"
              f"**Total Updates**: {sum(rlhf.state_visits.values())}\n"
              f"**Learning Rate**: {llm.config.rlhf.learning_rate}",
        inline=False
    )
    
    if rlhf.reward_history:
        import statistics
        avg_reward = statistics.mean(rlhf.reward_history)
        recent = rlhf.reward_history[-10:] if len(rlhf.reward_history) >= 10 else rlhf.reward_history
        recent_avg = statistics.mean(recent)
        
        trend = "ğŸ“ˆ Improving" if recent_avg > avg_reward else "ğŸ“‰ Declining" if recent_avg < avg_reward else "â¡ï¸ Stable"
        
        embed.add_field(
            name="ğŸ“ˆ Rewards",
            value=f"**Average**: {avg_reward:.3f}\n"
                  f"**Recent (10)**: {recent_avg:.3f}\n"
                  f"**Trend**: {trend}",
            inline=False
        )
    
    await interaction.followup.send(embed=embed)

@tree.command(name='knowledge', description='çŸ¥è­˜ã‚°ãƒ©ãƒ•æƒ…å ±ã‚’è¡¨ç¤º')
async def knowledge_command(interaction: discord.Interaction):
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•"""
    # deferã‚’è¿½åŠ 
    await interaction.response.defer()
    
    if not llm or not llm.knowledge_graph:
        await interaction.followup.send('âŒ çŸ¥è­˜ã‚°ãƒ©ãƒ•ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    kg = llm.knowledge_graph
    
    embed = discord.Embed(
        title="ğŸ§© Knowledge Graph",
        description="å‹•çš„çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ",
        color=discord.Color.teal()
    )
    
    embed.add_field(
        name="ğŸ“Š Graph Statistics",
        value=f"**Nodes**: {len(kg.nodes)}\n"
              f"**Edges**: {len(kg.edges)}\n"
              f"**Communities**: {len(kg.communities)}",
        inline=True
    )
    
    # ä¸­å¿ƒæ€§ã®é«˜ã„ãƒãƒ¼ãƒ‰
    central_nodes = kg.get_central_nodes(5)
    if central_nodes:
        central_str = "\n".join([
            f"â€¢ {kg.nodes[nid].name} (degree: {degree})"
            for nid, degree in central_nodes
        ])
        embed.add_field(
            name="ğŸŒŸ Central Concepts",
            value=central_str,
            inline=True
        )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='causal', description='å› æœæ¨è«–ã‚’å®Ÿè¡Œ')
async def causal_command(interaction: discord.Interaction, event: str):
    """å› æœæ¨è«–"""
    if not llm or not llm.causal_engine:
        await interaction.response.send_message('âŒ å› æœæ¨è«–ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    embed = discord.Embed(
        title="ğŸ§© Causal Inference",
        description=f"Event: {event}",
        color=discord.Color.purple()
    )
    
    # åŸå› ã‚’æ¨è«–
    causes = llm.causal_engine.infer_cause(event, depth=3)
    
    if causes:
        causes_str = "\n".join([
            f"{i}. {create_progress_bar(prob)} {prob:.0%} - {cause[:50]}"
            for i, (cause, prob) in enumerate(causes[:5], 1)
        ])
        embed.add_field(
            name="ğŸ” Potential Causes",
            value=causes_str,
            inline=False
        )
    
    # çµæœã‚’äºˆæ¸¬
    effects = llm.causal_engine.predict_effect(event, depth=3)
    
    if effects:
        effects_str = "\n".join([
            f"{i}. {create_progress_bar(prob)} {prob:.0%} - {effect[:50]}"
            for i, (effect, prob) in enumerate(effects[:5], 1)
        ])
        embed.add_field(
            name="ğŸ”® Predicted Effects",
            value=effects_str,
            inline=False
        )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='synthesize', description='2ã¤ã®æ¦‚å¿µã‚’å‰µé€ çš„ã«çµ±åˆ')
async def synthesize_command(interaction: discord.Interaction, concept_a: str, concept_b: str):
    """å‰µé€ çš„çµ±åˆ"""
    if not llm or not llm.creative_synthesizer:
        await interaction.response.send_message('âŒ å‰µé€ çš„çµ±åˆãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    synthesis = llm.creative_synthesizer.synthesize(concept_a, concept_b)
    
    embed = discord.Embed(
        title="ğŸ¨ Creative Synthesis",
        description=f"**{concept_a}** + **{concept_b}**",
        color=discord.Color.magenta()
    )
    
    embed.add_field(
        name="ğŸ’¡ Synthesized Concept",
        value=synthesis.synthesis,
        inline=False
    )
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    novelty_bar = create_progress_bar(synthesis.novelty_score)
    coherence_bar = create_progress_bar(synthesis.coherence_score)
    useful_bar = create_progress_bar(synthesis.usefulness_score)
    
    embed.add_field(
        name="ğŸ“Š Innovation Metrics",
        value=f"**Novelty**: [{novelty_bar}] {synthesis.novelty_score:.0%}\n"
              f"**Coherence**: [{coherence_bar}] {synthesis.coherence_score:.0%}\n"
              f"**Usefulness**: [{useful_bar}] {synthesis.usefulness_score:.0%}",
        inline=False
    )
    
    overall = (synthesis.novelty_score + synthesis.coherence_score + synthesis.usefulness_score) / 3
    embed.add_field(
        name="ğŸŒŸ Overall Innovation Score",
        value=f"{create_progress_bar(overall)} **{overall:.0%}**",
        inline=False
    )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='verify', description='ä¸»å¼µã‚’æ¤œè¨¼')
async def verify_command(interaction: discord.Interaction, claim: str):
    """æ¤œè¨¼"""
    if not llm or not llm.verification_system:
        await interaction.response.send_message('âŒ æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    from collections import defaultdict
    import statistics
    
    # è¤‡æ•°ã®æ¤œè¨¼æ–¹æ³•ã‚’é©ç”¨
    VerificationMethod = quantum_module.VerificationMethod
    methods = [
        VerificationMethod.LOGICAL_CONSISTENCY,
        VerificationMethod.CROSS_REFERENCE,
        VerificationMethod.FACT_CHECK
    ]
    
    results = []
    for method in methods:
        verification = llm.verification_system.verify_claim(claim, "", method)
        results.append(verification)
    
    embed = discord.Embed(
        title="ğŸ” Claim Verification",
        description=f"**Claim**: {claim[:200]}",
        color=discord.Color.blue()
    )
    
    # å„æ¤œè¨¼çµæœ
    for i, v in enumerate(results, 1):
        status = "âœ… VERIFIED" if v.result else "âŒ REJECTED"
        conf_bar = create_progress_bar(v.confidence)
        
        embed.add_field(
            name=f"{i}. {v.method.value.replace('_', ' ').title()}",
            value=f"{status}\n"
                  f"Confidence: [{conf_bar}] {v.confidence:.0%}\n"
                  f"Evidence: {', '.join(v.evidence[:2])}",
            inline=False
        )
    
    # ç·åˆåˆ¤å®š
    avg_confidence = statistics.mean(v.confidence for v in results)
    verified_count = sum(1 for v in results if v.result)
    
    if verified_count == len(results) and avg_confidence > 0.7:
        assessment = "âœ… HIGHLY CREDIBLE"
        color = discord.Color.green()
    elif verified_count >= len(results) / 2:
        assessment = "âš ï¸ PARTIALLY VERIFIED"
        color = discord.Color.orange()
    else:
        assessment = "âŒ NOT VERIFIED"
        color = discord.Color.red()
    
    embed.color = color
    embed.add_field(
        name="ğŸ¯ Overall Assessment",
        value=f"{assessment} ({avg_confidence:.0%} confidence)",
        inline=False
    )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='predict', description='æ¬¡ã®æ„å›³ã‚’äºˆæ¸¬')
async def predict_command(interaction: discord.Interaction):
    """äºˆæ¸¬"""
    if not llm or not llm.predictive_engine:
        await interaction.response.send_message('âŒ äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    embed = discord.Embed(
        title="ğŸ”® Predictive Analysis",
        color=discord.Color.purple()
    )
    
    # æ¬¡ã®æ„å›³ã‚’äºˆæ¸¬
    predicted_intent = llm.predictive_engine.predict_next_intent()
    success_prob = llm.predictive_engine.get_success_probability(predicted_intent)
    
    embed.add_field(
        name="ğŸ“ Next Query Prediction",
        value=f"**Predicted Intent**: {predicted_intent.value}\n"
              f"**Success Probability**: {success_prob:.0%}",
        inline=False
    )
    
    # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
    if llm.predictive_engine.model.user_patterns:
        from collections import Counter
        top_patterns = sorted(
            llm.predictive_engine.model.user_patterns.items(),
            key=lambda x: len(x[1]),
            reverse=True
        )[:5]
        
        patterns_str = "\n".join([
            f"â€¢ {pattern}: {statistics.mean(results):.0%} success ({len(results)} samples)"
            for pattern, results in top_patterns
        ])
        
        embed.add_field(
            name="ğŸ“Š Usage Patterns",
            value=patterns_str,
            inline=False
        )
    
    await interaction.response.send_message(embed=embed)


@tree.command(name='scientific', description='ç§‘å­¦çš„æ‰‹æ³•ã‚’é©ç”¨')
async def scientific_command(interaction: discord.Interaction, observation: str):
    """ç§‘å­¦çš„æ‰‹æ³•"""
    if not llm or not llm.scientific_method:
        await interaction.response.send_message('âŒ ç§‘å­¦çš„æ‰‹æ³•ãŒç„¡åŠ¹ã§ã™', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    embed = discord.Embed(
        title="ğŸ”¬ Scientific Method Application",
        description=f"**Observation**: {observation}",
        color=discord.Color.blue()
    )
    
    # 1. ä»®èª¬å®šå¼åŒ–
    hypothesis = llm.scientific_method.formulate_hypothesis(observation)
    embed.add_field(
        name="1ï¸âƒ£ Hypothesis",
        value=f"{hypothesis.statement}\n"
              f"Prior Confidence: {hypothesis.bayesian_prior:.0%}",
        inline=False
    )
    
    # 2. å®Ÿé¨“è¨­è¨ˆ
    experiment = llm.scientific_method.design_experiment(hypothesis)
    embed.add_field(
        name="2ï¸âƒ£ Experiment Design",
        value=f"**ID**: {experiment['id']}\n"
              f"**Method**: {experiment['method']}\n"
              f"**Status**: {experiment['status']}",
        inline=False
    )
    
    # 3. äºˆæ¸¬
    embed.add_field(
        name="3ï¸âƒ£ Predictions",
        value="â€¢ Measurable outcome expected\n"
              "â€¢ Reproducible under similar conditions\n"
              "â€¢ Consistent with existing knowledge",
        inline=False
    )
    
    # 4. çµæœåˆ†æï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
    analysis = llm.scientific_method.analyze_results(
        experiment['id'],
        {'data_points': 100, 'effect_observed': True}
    )
    
    embed.add_field(
        name="4ï¸âƒ£ Analysis",
        value=f"**Significance**: {analysis['statistical_significance']:.3f}\n"
              f"**Effect Size**: {analysis['effect_size']:.3f}\n"
              f"**Conclusion**: {analysis['conclusion']}",
        inline=False
    )
    
    # 5. ãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼
    mock_reviews = [
        "Sound methodology",
        "Results consistent with theory",
        "Further validation recommended"
    ]
    review_score = llm.scientific_method.peer_review(hypothesis, mock_reviews)
    
    embed.add_field(
        name="5ï¸âƒ£ Peer Review",
        value=f"Score: {create_progress_bar(review_score)} {review_score:.0%}",
        inline=False
    )
    
    # æœ€çµ‚è©•ä¾¡
    if review_score > 0.7 and analysis['statistical_significance'] > 0.05:
        assessment = "âœ… HYPOTHESIS SUPPORTED"
    else:
        assessment = "âš ï¸ MORE EVIDENCE NEEDED"
    
    embed.add_field(
        name="ğŸ¯ Final Assessment",
        value=assessment,
        inline=False
    )
    
    await interaction.followup.send(embed=embed)


@tree.command(name='progress', description='å­¦ç¿’é€²æ—ã‚’åˆ†æ')
async def progress_command(interaction: discord.Interaction):
    """å­¦ç¿’é€²æ—"""
    # æœ€åˆã«å¿œç­”ã‚’ç¢ºä¿
    await interaction.response.defer(ephemeral=True)
    
    if not llm:
        await interaction.followup.send('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    progress = llm.analyze_learning_progress()
    
    if progress['status'] == 'insufficient_data':
        await interaction.followup.send(
            'âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³\nç¶™ç¶šåˆ©ç”¨ã§é€²æ—è¿½è·¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™',
            ephemeral=True
        )
        return
    
    embed = discord.Embed(
        title="ğŸ“Š Learning Progress Analysis",
        color=discord.Color.gold()
    )
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰
    trend_emoji = {
        'improving': 'ğŸ“ˆ',
        'declining': 'ğŸ“‰',
        'stable': 'â¡ï¸'
    }
    
    embed.add_field(
        name="ğŸ“ˆ Overall Metrics",
        value=f"**Total Interactions**: {progress['total_interactions']}\n"
              f"**Recent Quality**: {progress['recent_quality']:.3f}\n"
              f"**Improvement**: {progress['improvement']:+.3f}\n"
              f"**Trend**: {trend_emoji.get(progress['trend'], 'â¡ï¸')} {progress['trend'].upper()}",
        inline=False
    )
    
    # æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    if progress['best_strategy']:
        embed.add_field(
            name="ğŸ¯ Best Strategy",
            value=progress['best_strategy'],
            inline=True
        )
        
        if 'strategy_performance' in progress:
            perf_str = "\n".join([
                f"{strategy}: {create_progress_bar(score, 10)} {score:.3f}"
                for strategy, score in sorted(
                    progress['strategy_performance'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]
            ])
            
            embed.add_field(
                name="ğŸ“Š Strategy Performance",
                value=perf_str,
                inline=False
            )
    
    await interaction.followup.send(embed=embed, ephemeral=True)


@tree.command(name='insights', description='ãƒ¡ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ')
async def insights_command(interaction: discord.Interaction):
    """ã‚¤ãƒ³ã‚µã‚¤ãƒˆ"""
    if not llm:
        await interaction.response.send_message('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    insights = llm.generate_meta_insights()
    
    if not insights:
        await interaction.response.send_message(
            'âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³\nã‚·ã‚¹ãƒ†ãƒ ã¨ã®å¯¾è©±ã‚’ç¶šã‘ã¦ãã ã•ã„',
            ephemeral=True
        )
        return
    
    embed = discord.Embed(
        title="ğŸŒŸ Meta-Level Insights",
        description="ã‚·ã‚¹ãƒ†ãƒ ãŒç”Ÿæˆã—ãŸæ·±ã„æ´å¯Ÿ",
        color=discord.Color.purple()
    )
    
    for i, insight in enumerate(insights, 1):
        embed.add_field(
            name=f"Insight {i}",
            value=insight,
            inline=False
        )
    
    await interaction.response.send_message(embed=embed)


@tree.command(name='save', description='ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜(ç®¡ç†è€…ã®ã¿)')
async def save_command(interaction: discord.Interaction):
    """ä¿å­˜"""
    if not interaction.user.guild_permissions.administrator:
        await interaction.response.send_message(
            'âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ç®¡ç†è€…ã®ã¿ä½¿ç”¨ã§ãã¾ã™',
            ephemeral=True
        )
        return
    
    if not llm:
        await interaction.response.send_message('âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“', ephemeral=True)
        return
    
    await interaction.response.defer(thinking=True)
    
    try:
        llm.save_state('discord_quantum_state.json')
        
        # ä¼šè©±å±¥æ­´ã‚‚ä¿å­˜
        with open('discord_conversations.json', 'w', encoding='utf-8') as f:
            json.dump(user_conversations, f, ensure_ascii=False, indent=2)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        with open('discord_session.json', 'w', encoding='utf-8') as f:
            session_copy = session_data.copy()
            session_copy['start_time'] = session_copy['start_time'].isoformat()
            json.dump(session_copy, f, ensure_ascii=False, indent=2)
        
        await interaction.followup.send('ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ')
    except Exception as e:
        await interaction.followup.send(f'âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}')


@tree.command(name='session', description='ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º')
async def session_command(interaction: discord.Interaction):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"""
    uptime = datetime.now() - session_data['start_time']
    
    embed = discord.Embed(
        title="ğŸ“Š Session Information",
        color=discord.Color.blue()
    )
    
    embed.add_field(
        name="â±ï¸ Uptime",
        value=f"{uptime.days}d {uptime.seconds//3600}h {(uptime.seconds//60)%60}m",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ“ˆ Queries",
        value=f"**Total**: {session_data['total_queries']}\n"
              f"**Successful**: {session_data['successful_queries']}\n"
              f"**Success Rate**: {session_data['successful_queries']/max(session_data['total_queries'],1):.1%}",
        inline=True
    )
    
    embed.add_field(
        name="ğŸš€ Advanced Features",
        value=f"ğŸ”® Quantum: {session_data['quantum_optimizations']}\n"
              f"ğŸ§¬ Genetic: {session_data['genetic_evolutions']}\n"
              f"ğŸŒŠ Swarm: {session_data['swarm_optimizations']}",
        inline=False
    )
    
    await interaction.response.send_message(embed=embed)

@tree.command(name='info', description='ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º')
async def info_command(interaction: discord.Interaction):
    """è©³ç´°æƒ…å ±"""
    await interaction.response.defer(thinking=True)
    
    user_id = interaction.user.id
    uptime = datetime.now() - session_data['start_time']
    
    # ãƒ¡ã‚¤ãƒ³Embed
    embed = discord.Embed(
        title="â„¹ï¸ System & User Information",
        description="Quantum-Enhanced AI System v3.5Î³ ULTIMATE",
        color=discord.Color.blue(),
        timestamp=datetime.now()
    )
    
    # ğŸ¤– Botæƒ…å ±
    bot_info = []
    bot_info.append(f"**Name**: {bot.user.name}#{bot.user.discriminator}")
    bot_info.append(f"**ID**: `{bot.user.id}`")
    bot_info.append(f"**Servers**: {len(bot.guilds)}")
    bot_info.append(f"**Uptime**: {uptime.days}d {uptime.seconds//3600}h {(uptime.seconds//60)%60}m")
    
    embed.add_field(
        name="ğŸ¤– Bot Information",
        value="\n".join(bot_info),
        inline=False
    )
    
    # ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
    user_info = []
    user_info.append(f"**User**: {interaction.user.name}")
    user_info.append(f"**ID**: `{user_id}`")
    
    # ä¼šè©±ãƒ¢ãƒ¼ãƒ‰çŠ¶æ…‹
    talk_mode = "ğŸŸ¢ ON" if user_id in talk_mode_users and talk_mode_users[user_id] else "ğŸ”´ OFF"
    user_info.append(f"**Talk Mode**: {talk_mode}")
    
    # ä¼šè©±å±¥æ­´
    if user_id in user_conversations:
        conv_count = len(user_conversations[user_id])
        user_info.append(f"**Conversations**: {conv_count}/50")
        
        if conv_count > 0:
            import statistics
            avg_quality = statistics.mean(c['quality'] for c in user_conversations[user_id])
            user_info.append(f"**Avg Quality**: {avg_quality:.1%}")
    else:
        user_info.append(f"**Conversations**: 0/50")
    
    embed.add_field(
        name="ğŸ‘¤ Your Information",
        value="\n".join(user_info),
        inline=False
    )
    
    # ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
    session_info = []
    session_info.append(f"**Total Queries**: {session_data['total_queries']}")
    session_info.append(f"**Successful**: {session_data['successful_queries']}")
    if session_data['total_queries'] > 0:
        success_rate = session_data['successful_queries'] / session_data['total_queries']
        session_info.append(f"**Success Rate**: {success_rate:.1%}")
    session_info.append(f"**Active Users**: {len(user_conversations)}")
    
    embed.add_field(
        name="ğŸ“Š Session Statistics",
        value="\n".join(session_info),
        inline=True
    )
    
    # ğŸš€ é«˜åº¦æ©Ÿèƒ½ã®ä½¿ç”¨çŠ¶æ³
    feature_info = []
    feature_info.append(f"ğŸ”® Quantum: {session_data['quantum_optimizations']}")
    feature_info.append(f"ğŸ§¬ Genetic: {session_data['genetic_evolutions']}")
    feature_info.append(f"ğŸŒŠ Swarm: {session_data['swarm_optimizations']}")
    
    embed.add_field(
        name="ğŸš€ Advanced Features",
        value="\n".join(feature_info),
        inline=True
    )
    
    # âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    if llm:
        config = llm.config
        config_info = []
        config_info.append(f"**Model**: {config.model}")
        config_info.append(f"**Temperature**: {config.temperature}")
        config_info.append(f"**Max Tokens**: {config.max_tokens}")
        
        # æœ‰åŠ¹ãªæ©Ÿèƒ½ã‚«ã‚¦ãƒ³ãƒˆ
        enabled_features = []
        if hasattr(config, 'quantum') and config.quantum.enabled:
            enabled_features.append("Quantum")
        if hasattr(config, 'genetic') and config.genetic.enabled:
            enabled_features.append("Genetic")
        if hasattr(config, 'swarm') and config.swarm.enabled:
            enabled_features.append("Swarm")
        if hasattr(config, 'rlhf') and config.rlhf.enabled:
            enabled_features.append("RLHF")
        if hasattr(config, 'adversarial_testing') and config.adversarial_testing:
            enabled_features.append("Adversarial")
        if hasattr(config, 'causal_reasoning') and config.causal_reasoning:
            enabled_features.append("Causal")
        if hasattr(config, 'creative_synthesis') and config.creative_synthesis:
            enabled_features.append("Creative")
        if hasattr(config, 'verification_system') and config.verification_system:
            enabled_features.append("Verification")
        
        config_info.append(f"**Active Modules**: {len(enabled_features)}/8")
        
        embed.add_field(
            name="âš™ï¸ System Configuration",
            value="\n".join(config_info),
            inline=False
        )
    
    # ğŸ§  LLMã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
    if llm:
        llm_info = []
        
        # Knowledge Graph
        if hasattr(llm, 'knowledge_graph') and llm.knowledge_graph:
            try:
                kg = llm.knowledge_graph
                llm_info.append(f"**KG Nodes**: {len(kg.nodes)}")
                llm_info.append(f"**KG Edges**: {len(kg.edges)}")
            except Exception as e:
                print(f"Knowledge Graph info error: {e}")
        
        # Vector DB - å®‰å…¨ã«ã‚¢ã‚¯ã‚»ã‚¹
        if hasattr(llm, 'vector_db') and llm.vector_db:
            try:
                # VectorDBã®å®Ÿè£…ã«å¿œã˜ã¦é©åˆ‡ãªå±æ€§ã«ã‚¢ã‚¯ã‚»ã‚¹
                if hasattr(llm.vector_db, 'vectors') and isinstance(llm.vector_db.vectors, dict):
                    llm_info.append(f"**Vector Entries**: {len(llm.vector_db.vectors)}")
                elif hasattr(llm.vector_db, 'embeddings') and isinstance(llm.vector_db.embeddings, dict):
                    llm_info.append(f"**Vector Entries**: {len(llm.vector_db.embeddings)}")
                elif hasattr(llm.vector_db, '__len__'):
                    llm_info.append(f"**Vector Entries**: {len(llm.vector_db)}")
            except Exception as e:
                print(f"Vector DB info error: {e}")
        
        # Context Window
        if hasattr(llm, 'context_window') and llm.context_window:
            try:
                llm_info.append(f"**Context Size**: {len(llm.context_window.messages)}")
            except Exception as e:
                print(f"Context Window info error: {e}")
        
        # Metrics
        if hasattr(llm, 'metrics') and llm.metrics:
            try:
                total_interactions = llm.metrics.get('total_queries', 0)
                if total_interactions > 0:
                    llm_info.append(f"**Total Interactions**: {total_interactions}")
            except Exception as e:
                print(f"Metrics info error: {e}")
        
        if llm_info:
            embed.add_field(
                name="ğŸ§  LLM State",
                value="\n".join(llm_info),
                inline=True
            )
    
    # ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    if llm and hasattr(llm, 'metrics') and llm.metrics:
        perf_info = []
        
        if 'strategy_performance' in llm.metrics and llm.metrics['strategy_performance']:
            try:
                best_strategy = max(llm.metrics['strategy_performance'].items(), 
                                  key=lambda x: x[1])
                perf_info.append(f"**Best Strategy**: {best_strategy[0]}")
            except:
                pass
        
        if 'total_tokens' in llm.metrics:
            perf_info.append(f"**Total Tokens**: {llm.metrics['total_tokens']:,}")
        
        if 'total_cost' in llm.metrics:
            perf_info.append(f"**Total Cost**: ${llm.metrics['total_cost']:.4f}")
        
        if perf_info:
            embed.add_field(
                name="ğŸ“ˆ Performance",
                value="\n".join(perf_info),
                inline=True
            )
    
    # ğŸ® åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰æ•°
    try:
        commands = await tree.fetch_commands()
        embed.add_field(
            name="ğŸ® Available Commands",
            value=f"**Total**: {len(commands)} commands\n"
                  f"Use `/about` to see features",
            inline=False
        )
    except:
        embed.add_field(
            name="ğŸ® Available Commands",
            value=f"Use `/about` to see all features",
            inline=False
        )
    
    # ğŸ’¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    quick_actions = []
    quick_actions.append("`/talk mode:on` - ä¼šè©±ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
    quick_actions.append("`/clear` - ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢")
    quick_actions.append("`/config` - è©³ç´°è¨­å®šè¡¨ç¤º")
    quick_actions.append("`/session` - ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±")
    
    embed.add_field(
        name="ğŸ’¡ Quick Actions",
        value="\n".join(quick_actions),
        inline=False
    )
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    embed.set_footer(
        text=f"Requested by {interaction.user.name}",
        icon_url=interaction.user.display_avatar.url if interaction.user.display_avatar else None
    )
    
    await interaction.followup.send(embed=embed)

# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ====================

def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    discord_token = os.environ.get('DISCORD_BOT_TOKEN')
    groq_key = os.environ.get('GROQ_API_KEY')
    
    if not discord_token:
        print('âŒ DISCORD_BOT_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
        print('export DISCORD_BOT_TOKEN="your_token_here"')
        sys.exit(1)
    
    if not groq_key:
        print('âŒ GROQ_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
        print('export GROQ_API_KEY="your_key_here"')
        sys.exit(1)
    
    print('ğŸš€ Quantum Discord Bot ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...')
    print('=' * 80)
    
    try:
        bot.run(discord_token)
    except discord.LoginFailure:
        print('âŒ Discord Token ãŒç„¡åŠ¹ã§ã™')
        sys.exit(1)
    except Exception as e:
        print(f'âŒ Botèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}')
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
