# -*- coding: utf-8 -*-
"""
ã‚³ãƒãƒ³ãƒ‰ãƒãƒ³ãƒ‰ãƒ©
ãƒãƒ£ãƒƒãƒˆã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
"""

import json
import statistics
from datetime import datetime


class CommandHandlers:
    """ã‚³ãƒãƒ³ãƒ‰å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, chat_interface):
        self.chat = chat_interface
        self.llm = chat_interface.llm
    
    def handle(self, command: str) -> bool:
        """
        ã‚³ãƒãƒ³ãƒ‰å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©
        
        Args:
            command: ã‚³ãƒãƒ³ãƒ‰æ–‡å­—åˆ—
        
        Returns:
            ç¶™ç¶šã™ã‚‹ã‹ã©ã†ã‹ï¼ˆFalse=çµ‚äº†ï¼‰
        """
        parts = command.strip().split()
        cmd = parts[0].lower()
        
        # ========== åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ ==========
        if cmd == '/exit':
            print("ğŸ‘‹ Goodbye!")
            return False
        
        elif cmd == '/help':
            self.chat.print_welcome()
        
        elif cmd == '/stats':
            self.chat.print_stats()
        
        # ========== ãƒ‡ãƒ¼ã‚¿ç®¡ç† ==========
        elif cmd == '/save':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.save_state(filepath)
        
        elif cmd == '/load':
            filepath = parts[1] if len(parts) > 1 else 'quantum_llm_state.json'
            self.llm.load_state(filepath)
        
        elif cmd == '/clear':
            self.chat.history.clear()
            self.llm.context_window.clear()
            if self.llm.vector_db:
                self.llm.vector_db.clear()
            print("ğŸ—‘ï¸  All history cleared")
        
        # ========== è©•ä¾¡ãƒ»å­¦ç¿’ ==========
        elif cmd == '/feedback':
            self._handle_feedback(parts)
        
        elif cmd == '/rate':
            self._handle_rate(parts)
        
        # ========== é«˜åº¦ãªæ©Ÿèƒ½ ==========
        elif cmd == '/quantum':
            self._show_quantum_info()
        
        elif cmd == '/genetic':
            self._show_genetic_info()
        
        elif cmd == '/swarm':
            self._show_swarm_info()
        
        elif cmd == '/rlhf':
            self._show_rlhf_info()
        
        elif cmd == '/kg':
            self._show_knowledge_graph()
        
        # ========== è¡¨ç¤ºãƒ»è¨­å®š ==========
        elif cmd == '/history':
            self._show_history()
        
        elif cmd == '/profile':
            self._show_profile()
        
        elif cmd == '/config':
            self._show_config()
        
        else:
            print(f"âŒ Unknown command: {cmd}")
            print("ğŸ’¡ Type /help for available commands")
        
        return True
    
    def _handle_feedback(self, parts):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†"""
        if not self.chat.history:
            print("âŒ No previous response to rate")
            return
        
        try:
            rating = int(parts[1]) if len(parts) > 1 else 0
            if rating < -2 or rating > 2:
                print("âŒ Rating must be between -2 and +2")
                return
            
            last_query, last_response = self.chat.history[-1]
            self.llm.add_feedback(last_query, last_response.text, rating, last_response)
            print(f"âœ… Feedback recorded: {rating:+d}")
        except ValueError:
            print("âŒ Invalid rating")
    
    def _handle_rate(self, parts):
        """5æ®µéšè©•ä¾¡å‡¦ç†"""
        if not self.chat.history:
            print("âŒ No previous response to rate")
            return
        
        try:
            rating = int(parts[1]) if len(parts) > 1 else 3
            if rating < 1 or rating > 5:
                print("âŒ Rating must be between 1 and 5")
                return
            
            # 5æ®µéšã‚’-2~+2ã«å¤‰æ›
            converted = rating - 3
            last_query, last_response = self.chat.history[-1]
            self.llm.add_feedback(last_query, last_response.text, converted, last_response)
            print(f"â­ Rated: {rating}/5 stars")
        except ValueError:
            print("âŒ Invalid rating")
    
    def _show_quantum_info(self):
        """é‡å­æœ€é©åŒ–è©³ç´°"""
        if not self.llm.quantum_optimizer:
            print("âŒ Quantum optimization disabled")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ”® Quantum Optimization Details")
        print("=" * 80)
        print(f"\nâš›ï¸  Configuration:")
        print(f"   Qubits: {self.llm.quantum_optimizer.num_qubits}")
        print(f"   Iterations: {self.llm.quantum_optimizer.config.iterations}")
        print(f"   Optimization Depth: {self.llm.quantum_optimizer.config.optimization_depth}")
        print(f"\nğŸ“Š Performance:")
        print(f"   Total Optimizations: {self.llm.metrics['quantum_optimizations']}")
        print(f"\nğŸ’¡ When to Use:")
        print(f"   â€¢ Frontier-level complexity questions")
        print(f"   â€¢ Multi-dimensional optimization problems")
        print("=" * 80 + "\n")
    
    def _show_genetic_info(self):
        """éºä¼çš„é€²åŒ–è©³ç´°"""
        if not self.llm.genetic_evolver:
            print("âŒ Genetic evolution disabled")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ§¬ Genetic Evolution Details")
        print("=" * 80)
        print(f"\nğŸ“ˆ Population Status:")
        print(f"   Generation: {self.llm.genetic_evolver.generation}")
        print(f"   Population Size: {len(self.llm.genetic_evolver.population)}")
        print(f"   Mutation Rate: {self.llm.config.genetic.mutation_rate:.1%}")
        print(f"   Crossover Rate: {self.llm.config.genetic.crossover_rate:.1%}")
        
        best_prompts = self.llm.genetic_evolver.get_best_prompts(5)
        if best_prompts:
            print(f"\nğŸ† Top 5 Evolved Prompts:")
            for i, prompt in enumerate(best_prompts, 1):
                fitness_bar = "â–ˆ" * int(prompt.fitness * 20) + "â–‘" * (20 - int(prompt.fitness * 20))
                print(f"\n   {i}. Fitness: [{fitness_bar}] {prompt.fitness:.3f}")
                print(f"      Generation: {prompt.generation} | Mutations: {prompt.mutations}")
                print(f"      Template: {prompt.template[:60]}...")
        
        print("=" * 80 + "\n")
    
    def _show_swarm_info(self):
        """ç¾¤çŸ¥èƒ½è©³ç´°"""
        if not self.llm.swarm:
            print("âŒ Swarm intelligence disabled")
            return
        
        print("\n" + "=" * 80)
        print("ğŸŒŠ Swarm Intelligence Details")
        print("=" * 80)
        print(f"\nğŸ Swarm Configuration:")
        print(f"   Agents: {len(self.llm.swarm.agents)}")
        print(f"   Inertia Weight: {self.llm.config.swarm.inertia_weight}")
        print(f"   Cognitive Weight: {self.llm.config.swarm.cognitive_weight}")
        print(f"   Social Weight: {self.llm.config.swarm.social_weight}")
        
        if self.llm.swarm.agents:
            print(f"\nğŸ­ Agent Personas:")
            for agent in self.llm.swarm.agents:
                print(f"   â€¢ {agent.persona.value}: Fitness {agent.best_fitness:.3f}")
        
        print(f"\nğŸ“Š Performance:")
        print(f"   Global Best Fitness: {self.llm.swarm.global_best_fitness:.3f}")
        print(f"   Total Optimizations: {self.llm.metrics['swarm_optimizations']}")
        
        print("=" * 80 + "\n")
    
    def _show_rlhf_info(self):
        """RLHFè©³ç´°"""
        if not self.llm.rlhf:
            print("âŒ RLHF disabled")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ¯ Reinforcement Learning Details")
        print("=" * 80)
        print(f"\nğŸ§  Learning Status:")
        print(f"   States Explored: {len(self.llm.rlhf.state_visits)}")
        print(f"   Q-Table Size: {len(self.llm.rlhf.q_table)}")
        print(f"   Total Updates: {sum(self.llm.rlhf.state_visits.values())}")
        print(f"   Learning Rate: {self.llm.config.rlhf.learning_rate}")
        print(f"   Exploration Rate: {self.llm.config.rlhf.exploration_rate:.1%}")
        
        if self.llm.rlhf.reward_history:
            avg_reward = statistics.mean(self.llm.rlhf.reward_history)
            recent_reward = statistics.mean(
                self.llm.rlhf.reward_history[-10:]
            ) if len(self.llm.rlhf.reward_history) >= 10 else avg_reward
            print(f"\nğŸ“ˆ Rewards:")
            print(f"   Average Reward: {avg_reward:.3f}")
            print(f"   Recent Reward (last 10): {recent_reward:.3f}")
            trend = 'ğŸ“ˆ Improving' if recent_reward > avg_reward else 'ğŸ“‰ Declining' if recent_reward < avg_reward else 'â¡ï¸ Stable'
            print(f"   Trend: {trend}")
        
        print("=" * 80 + "\n")
    
    def _show_knowledge_graph(self):
        """çŸ¥è­˜ã‚°ãƒ©ãƒ•è¡¨ç¤º"""
        if not self.llm.knowledge_graph:
            print("âŒ Knowledge graph disabled")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ§© Knowledge Graph Status")
        print("=" * 80)
        print(f"\nğŸ“Š Statistics:")
        print(f"   Nodes: {len(self.llm.knowledge_graph.nodes)}")
        print(f"   Edges: {len(self.llm.knowledge_graph.edges)}")
        
        central = self.llm.knowledge_graph.get_central_nodes(5)
        if central:
            print(f"\nğŸ¯ Central Nodes (by degree):")
            for node_id, degree in central:
                node = self.llm.knowledge_graph.nodes[node_id]
                print(f"   â€¢ {node.name} (degree: {degree}, type: {node.type})")
        
        print("=" * 80 + "\n")
    
    def _show_history(self):
        """ä¼šè©±å±¥æ­´è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“œ Conversation History")
        print("=" * 80)
        
        if not self.chat.history:
            print("\nNo conversation history yet.")
            print("=" * 80 + "\n")
            return
        
        recent = self.chat.history[-10:]
        for i, (query, response) in enumerate(recent, 1):
            print(f"\n{i}. Q: {query[:60]}...")
            print(f"   A: {response.text[:60]}...")
            print(f"   Strategy: {response.strategy.value if response.strategy else 'N/A'} | Quality: {response.quality_score:.2f}")
        
        print(f"\nğŸ“Š Total Conversations: {len(self.chat.history)}")
        print("=" * 80 + "\n")
    
    def _show_profile(self):
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ‘¤ User Profile")
        print("=" * 80)
        
        profile = self.llm.profile
        print(f"\nğŸ“Š Activity:")
        print(f"   Total Interactions: {profile['interaction_count']}")
        print(f"   Feedback Given: {len(profile.get('feedback_history', []))}")
        
        # ãƒˆãƒƒãƒ—ãƒˆãƒ”ãƒƒã‚¯
        topics = sorted(profile['topics'].items(), key=lambda x: x[1], reverse=True)[:10]
        if topics:
            print(f"\nğŸ“š Top Topics:")
            for topic, score in topics:
                print(f"   â€¢ {topic}: {score}")
        
        # å°‚é–€çŸ¥è­˜
        expertise = [(k, v) for k, v in profile['expertise'].items() if v > 0.3]
        if expertise:
            expertise.sort(key=lambda x: x[1], reverse=True)
            print(f"\nğŸ“ Expertise Areas:")
            for topic, level in expertise[:10]:
                bar = "â–ˆ" * int(level * 20) + "â–‘" * (20 - int(level * 20))
                print(f"   {topic:20s} [{bar}] {level:.0%}")
        
        print("=" * 80 + "\n")
    
    def _show_config(self):
        """è¨­å®šè¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("âš™ï¸  System Configuration")
        print("=" * 80)
        
        config = self.llm.config
        print(f"\nğŸ”§ Basic Settings:")
        print(f"   Model: {config.model}")
        print(f"   Max Tokens: {config.max_tokens}")
        print(f"   Temperature: {config.temperature}")
        print(f"   Similarity Threshold: {config.similarity_threshold}")
        
        print(f"\nğŸš€ Features:")
        print(f"   Adaptive: {'âœ…' if config.adaptive else 'âŒ'}")
        print(f"   Vector DB: {'âœ…' if config.vec_db else 'âŒ'}")
        print(f"   Knowledge Graph: {'âœ…' if config.knowledge_graph else 'âŒ'}")
        print(f"   Chain of Thought: {'âœ…' if config.chain_of_thought else 'âŒ'}")
        print(f"   Quantum Optimization: {'âœ…' if config.quantum.enabled else 'âŒ'}")
        print(f"   Genetic Evolution: {'âœ…' if config.genetic.enabled else 'âŒ'}")
        print(f"   Swarm Intelligence: {'âœ…' if config.swarm.enabled else 'âŒ'}")
        print(f"   RLHF: {'âœ…' if config.rlhf.enabled else 'âŒ'}")
        
        print("=" * 80 + "\n")
